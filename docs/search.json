[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Nothing to see here"
  },
  {
    "objectID": "homework/homework.html",
    "href": "homework/homework.html",
    "title": "Homework",
    "section": "",
    "text": "Under construction\n\n\n\nThis syllabus is under construction until Fall 2023"
  },
  {
    "objectID": "homework/homework.html#exercises",
    "href": "homework/homework.html#exercises",
    "title": "Homework",
    "section": "Exercises",
    "text": "Exercises\nVarious tasks and exercises will be found here.\nThe exercise list will be updated as the semester progresses."
  },
  {
    "objectID": "homework/homework.html#download",
    "href": "homework/homework.html#download",
    "title": "Homework",
    "section": "Download",
    "text": "Download\nHomework Exercise 01"
  },
  {
    "objectID": "index.html#psyc-167-data-visualization",
    "href": "index.html#psyc-167-data-visualization",
    "title": "**PSYC167**",
    "section": "PSYC 167: Data Visualization",
    "text": "PSYC 167: Data Visualization\nThis is the course website for PSYC 167: Data Visualization, taught by Prof. Gabriel I. Cook; 1 credit\nDescription\nData visualization is the science and art of creating graphical representations of information and data. Visual representations provide accessible ways to see patterns, trends, and outliers in data. Variables like position, size, and orientation can focus attention and guide perception but can also bias interpretation of data. Students will learn how well-designed visualizations can reduce bias and improve comprehension for data thereby facilitating data-driven decision-making. Students will explore techniques for creating effective visualizations based on principles from cognitive and perceptual psychology, art, and design. Students will gain hands-on experience coding real-world data visualizations for local offices, organizations, and industry participants.\nThe course is targeted toward students with expressed interest in cognition and cognitive biases related to data communication, students interested in using visualization to communicate their own messages, and students interested in creating better visualization tools and systems. Students will engage in discussions of the readings, complete programming and data analysis assignments, and prepare a final project involving storytelling with data visualizations."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html",
    "href": "modules/001_installing_and_setting_up_git_and_github.html",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "",
    "text": "We will perform all the necessary tasks for using Git with RStudio and managing files at the remote repository at GitHub.\n\n\n\nCreate a GitHub account\nInstall Git\nConfigure Git for R, within R (a familiar context)\nCreate a Personal Access Token (PAT)\nSet your Git Credentials (using PAT)\nCreate a Version Control Project in RStudio (for your team project)\nMake file edits, stage the, and commit them\nPush commits to GitHub"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#overview",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#overview",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "",
    "text": "We will perform all the necessary tasks for using Git with RStudio and managing files at the remote repository at GitHub.\n\n\n\nCreate a GitHub account\nInstall Git\nConfigure Git for R, within R (a familiar context)\nCreate a Personal Access Token (PAT)\nSet your Git Credentials (using PAT)\nCreate a Version Control Project in RStudio (for your team project)\nMake file edits, stage the, and commit them\nPush commits to GitHub"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#libraries-used",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#libraries-used",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Libraries Used",
    "text": "Libraries Used\n\n{usethis}: 2.2.2: for project workflow automation\n{gitcreds}: 0.1.2: for querying git credentials"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#why-go-through-the-trouble",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#why-go-through-the-trouble",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Why Go Through the Trouble?",
    "text": "Why Go Through the Trouble?\nProjects are rarely done without collaboration. Teams collaborate, leveraging team members’ work and accomplishments. Using R in conjunction with the a distributed version control system, like Git, will facilitate that collaboration process. Writing flexible R code that does not hard-code objects will allow your research project to be reproducible, for example, when variables and data change (e.g., new data added, a new year added, etc.). Git long with GitHub will allow you to track your edits (the version control) and share your code with your collaborators or interested scholars.\nSome reasons to use version control are:\n\nFacilitates project sharing (once it’s setup, you’ll get there)\nFacilitates collaboration. Others can also report errors or suggest features to your project.\nMakes reverting back to previous states easy. You can easily revert back to a previous version of your code in the event you discover errors or you delete critical details accidentally.\nServes as a memory for edits when memory fails. All changes across different versions of your code or written content is available.\n\nRStudio integrates support for Git but this interface is a little clunky. You can use it but RStudio also allows for communication via the command line Terminal, which will be the preferred method shared here."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#installing-git",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#installing-git",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Installing Git",
    "text": "Installing Git\n\nDo I need to install Git?\n\nMac OS Users can check if already install by typing git --version at the Mac Terminal. If a version number is returned, then Git is installed.\nWindows Users can press the Windows key (or click the Start button) and type Git in the search bar. If you see Git or GitBash listed, then Git is installed.\n\nDownload and Install Git (if necessary)\n\nMac OS Users may experience problems with instructions listed at the Git download site to install Homebrew and set the PATH variable. Instead, I recommend downloading the binary version here and download it to install.\nWindows Users can download the latest version of Git here. Download and install Git, making a note of where on your computer you are install it as you may need to locate the path for RStudio, especially if you use a portable version of Git."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-github-account",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-github-account",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Creating a GitHub Account",
    "text": "Creating a GitHub Account\n\nGo to GitHub and create a free GitHub account. Make note of your username and your associated e-mail as you will need those for configuring Git with R.\n\nConsider this brief 15-minute TryGit Tutorial.\n\nStay logged in so that you can complete a later step.\nSend your PM your GitHub username. Your PM will send those to me and I will add you to a private repo. Once you are added to the repo, you can do the next step."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#checking-git-setup-in-rstudio",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#checking-git-setup-in-rstudio",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Checking Git Setup in RStudio",
    "text": "Checking Git Setup in RStudio\nYou will need to tell RStudio where to find the Git program as this may not be recognize automatically.\n\nFind the path to the Git program executable that was installed in an earlier step.\n\nIn the Terminal in RStudio (not the R console), type: where git on Windows or which git on Mac/Linux and you might find the path easily. If there are more than one paths listed, just make note of one of them.\nIf for some reason you don’t see a path listed using that approach, type: Sys.which(\"git\") in your R console. The path here will likely be truncated so you will have to fill in the gaps when performing the step to set the path.\n\nIn RStudio, go to Tools &gt; Global Options and click on left side bar menu item Git/SVN.\nSelect the option at the top to Enable version control interface for RStudio projects if it is not selected.\nSet the path to the Git executable if it is not already there. Browse to the path to where Git.exe installed on your computer. Windows Users should make note that this path should be a path containing Git.exe and not a path containing git-bash.exe.\nClick Apply and click OK."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#configuring-git-and-github",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#configuring-git-and-github",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Configuring Git and GitHub",
    "text": "Configuring Git and GitHub\nThere are two ways you can set up, either using R (console) or the command line (terminal). My recommendation is to use R because that is where you are likely most familiar. We will use the {usethis} library to help you.\nThe {usethis} library will make connecting your R project to your github account simple. This library should be installed as part of the packages from the start of the course. You will use usethis::use_git_config() to configure your GitHub account (see earlier) with Git on your computer. In the below example, you need to pass two arguments, your user.name and user.email attached to your GitHub account and then execute the modified R code:\nusethis::use_git_config(user.name = \"Jane Git\", user.email = \"jane_git@gitrdone.com\")"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-personal-access-token-pat-for-github",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-personal-access-token-pat-for-github",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Creating a Personal Access Token (PAT) for GitHub",
    "text": "Creating a Personal Access Token (PAT) for GitHub\nYou will need a personal access token for making remote changes to GitHub.\nExecute the following R to create a token.\nusethis::create_github_token()\nAfter executing the code, you will be taken to your GitHub account (if you remained logged in). Go to the bottom of the page and click generate token. Copy it to the clipboard and save it someplace safe. Do not share your token with anyone because anyone who has it can access your public or private GitHub repositories.\nNote: Your PAT will expire after some duration, usually 30 days unless you change it. For this project, I suggest you change the expiration to a date after the semester ends."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#setting-your-git-credentials-using-pat",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#setting-your-git-credentials-using-pat",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Setting your Git Credentials (using PAT)",
    "text": "Setting your Git Credentials (using PAT)\nWe now need to set those credentials for RStudio to communicate with your GitHub account.\nExecute the following R code to set your credentials:\ngitcreds::gitcreds_set()\nYou will then paste your PAT here and press return/enter. If there are options, enter the number corresponding to the one that makes the more sense for what you are doing, like set or replace your credentials."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-version-control-project-in-rstudio",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#creating-a-version-control-project-in-rstudio",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Creating a Version Control Project in RStudio",
    "text": "Creating a Version Control Project in RStudio\n\nIn RStudio, File &gt; New Project &gt; Version Control &gt; Git.\nIn the pop-up, you will see a request for the “repository URL”. Paste the URL of the GitHub repository based on your liaison name. This URL will be the same as what you see on your GitHub account. However, we need to add .git to the end.\n\n    https://github.com/slicesofdata/dataviz23-stewart.git\n    https://github.com/slicesofdata/dataviz23-venglass.git\n    https://github.com/slicesofdata/dataviz23-lawson.git\n\nWhen you create the project, a directory will be created, a name will auto populate (e.g., ‘dataviz23-stewart’). If you change the name, name it something that you will know as your team project. In order to keep the class organized, I might suggest you create the project in your PSYC167 course directory. You should already have a R project for you homework called something like homework.Rproj in that course directory.\n\nNote: I recommend that you also select “Open in new session” in order to compartmentalize projects. When you work on the team project, open the project. When you work on your homework or other class exercises, open your homework project.\n\nClick “Create Project” to create the new project directory, which will create:\n\na project directory on your computer\na project file with file extension .Rproj\na Git repository or link to the remote GitHub repository for the project (also an RStudio Project)\n\n\nIf the repository already exists (and it does in this instance) you should see RStudio flash a connection to GitHub and likely pull the repo contents down to your newly-created project directory. You will see the directory structure and corresponding files. Your code files should be saved to /r, the data you read or save to /data, your RMarkdown report files to /report, etc.\nThese directories are there for project management purposes. Also, to maintain a clean project, create sub-directories within those directories as needed; create new directories if and only if its contents differ qualitatively from what is in the existing directories. Because the project report will need to be reproduced, don’t complicate your code by creating RMarkdown files for code used to perform some task when only code is needed. In those cases, use .R code script files. Use .Rmd files only for a report containing text and minor code. You cannot easily source() .Rmd files and creating them will be a a hassle to deal with later. Project organization is an element of the project."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#git-workflow-basics",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#git-workflow-basics",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Git Workflow Basics",
    "text": "Git Workflow Basics\nThere are three main parts to Git Workflow:\n\nMake local changes (in your working directory)\nStage changes (in your staging directory)\nCommit changes (to apply them for pushing to your remote repository)"
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#making-local-file-changes-committing-and-pushing-to-github",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#making-local-file-changes-committing-and-pushing-to-github",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Making Local File Changes, Committing, and Pushing to GitHub",
    "text": "Making Local File Changes, Committing, and Pushing to GitHub\n\nMaking a local change\n\nCreate a .R script and name it something like yourname.R. Save it to … you guessed it: /r.\n\nChecking the status of local file changes\n\nCheck for the local changes you have made at the Terminal by typing git status and press return/enter\n\n$ git status\n\nIf you made changes, Git will tell you what those changes are. For example, there will be a new file, a deleted file, a modified file, etc.\n\nStaging Changes (Add Changes)\n\nStage a specific change: If you made multiple changes and all you want to do is commit a single change and no others, you can specify the change you want to add. For example, if you want only to add a specific file, like yourname.R, you will use git add &lt;file&gt;... such that &lt;file&gt; refers to the file name.\n\nAt the Terminal prompt, type git add followed by &lt;file&gt; to include in what will be committed)\n$ git add r/yourname.R\n\nStage all change(s): When you make numerous changes, you may wish not to specify each file individually as that could be tedious. In this case, you may wish to stage all of your changes. Assuming everything you are doing is relevant to the project, one of the easiest ways to add changes is to just add all of your file changes. Note, your changes should not be done inside data files (e.g., .csv, .xlsx). Changes should only be done using R code. If not, your project will not be reproducible.\n\nAt the Terminal, you can type git add . which tells Git that you are adding all of those changes to commit them.\n$ git add .\n\n\nCommitting the change(s)\n\nNow that you made a change, you will commit it and assign a useful message to remind your future self and collaborators what you just did.\n\nAt the Terminal, type git commit to commit the changes, add -m to tell git you want a message, and then type the message as a string, \"my message here\" and then press enter/return to commit the changes.\n$ git commit -m \"added my first .R file\"\n\n\nPush the change to the remote repository\n\nWe need to push the changes to the remote GitHub repository for version control and for collaborators to access\n\nAt the Terminal, you will push those changes using git push and press enter/return to push.\n$ git push\n\nIf you navigate to your GitHub account in your web browser, you will see the changes there as soon as they arrive. Congrats!\n\nChanging, Committing, and Pushing Again\n\nOK, that file with your name is not needed for the project. Delete it from the project directory and then add the change, commit the change with message “deleted my silly file” and push changes.\nIf for some reason, your push did not work, you may need to specify the project branch. Branching is beyond the scope of this course. If team members are working on separate tasks, their code will be compartmentalized so you can use the main branch.\n\nYou can set the branch to the main branch at the Terminal using git branch -M main.\n$ git branch -M main\n\n\nPushing Specific File Changes\n\nYou should not push all of your edits. For example, if you edit a file and save it but it is incomplete (e.g., it contains errors) that will create problems for your team members, you do not want to push them to the repo. If you do, your team member’s code will also break if they are sourcing (e.g., source()) your script file. Similarly, if the data file you write out contains errors, a teammate cannot read that file in successfully. So make sure that what you push is correct and accurate before pushing.\n\nPulling Changes from the Remote\n\nThe opposite of push is pull. When your teammates push their changes (e.g., data cleaning, file creation, etc.) to the repo and your code depends on those files, you will want to make sure their edits are in your local project so that you can use them.\n\nTo pull the changes down to your project, at the Terminal, type git pull.\n$ git pull\n\nYou should find the changes appear in your local project directory."
  },
  {
    "objectID": "modules/001_installing_and_setting_up_git_and_github.html#other-resources",
    "href": "modules/001_installing_and_setting_up_git_and_github.html#other-resources",
    "title": "Installing and Setting Up Git and GitHub for R",
    "section": "Other Resources",
    "text": "Other Resources\n\nGit Clients: GitKraken\n\nIf you find the Terminal command line daunting or limiting, I might recommend a Git Client to use as I am not a big fan of the RStudio interface.\nGitKraken is a good option and they have lots of tutorials on their website. GitKraken is seamless to set up. Install, connect your GitHub account, select your repo to add, and voilà. You can stage, commit, and push from there.\n\nhappygitwithr"
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html",
    "href": "modules/01_installing_r_and_rstudio.html",
    "title": "Installing R & RStudio",
    "section": "",
    "text": "For this course, we will use the R programming language and the RStudio IDE for manipulating data and creating data visualizations."
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#tasks",
    "href": "modules/01_installing_r_and_rstudio.html#tasks",
    "title": "Installing R & RStudio",
    "section": "Tasks",
    "text": "Tasks\nThe first step is to install these pieces of software so that you can use them.\n\nDownload and Install R\nDownload and Install RStudio\nConfigure RStudio"
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#readings",
    "href": "modules/01_installing_r_and_rstudio.html#readings",
    "title": "Installing R & RStudio",
    "section": "Readings",
    "text": "Readings\n\nIntro to R\nWorking with RMarkdown"
  },
  {
    "objectID": "modules/01_installing_r_and_rstudio.html#install-r-first-and-then-install-rstudio.",
    "href": "modules/01_installing_r_and_rstudio.html#install-r-first-and-then-install-rstudio.",
    "title": "Installing R & RStudio",
    "section": "Install R first and then install RStudio.",
    "text": "Install R first and then install RStudio.\nInstalling should be easy and you can accept all of the defaults although the desktop icons are not needed, especially for R because you will never need it; RStudio will find R for you. You can follow these videos for simple installing.\nPC: How to Install R and R Studio on Windows 10/11\nMac: Installing R and RStudio on a Mac\nNote: If you leave the desktop icon for R, you can remove that later. You will never need it because RStudio will find R for you.\n##Additional Step for Mac Users:\nDownload and Install XQuartz\nSome functions in R require an “X11 Server” and/or libraries associated with an X11 server. Apple does not provide this software with OS X anymore so unfortunately you have to do it on your own via a third-party application called XQuartz for OS X 10.9 or later.\nUse the url below to download the XQuartz file and save it to your computer. Follow the same install instructions as above for installing the XQuartz file.\nFor macOS 10.9 or later, download this XQuartz file and save it to your computer and install: https://github.com/XQuartz/XQuartz/releases/download/XQuartz-2.8.5/XQuartz-2.8.5.pkg"
  },
  {
    "objectID": "modules/02_graphical_perception.html",
    "href": "modules/02_graphical_perception.html",
    "title": "Graphical perception",
    "section": "",
    "text": "In this module, we will address some aspects of how people perceive elements of data visualizations. You will likely learn that you are not as accurate as you might have thought at extracting data from visual representations. There will be illusions."
  },
  {
    "objectID": "modules/02_graphical_perception.html#readings",
    "href": "modules/02_graphical_perception.html#readings",
    "title": "Graphical perception",
    "section": "Readings",
    "text": "Readings\n\nLooking at Data"
  },
  {
    "objectID": "modules/02_graphical_perception.html#content-pending",
    "href": "modules/02_graphical_perception.html#content-pending",
    "title": "Graphical perception",
    "section": "Content Pending",
    "text": "Content Pending"
  },
  {
    "objectID": "modules/03_reading_data_files.html",
    "href": "modules/03_reading_data_files.html",
    "title": "Reading data files",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/03_reading_data_files.html#readings",
    "href": "modules/03_reading_data_files.html#readings",
    "title": "Reading data files",
    "section": "Readings",
    "text": "Readings\n\nR Workflow Basics\nGeneral Wrangling: Sections 5.1 up through 5.5"
  },
  {
    "objectID": "modules/03_reading_data_files.html#task",
    "href": "modules/03_reading_data_files.html#task",
    "title": "Reading data files",
    "section": "Task",
    "text": "Task\n\nCreate a GitHub account if you don’t have one (this may come in handy for projects and a blog if you want)"
  },
  {
    "objectID": "modules/03_reading_data_files.html#libraries",
    "href": "modules/03_reading_data_files.html#libraries",
    "title": "Reading data files",
    "section": "Libraries",
    "text": "Libraries\n\n{openxlsx} 4.2.5.2: for reading Excel spreadsheets from a URL\n{readxl} 1.4.3: for reading Excel spreadsheets\n{readr} 2.1.4: for reading .csv, .tsv, and .fwf files\n\nFirst, we need an .xlsx data file. You can obtain one locally or online from a URL."
  },
  {
    "objectID": "modules/03_reading_data_files.html#excel-files-from-a-url",
    "href": "modules/03_reading_data_files.html#excel-files-from-a-url",
    "title": "Reading data files",
    "section": "Excel files from a URL",
    "text": "Excel files from a URL\n{readxl} 1.4.3 lacks the ability to read the file from online. We can, however, read it using {openxlsx}. The problem is that you will only be able to read a the first sheet. If the first sheet is all you need, this can work. Pass the URL to openxlsx::read.xlsx() and assign it’s contents to an object named DAT using the assignment operator &lt;-.\n\nURL &lt;- \"https://github.com/slicesofdata/dataviz23/raw/main/data/cms-top-all-time-2023-swim.xlsx\"\n\nDAT &lt;- openxlsx::read.xlsx(URL, sheet = 1)\n\nWhat does the head of the data file look like?\n\nhead(DAT)\n\n   score              name year          event   team\n1 525.35       Maia Presti 2015 1-Meter Diving Athena\n2 514.70 Makenna Parkinson 2023 1-Meter Diving Athena\n3 512.05      Emma Ng Pack 2023 1-Meter Diving Athena\n4 494.95         Izzy Doud 2023 1-Meter Diving Athena\n5 462.15     Carli Lessard 2015 1-Meter Diving Athena\n6 447.70     Alexis Romero 2023 1-Meter Diving Athena\n\n\nJust an FYI, when you want a different worksheet you will need to pass a sheet name to the sheet argument. In this case, we saved it as part of the download process. Let’s pass sheet = \"swim\".\n\nhead(\n  openxlsx::read.xlsx(URL, sheet = \"swim\")\n)\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena"
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-excel-spreadsheets-with-readxl",
    "href": "modules/03_reading_data_files.html#reading-excel-spreadsheets-with-readxl",
    "title": "Reading data files",
    "section": "Reading Excel Spreadsheets with {readxl}",
    "text": "Reading Excel Spreadsheets with {readxl}\nWe will use the {readxl} library to handing reading of Excel files. Because Excel files can contain multiple sheets, one goal would be to find out the sheet names using readxl::excel_sheets (see ?readxl::excel_sheets). This function takes one argument, which is the path to the file. Passing the path will return the sheet names in that file. We can pass the path string directly into the function or if the file path is already saved as a object, pass that.\nIn order to read an Excel spreadsheet file, you will need to specify at very least file and if you want to read a specific sheet other than the first one, then you will need to specify sheet.\n\nfile: a path to the file, including the file name\nsheet: the sheet name to read\n\n\nGetting Sheet Names\nFirst, let’s assign the file path to an object because we will use this path a few times and we don’t want to keep typing it lest we make an error.\n\nfile_name &lt;- \"cms-top-all-time-2023-swim.xlsx\"\n\nWe can examine the worksheet names:\n\nreadxl::excel_sheets(path = here::here(\"data\", file_name))\n\n[1] \"diving\" \"swim\"   \"relay\" \n\n\nGreat, we know know the sheet names. The benefit of passing an object is that you you may wish to pass the path to another function, for example, to read a sheet from the file.\n\n\nReading a Sheet\nIn order to read a sheet, we will use readxl::read_excel(), which takes the file path as the first argument and the name of the desired sheet as the second argument. You might get away with passing only the path as long as your goal is to read the first sheet because this is the default action. Let’s wrap the function in head() to see the top.\n\nhead(\n  readxl::read_excel(here::here(\"data\", file_name))\n)\n\n# A tibble: 6 × 5\n  score  name              year  event          team  \n  &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt; \n1 525.35 Maia Presti       2015  1-Meter Diving Athena\n2 514.70 Makenna Parkinson 2023  1-Meter Diving Athena\n3 512.05 Emma Ng Pack      2023  1-Meter Diving Athena\n4 494.95 Izzy Doud         2023  1-Meter Diving Athena\n5 462.15 Carli Lessard     2015  1-Meter Diving Athena\n6 447.70 Alexis Romero     2023  1-Meter Diving Athena\n\n\nThe function also turns the file content into special object type knows as a data frame. A data frame is composed of row and column data. Sometimes data frames are messy but luckily we have a fairly clean file. You can verify using R’s built-in function is.data.frame(), which will return TRUE if it’s a data frame or FALSE if not. We will assign this to an object\n\nis.data.frame(readxl::read_excel(here::here(\"data\", file_name)))\n\n[1] TRUE\n\n\nBut we don’t want the first sheet. Pass sheet = \"swim\" to read that sheet. Also, let’s read in the data and assign it to an object called DAT which will hold the data frame.\n\nDAT &lt;- readxl::read_excel(here::here(\"data\", file_name), sheet = \"swim\")\n\nViewing the head of the data frame, we can see that it is composed of 5 column vectors representing variables with names: time, name, year, event, team.\n\nhead(DAT)\n\n# A tibble: 6 × 5\n  time  name             year  event   team  \n  &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n2 23.31 Ava Sealander    2022  50 FREE Athena\n3 23.49 Kelly Ngo        2016  50 FREE Athena\n4 23.71 Helen Liu        2014  50 FREE Athena\n5 23.76 Michele Kee      2014  50 FREE Athena\n6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n\n\nOK, that was fun. In order to demonstrate reading local .csv files, we will take a detour into saving files."
  },
  {
    "objectID": "modules/03_reading_data_files.html#managing-file-paths-with-here",
    "href": "modules/03_reading_data_files.html#managing-file-paths-with-here",
    "title": "Reading data files",
    "section": "Managing file paths with {here}",
    "text": "Managing file paths with {here}\nWhen downloading the file, you may have noticed using the {here} library. A discussion of the library was delayed at the time. We will now look a little deeper into how the library simplifies working with file paths within the context of the {readr}.\nWhat’s the best way to handle directories and file paths? Undoutedly, that is the {here} library, assuming of course you are smart enough to be using projects in RStudio. When you open a file from within a project, {here} will make the project directory the working directory. And if you are organized, your data files will be in a /data directory inside the project directory. When passing \"data\" as the first argument to here::here() ( e.g., here::here(\"data\"), you will see that the function returns a string containing the full path to the project directory plus the data subdirectory.\n\nhere::here(\"data\")\n\n[1] \"C:/Users/gcook/Sync/git/dataviz23/data\""
  },
  {
    "objectID": "modules/03_reading_data_files.html#a-workflow-side-note-on-strings",
    "href": "modules/03_reading_data_files.html#a-workflow-side-note-on-strings",
    "title": "Reading data files",
    "section": "A Workflow Side Note on Strings",
    "text": "A Workflow Side Note on Strings\nYou could avoid hard coding the change of the file extension in order to streamline you workflow. Every time to pass the path and the path changes you will need to change this by hand and doing so could be extremely annoying. For example, if you change the save location or the file name, you’ll need to make updates for all code referencing the path. To avoid potential headaches, we can instead use gsub() to examine a string, look for a pattern, and replace that pattern with another pattern. All we want to do is to change \".xlsx\" or \".xls\" in the string to \".csv\". And because we will next want to use this new name for reading later, let’s assign the change to a new string object, file_csv.\nFirst, let’s see what gsub() is doing.\n\ngsub(pattern = \".xlsx|.xls\",  \n     replacement = \".csv\", \n     x = file_name\n     )\n\n[1] \"cms-top-all-time-2023-swim.csv\"\n\n\nAssign to an object:\n\nfile_csv &lt;- gsub(\".xlsx|.xls\", \".csv\", file_name)\n\nNote: Code was simplified because the arguments were passed in the order expected by the gsub() function.\nSecond, pass the path object to write_csv():\n\nreadr::write_csv(x = DAT, \n                 file = here::here(\"data\", file_csv)\n                 )\n\nDid it save? Use file.exists().\n\nfile.exists(here::here(\"data\", file_csv))\n\n[1] TRUE\n\n\nRemember, all we have done is save the data frame. This new file will contain only the data from the spreadsheet that we read earlier. Before opening this new file, we need to take a detour on general handling of reading files with {readr}."
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-a-.csv-file-stored-on-a-website",
    "href": "modules/03_reading_data_files.html#reading-a-.csv-file-stored-on-a-website",
    "title": "Reading data files",
    "section": "Reading a .csv File Stored on a Website",
    "text": "Reading a .csv File Stored on a Website\nFor example, although the mtcars data is also a built-in data set in R, if it were a read actual .csv file save on some website, you can pass the URL path as the file. This file does exist on the {tidyverse} github for {readr}.\n\nreadr::read_csv(file = \"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nBecause file if the first argument of the function, you do not need to reference it specifically. Doing so just eliminates ambiguity for more complicated function calls. You will come across a lot of examples of code that do NOT reference the arguments by name.\n\nreadr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nBy default, readr::read_csv() tries to guess whether column/variable names are present. If you know they exist, you can set col_names = TRUE.\n\nreadr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\", col_names = T)\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\nIf the names are present and you set col_names = FALSE, you will get a mess because {readr} will assume the header row is data just as the rest of the file.\n\nreadr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\", col_names = F)\n\nRows: 33 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (11): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 33 × 11\n   X1    X2    X3    X4    X5    X6    X7    X8    X9    X10   X11  \n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 mpg   cyl   disp  hp    drat  wt    qsec  vs    am    gear  carb \n 2 21    6     160   110   3.9   2.62  16.46 0     1     4     4    \n 3 21    6     160   110   3.9   2.875 17.02 0     1     4     4    \n 4 22.8  4     108   93    3.85  2.32  18.61 1     1     4     1    \n 5 21.4  6     258   110   3.08  3.215 19.44 1     0     3     1    \n 6 18.7  8     360   175   3.15  3.44  17.02 0     0     3     2    \n 7 18.1  6     225   105   2.76  3.46  20.22 1     0     3     1    \n 8 14.3  8     360   245   3.21  3.57  15.84 0     0     3     4    \n 9 24.4  4     146.7 62    3.69  3.19  20    1     0     4     2    \n10 22.8  4     140.8 95    3.92  3.15  22.9  1     0     4     2    \n# ℹ 23 more rows\n\n\nAs you can see, the column names are all prefixed with “X” and the first row is now the name of the headers. names() or colnames() will return the column names, so we can apply it and see what happens. We will wrap readr::read_csv() in names(). See how this is a problem. You can use colnames() to test this too.\n\nnames(\n  readr::read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\", col_names = T)\n  )\n\nRows: 32 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\""
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-a-.csv-file-stored-locally-on-your-computer",
    "href": "modules/03_reading_data_files.html#reading-a-.csv-file-stored-locally-on-your-computer",
    "title": "Reading data files",
    "section": "Reading a .csv File Stored Locally on your Computer",
    "text": "Reading a .csv File Stored Locally on your Computer\nIf a file actually existed on your computer, the file would not be a URL but rather the path location to where the file is stored.\nAnd now we can read the locale file as before except we are not passing the string name but rather an object (e.g., file_csv) holding the file path and file name. Voilà.\n\nreadr::read_csv(here::here(\"data\", file_csv))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   team  \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows"
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-raw-data-that-is-comma-separated-e.g.-.csv",
    "href": "modules/03_reading_data_files.html#reading-raw-data-that-is-comma-separated-e.g.-.csv",
    "title": "Reading data files",
    "section": "Reading Raw Data that is Comma-Separated (e.g., .csv)",
    "text": "Reading Raw Data that is Comma-Separated (e.g., .csv)\nWe will file use readr::read_csv() to read our data file (viz., cms-top-all-time-2023-swim.csv).\n\nreadr::read_csv(here::here(\"data\", file_csv))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   team  \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nIf there were only data in the file and no names representing variables on the first row, the file might look like that below. We can imitate this by skipping the first row (containing names) using skip =.\n\nreadr::read_csv(here::here(\"data\", file_csv), skip = 1)\n\nRows: 439 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): 23.29, Jocelyn Crawford, 2019, 50 FREE, Athena\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 439 × 5\n   `23.29` `Jocelyn Crawford` `2019` `50 FREE` Athena\n   &lt;chr&gt;   &lt;chr&gt;              &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt; \n 1 23.31   Ava Sealander      2022   50 FREE   Athena\n 2 23.49   Kelly Ngo          2016   50 FREE   Athena\n 3 23.71   Helen Liu          2014   50 FREE   Athena\n 4 23.76   Michele Kee        2014   50 FREE   Athena\n 5 23.77   Natalia Orbach-M   2020   50 FREE   Athena\n 6 23.77   Suzia Starzyk      2020   50 FREE   Athena\n 7 23.87   Katie Bilotti      2010   50 FREE   Athena\n 8 23.93   Jenni Rinker       2011   50 FREE   Athena\n 9 24.02   Annika Sharma      2023   50 FREE   Athena\n10 51.05   Kelly Ngo          2016   100 FREE  Athena\n# ℹ 429 more rows\n\n\nSee how the first row is assumed to be names? Setting col_names = F will fix the problem. Putting the arguments on separate rows of R code might improve code legibility.\n\nreadr::read_csv(here::here(\"data\", file_csv), \n                skip = 1,\n                col_names = F\n                )\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): X1, X2, X3, X4, X5\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   X1    X2               X3    X4      X5    \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nBut we have no column names now. Setting col_names = will fix that. Use c() to combine 4 names, e.g., col_names = c(\"name1\", \"name2\", \"name3\", \"name4\").\n\nreadr::read_csv(here::here(\"data\", file_csv), \n                skip = 1,\n                col_names = c(\"time\", \"name\", \"year\", \"event\")\n                )\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, X5\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   X5    \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nIf you have column names that are on row 1 of the data frame, don’t skip that row and instead set col_names = TRUE to put them in place.\n\nreadr::read_csv(here::here(\"data\", file_csv), \n                col_names = T\n                )\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 440 × 5\n   time  name             year  event   team  \n   &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n 2 23.31 Ava Sealander    2022  50 FREE Athena\n 3 23.49 Kelly Ngo        2016  50 FREE Athena\n 4 23.71 Helen Liu        2014  50 FREE Athena\n 5 23.76 Michele Kee      2014  50 FREE Athena\n 6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n 7 23.77 Suzia Starzyk    2020  50 FREE Athena\n 8 23.87 Katie Bilotti    2010  50 FREE Athena\n 9 23.93 Jenni Rinker     2011  50 FREE Athena\n10 24.02 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nLuckily, we have both names and data in the file and by default readr::read_csv() does what we intend."
  },
  {
    "objectID": "modules/03_reading_data_files.html#reading-data-from-a-librarypackage",
    "href": "modules/03_reading_data_files.html#reading-data-from-a-librarypackage",
    "title": "Reading data files",
    "section": "Reading Data from a Library/Package",
    "text": "Reading Data from a Library/Package\nAs mentioned earlier, mtcars is a data set on cars which is also part of base R, meaning you do not need to read it from anyplace. R does this automatically.\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n# or \nprint(mtcars)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nUse names() to read the column names:\n\nnames(mtcars)\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\""
  },
  {
    "objectID": "modules/03_reading_data_files.html#object-assignment-using--",
    "href": "modules/03_reading_data_files.html#object-assignment-using--",
    "title": "Reading data files",
    "section": "Object Assignment using <-",
    "text": "Object Assignment using &lt;-\nYou will want to take the data frame object that is returned by the read.csv() function and assign it to an object of some name using the assignment operator &lt;- . Although the concept of assignment will be covered later, for now just understand that we need to make the data more accessible to work with. You could name the object anything you want. Let’s assign it to DAT standing for data frame and let’s make it ALL CAPS.\nA note about case: R is a case-sensitive language so object names like DAT, dat, DaT, etc. are possible and can refer to different objects depending on how you assign them. We will use capital letters only because I like to flag objects that are data frame as special and this approach makes them visually identifiable. You could choose your own convention for naming data frames, other objects, variables in data frames, etc. but I don’t recommend being random about it."
  },
  {
    "objectID": "modules/03_reading_data_files.html#using-read.table",
    "href": "modules/03_reading_data_files.html#using-read.table",
    "title": "Reading data files",
    "section": "Using read.table():",
    "text": "Using read.table():\nread.table() is a flexible function for reading files because you can specify how the data are separated in rows by setting the sep argument. A common separation is a comma but you might also have tabs or other special characters.\n\nDAT &lt;- read.table(file = here::here(\"data\", file_csv),\n                  sep = \",\",\n                  header = T\n                  )\n\nread.csv() is a specific case of read.table() that sets sep = \",\" for you so there is no need to pass the argument. read.csv() is the more common function you will come across for reading .csv files but read.table() works the same as long as you set the argument.\n\nDAT &lt;- read.csv(here::here(\"data\", file_csv))"
  },
  {
    "objectID": "modules/03_reading_data_files.html#using-read_csv-from-readr",
    "href": "modules/03_reading_data_files.html#using-read_csv-from-readr",
    "title": "Reading data files",
    "section": "Using read_csv() from {readr}:",
    "text": "Using read_csv() from {readr}:\nThere are advantages to using readr::read_csv() over read.csv(), which is why we will prefer it. We will assign it to an object named DAT2.\n\nDAT2 &lt;- readr::read_csv(here::here(\"data\", file_csv))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): time, name, year, event, team\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(DAT2)\n\n# A tibble: 6 × 5\n  time  name             year  event   team  \n  &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 23.29 Jocelyn Crawford 2019  50 FREE Athena\n2 23.31 Ava Sealander    2022  50 FREE Athena\n3 23.49 Kelly Ngo        2016  50 FREE Athena\n4 23.71 Helen Liu        2014  50 FREE Athena\n5 23.76 Michele Kee      2014  50 FREE Athena\n6 23.77 Natalia Orbach-M 2020  50 FREE Athena\n\n\nWe can test whether DAT and DAT2 are the same using a logical test ==. Notice the two =. If we use one =, we will actually assign the contents of DAT2 to DAT because a single = in this context (scope) will do the same as &lt;-. A discussion of the differences is beyond the scope here but suffice it so say &lt;- is the common practice except when you are writing custom functions. In most cases, assignment inside functions are done with = because objects created inside a function are not typically needed outside that scope.\nAnyway, you can see that the contents are the same even when files are read by different functions. This is wrapped in the all() function, which will return TRUE if everything is TRUE. This is good that the contents are identical.\n\nall(DAT == DAT2)\n\n[1] TRUE"
  },
  {
    "objectID": "modules/03_reading_data_files.html#data-as-a-data-frame",
    "href": "modules/03_reading_data_files.html#data-as-a-data-frame",
    "title": "Reading data files",
    "section": "Data as a Data Frame",
    "text": "Data as a Data Frame\nYou should see an object named DAT that contains the data frame with some swim data. If you want to verify this is actually a data frame object, you can pass the DAT object into the is.data.frame() function. The function will return TRUE if it is and FALSE if it is not.\n\nis.data.frame(DAT)\n\n[1] TRUE\n\nis.data.frame(DAT2)  # tibbles are also data frames\n\n[1] TRUE"
  },
  {
    "objectID": "modules/03_reading_data_files.html#are-they-both-tibbles",
    "href": "modules/03_reading_data_files.html#are-they-both-tibbles",
    "title": "Reading data files",
    "section": "Are they both tibbles?",
    "text": "Are they both tibbles?\nTibbles are different from data frames, see the {tibble} library.\n\ntibble::is_tibble(DAT)\n\n[1] FALSE\n\ntibble::is_tibble(DAT2)\n\n[1] TRUE\n\n\nNow the you have the data frame, you can examine some of its contents, for example, the first 6 rows using the head() function.\n\nhead(DAT)    # hmm, something seems off.\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena\n\n\nBecause header rows do exist atop the .csv file, specify that they exist by passing TRUE to the header argument of the function (e.g., header = TRUE or header = T).\n\nDAT &lt;- read.table(here::here(\"data\", file_csv),\n                  sep = \",\", \n                  header = TRUE\n                  )\n\nhead(DAT)    # Perfect!\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html",
    "title": "Data frame manipulation and wrangling",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#libraries",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#libraries",
    "title": "Data frame manipulation and wrangling",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{stringr}: 1.5.0: for working with strings\n{tidyselect}: 1.2.0: for selecting sets from strings"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#external-functions",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#external-functions",
    "title": "Data frame manipulation and wrangling",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#libraries-1",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#libraries-1",
    "title": "Data frame manipulation and wrangling",
    "section": "Libraries",
    "text": "Libraries\nWe will work with a few different libraries for data manipulation. Let’s load them into our work space using library().\n\nlibrary(magrittr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\n\nMake note of any warnings that appear when loading libraries. There are some libraries that contain functions with the same names. Be aware that the most recently loaded library function will take precedence. You can avoid confusion using :: to call a function from a particular library (e.g., libraryname::functionname())."
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#select-variables-starting-with-or-ending-with-certain-characters",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#select-variables-starting-with-or-ending-with-certain-characters",
    "title": "Data frame manipulation and wrangling",
    "section": "Select Variables Starting with or Ending with Certain Characters",
    "text": "Select Variables Starting with or Ending with Certain Characters\nOne thing about {dplyr}, when you load the library, there are functions from other libraries that are imported along with {dplyr}’s own functions. These important functions are designed to work with each other, so the people who maintain the libraries have packaged them up nicely so you don’t have to load separate libraries.\nMany of the functions are imported from the {tidyselect} library and these functions are what give you additional manipulation ability. Some imported functions are: all_of(), any_of(), contains(), ends_with(), everything(), last_col(), matches(), and starts_with().\nWith functions like starts_with(), contains(), and ends_with(), you can select variables with character patterns in their names.\nRather that passing the names of the variables as the second argument (e.g., c(\"Murder\", \"Assault\")), you would pass the helper function, say starts_with(). Whatever starts_with() returns is what gets passed to select() as the variables. This is what is referred to as functional programming. Rather than coding specifically what to do, you with utilize the task of another function to passed its returned object as an argument to another function.\nBut first, we need to see what these functions, like starts_with(), are doing. For more information, use ?starts_with.\nstarts_with(match, ignore.case = TRUE, vars = NULL)\nNotice the arguments we need to pass:\n\nmatch: A character vector\nignore.case: If TRUE, the default, ignores case when matching names. This is most flexible.\nvars: A character vector of variable names. If not supplied, the variables are taken from the current selection context (as established by functions like select() or pivot_longer()).\n\nLet’s just try out starts_with() on its own. Let’s set a required pattern match = some character and because vars = NULL by default, let’s just set vars = some character vector. Note that vars is not the second argument, so you will want to name it in the function call.\n\nstarts_with(match = \"a\", vars = c(\"Hello\", \"Hi\", \"Bye\"))\n\ninteger(0)\n\n\nReturns integer(0) which is speak for “there is no match”. Hmm, OK. Let’s try another character.\n\nstarts_with(match = \"b\", vars = c(\"Hello\", \"Hi\", \"Bye\"))\n\n[1] 3\n\n\nOK, so now an integer is returned (yes, try is.integer() if you don’t believe me).\n\nis.integer(starts_with(\"b\", vars = c(\"Hello\", \"Hi\", \"Bye\")))\n\n[1] TRUE\n\n\nImportantly, the value refers to the element index/position in the vars vector. Because the third string \"Bye\" starts with \"b\", that’s what is returned.\nTry something else:\n\nstarts_with(\"h\", vars = c(\"Hello\", \"Hi\", \"Bye\"))\n\n[1] 1 2\n\n\nNow a vector with length = 2 is returned, representing both the first and the second elements start with “h”.\n\nlength(starts_with(\"h\", vars = c(\"Hello\", \"Hi\", \"Bye\")))\n\n[1] 2\n\n\nSee, it’s really a vector containing the element(s) of the vars vector matching the pattern.\nAnd yes, this the letter casing is ignored because the default ignore.case = TRUE. Set to FALSE if you want your match to be case sensitive.\n\nstarts_with(\"h\", \n            vars = c(\"Hello\", \"Hi\", \"Bye\"), \n            ignore.case = F\n            )\n\ninteger(0)\n\n\nOK, no matches.\nYou will typically use starts_with() along with other functions. When using starts_with() in the context of select(), the vars argument is essentially passing vars = the names of the columns of the data frame passed to select().\nExample:\nselect(mydataframe,\n    starts_with(match = \"my pattern\",\n                vars = \"var names of mydataframe\")\n                )\nPassing the data frame into select() without piping it using %&gt;%:\n\nselect(USArrests, starts_with(\"m\")) %&gt;% head()\n\n           Murder\nAlabama      13.2\nAlaska       10.0\nArizona       8.1\nArkansas      8.8\nCalifornia    9.0\nColorado      7.9\n\n\nPiping the data frame into select():\n\nUSArrests %&gt;%\n  select(., starts_with(\"m\")) %&gt;% head()\n\n           Murder\nAlabama      13.2\nAlaska       10.0\nArizona       8.1\nArkansas      8.8\nCalifornia    9.0\nColorado      7.9\n\n\nAnother example:\n\nUSArrests %&gt;%\n  select(., ends_with(\"t\")) %&gt;% head()\n\n           Assault\nAlabama        236\nAlaska         263\nArizona        294\nArkansas       190\nCalifornia     276\nColorado       204"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-bybetween-index",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-bybetween-index",
    "title": "Data frame manipulation and wrangling",
    "section": "Selecting and Selecting Out Variables By/Between Index",
    "text": "Selecting and Selecting Out Variables By/Between Index\nThere are many approaches for selecting or selecting out column variables. You can pass multiple arguments for each specification or you can pass a single vector that contains all specifications.\n\nselect(., 1,2): select first and second columns\nselect(., c(1,2)): select first and second columns\nselect(., -c(1,2)): select out first and second columns\nselect(., 1:2): select first through second columns\nselect(., c(1:2)): select first through second columns\nselect(., -c(1:2)): select out first through second columns\n\nPotential Recommendation: use options utilizing c() to pass a vector because this habit will be more versatile with base R functionality. However, online solutions will likely not take this approach.\nLet’s make a data frame to work with first.\n\nDAT &lt;- data.frame(\n  Id  = c(100, 101, 102, 103, 104, 100, 105),\n  Sex = c('male', 'female', 'Male', NA, 'man', \"male\", \"neither\"),\n  Age = c(25, 33, 27, 40, 44, 25, 40),\n  Renting = c(\"yes\", NA, \"yes\", NA, \"no\", \"yes\", \"yes\")\n)\n\nSelect columns 1 and 2:\n\nDAT %&gt;%\n  select(., 1,2) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect columns 1 and 2 as a vector containing values 1 and 2:\n\nDAT %&gt;%\n  select(., c(1,2)) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect out columns 1 and 2 as a vector containing values 1 and 2:\n\nDAT %&gt;%\n  select(., -c(1,2)) \n\n  Age Renting\n1  25     yes\n2  33    &lt;NA&gt;\n3  27     yes\n4  40    &lt;NA&gt;\n5  44      no\n6  25     yes\n7  40     yes\n\n\nSelect from columns 1 to 2 using the : operator:\n\nDAT %&gt;%\n  select(., 1:2) \n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect from columns 1 through 3 using a vector containing the : operator:\n\nDAT %&gt;%\n  select(., c(1:3)) \n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect out columns 1 through 3 using a vector containing the : operator:\n\nDAT %&gt;%\n  select(., -c(1:3))   # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-by-or-between-character-name",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-by-or-between-character-name",
    "title": "Data frame manipulation and wrangling",
    "section": "Selecting and Selecting Out Variables By or Between Character Name",
    "text": "Selecting and Selecting Out Variables By or Between Character Name\nThese approaches are similar to those offered earlier except that some involve passing variables by their name (e.g., character names). Whereas the order of the variables in a data frame may move around, the names may be more stable or permanent, at least after you have cleaned up the names. Consequently, passing variables by name may be more foolproof.\nYou don’t have to be familiar with all approaches and you may settle on using one that makes the most sense to you.\n\nselect(., \"var1\", \"var2\")\nselect(., c(\"var1\", \"var2\"))\nselect(., -c(\"var1\", \"var2\"))\nselect(., var1:var2))\nselect(., c(\"var1\":\"var2))\nselect(., -c(\"var1\":\"var2))\n\nRecommendation: use options utilizing c() as this will be more versatile with base R functionality.\nThese approaches also work but they may lead to some confusion regarding usage of quotes:\n\nselect(., var1, var2)\nselect(., c(var1, var2))\nselect(., -c(var1, var2))\n\nSelect variables Id though Age using the : operator:\n\nDAT %&gt;%\n  select(., Id:Age) # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect variables Id though Age passed as strings using the : operator:\n\nDAT %&gt;%\n  select(., \"Id\":\"Age\") # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect variables Id though Age as a vector containing the variable names passed as strings and using the : operator:\n\nDAT %&gt;%\n  select(., c(\"Id\":\"Age\")) # select from here to there\n\n   Id     Sex Age\n1 100    male  25\n2 101  female  33\n3 102    Male  27\n4 103    &lt;NA&gt;  40\n5 104     man  44\n6 100    male  25\n7 105 neither  40\n\n\nSelect out variables Id though Age as a vector containing the variable names passed as strings and using the : operator:\n\nDAT %&gt;%\n  select(., -c(\"Id\":\"Age\"))   # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes\n\n\nYou can also use the ! operator to select NOT these variables (therefore, all others)\n\nDAT %&gt;%\n  select(., !c(\"Id\":\"Age\"))   # select out from here to there\n\n  Renting\n1     yes\n2    &lt;NA&gt;\n3     yes\n4    &lt;NA&gt;\n5      no\n6     yes\n7     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-characters-in-their-names",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-characters-in-their-names",
    "title": "Data frame manipulation and wrangling",
    "section": "Selecting and Selecting Out Variables Characters in Their Names",
    "text": "Selecting and Selecting Out Variables Characters in Their Names\n\nselect(., starts_with(\"characters\"))\nselect(., ends_with(\"characters\"))\nselect(., contains('e'))\n\nSelect variables which start with character “i”:\n\nDAT %&gt;% select(., starts_with('i'))\n\n   Id\n1 100\n2 101\n3 102\n4 103\n5 104\n6 100\n7 105\n\n\nSelect variables which DO NOT start with character “s”:\n\nDAT %&gt;% select(., -starts_with('s'))\n\n   Id Age Renting\n1 100  25     yes\n2 101  33    &lt;NA&gt;\n3 102  27     yes\n4 103  40    &lt;NA&gt;\n5 104  44      no\n6 100  25     yes\n7 105  40     yes\n\n\nSelect variables which end with character “e”:\n\nDAT %&gt;% select(., ends_with('e'))\n\n  Age\n1  25\n2  33\n3  27\n4  40\n5  44\n6  25\n7  40\n\n\nSelect variables which end with character “e”:\n\nDAT %&gt;% select(., -ends_with('e'))\n\n   Id     Sex Renting\n1 100    male     yes\n2 101  female    &lt;NA&gt;\n3 102    Male     yes\n4 103    &lt;NA&gt;    &lt;NA&gt;\n5 104     man      no\n6 100    male     yes\n7 105 neither     yes\n\n\nSelect variables which contain character “g”:\n\nDAT %&gt;% select(., contains('g'))\n\n  Age Renting\n1  25     yes\n2  33    &lt;NA&gt;\n3  27     yes\n4  40    &lt;NA&gt;\n5  44      no\n6  25     yes\n7  40     yes\n\n\nSelect variables which DO NOT contain character “g”:\n\nDAT %&gt;% select(., -contains('g'))\n\n   Id     Sex\n1 100    male\n2 101  female\n3 102    Male\n4 103    &lt;NA&gt;\n5 104     man\n6 100    male\n7 105 neither\n\n\nSelect variables containing a regular expression, use matches():\n.* will grab all names because it means any character and any number of times\n\nDAT %&gt;% select(., matches(\".*\"))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\n\\\\d will grab all variables containing a digit:\n\nDAT %&gt;% \n  mutate(., \n         var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) %&gt;%\n  select(., matches(\"\\\\d\"))\n\n  var_1 var_11 var_3 var1_var\n1     1      1     1        1\n2     1      1     1        1\n3     1      1     1        1\n4     1      1     1        1\n5     1      1     1        1\n6     1      1     1        1\n7     1      1     1        1\n\n\nv.*\\\\d will grab all variables that start with v and then contain any characters which are followed by a digit:\n\nDAT %&gt;% \n    mutate(., \n         var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) %&gt;%\n  select(., matches(\"v.*\\\\d\"))\n\n  var_1 var_11 var_3 var1_var\n1     1      1     1        1\n2     1      1     1        1\n3     1      1     1        1\n4     1      1     1        1\n5     1      1     1        1\n6     1      1     1        1\n7     1      1     1        1\n\n\n\\\\d$ will grab all variables ending in a digit ($ means end):\n\nDAT %&gt;% \n    mutate(., \n         var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) %&gt;%\n  select(., matches(\"\\\\d$\"))\n\n  var_1 var_11 var_3\n1     1      1     1\n2     1      1     1\n3     1      1     1\n4     1      1     1\n5     1      1     1\n6     1      1     1\n7     1      1     1\n\n\nYou can also negate all regular expression matches if you want to exclude:\n\nDAT %&gt;%\n      mutate(., \n         var_1    = 1,\n         var_11   = 1,\n         var_3    = 1,\n         var1_var = 1\n         ) %&gt;%\n  select(., -matches(\"\\\\d$\"))\n\n   Id     Sex Age Renting var1_var\n1 100    male  25     yes        1\n2 101  female  33    &lt;NA&gt;        1\n3 102    Male  27     yes        1\n4 103    &lt;NA&gt;  40    &lt;NA&gt;        1\n5 104     man  44      no        1\n6 100    male  25     yes        1\n7 105 neither  40     yes        1\n\n\nNote: The functions will return lowercase and uppercase variable name matches because the default behavior is ignore.case = TRUE. Set to FALSE if you want to perform precise surgery on the variables."
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-by-type",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#selecting-and-selecting-out-variables-by-type",
    "title": "Data frame manipulation and wrangling",
    "section": "Selecting and Selecting Out Variables by Type",
    "text": "Selecting and Selecting Out Variables by Type\nSelect variables that are numeric:\n\nDAT %&gt;% select(., where(is.numeric))\n\n   Id Age\n1 100  25\n2 101  33\n3 102  27\n4 103  40\n5 104  44\n6 100  25\n7 105  40\n\n\nSelect variables that are NOT numeric:\n\nDAT %&gt;% select(., -where(is.numeric))\n\n      Sex Renting\n1    male     yes\n2  female    &lt;NA&gt;\n3    Male     yes\n4    &lt;NA&gt;    &lt;NA&gt;\n5     man      no\n6    male     yes\n7 neither     yes\n\n\nSelect variables that are character:\n\nDAT %&gt;% select(., where(is.character))\n\n      Sex Renting\n1    male     yes\n2  female    &lt;NA&gt;\n3    Male     yes\n4    &lt;NA&gt;    &lt;NA&gt;\n5     man      no\n6    male     yes\n7 neither     yes\n\n\nSelect variables that are NOT character:\n\nDAT %&gt;% select(., -where(is.character))\n\n   Id Age\n1 100  25\n2 101  33\n3 102  27\n4 103  40\n5 104  44\n6 100  25\n7 105  40\n\n\nSelect variables that are logical (TRUE to FALSE):\n\nDAT %&gt;% select(., where(is.logical))\n\ndata frame with 0 columns and 7 rows\n\n\nSelect variables that are NOT logical (TRUE to FALSE):\n\nDAT %&gt;% select(., -where(is.logical))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#removing-duplicate-rows-using-distinct",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#removing-duplicate-rows-using-distinct",
    "title": "Data frame manipulation and wrangling",
    "section": "Removing duplicate rows using distinct()",
    "text": "Removing duplicate rows using distinct()\n\ndplyr::distinct(): remove duplicate rows\ndplyr::distinct(., column): remove duplicate rows by column\nna.omit(): remove any row with NA’s (missing values)\n\nLet’s use the simple DAT data frame.\n\nDAT # or with %&gt;% print() \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes\n\n\nNotice that rows 1 and 6 are the same person (e.g., Id) and have exactly the same data for all variables.\n\nDAT[1,] == DAT[6,]\n\n    Id  Sex  Age Renting\n1 TRUE TRUE TRUE    TRUE\n\n\nGreat that the rows are consistent but you don’t want their data twice. So let’s just remove any rows that are identical.\n\nDAT %&gt;%\n  distinct(.) #%&gt;%    # Remove exact duplicates\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 105 neither  40     yes\n\n\nIf you know each row is unique based on a variable in the data frame, you can also use distinct() to remove duplicates for a specific variable. Make sure that this variable specification is actually one that you would not want duplicates of.\n\nDAT %&gt;%             \n  distinct(., Id) # %&gt;% view_html(.) # Remove duplicates by variable; passes unique values for data frame\n\n   Id\n1 100\n2 101\n3 102\n4 103\n5 104\n6 105\n\n\nBut this function simply returns the unique values in Id. To retain the variables, set .keep_all = T. If you want to remove duplicates and assign the cleaned data frame to an object, you would likely want to keep all of your variables.\n\nDAT %&gt;%             \n  distinct(., Id, .keep_all = T) #%&gt;% view_html(.)\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 104     man  44      no\n6 105 neither  40     yes\n\n\nNotice, however, this only removed the last instance or Id == 100. Which row to include is a judgment call. The first, the last, neither, the average? Is there a correct answer?"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-using",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-using",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter Cases using ==",
    "text": "Filter Cases using ==\nFilter rows for which the Sex variable is equal to the string 'female':\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'female')\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nFilter rows for which the Sex variable is not equal to the string 'female':\n\nDAT %&gt;%\n  dplyr::filter(., Sex != 'female')\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nFilter rows for which the Sex variable is equal to the string 'female' AND Age is greater than the numeric 27:\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'female' & Age &gt; 27) # this \"AND\" that\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n\n\nFilter rows for which the Sex variable is equal to the string 'female' OR Age is greater than the numeric 27:\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'female' | Age &gt; 27) # this \"OR\" that\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 104     man  44      no\n4 105 neither  40     yes\n\n\nA cleaner method involves separate lines of code. Although cleaner, this will not allow the “OR” option because the data frame that is returned from the first filter() is passed to the second filter() and all cases other than \"female\" have already been removed from the data frame.\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'female') %&gt;%   # keep female (and add another pipe)\n  dplyr::filter(., Age &gt;= 27)             # keep only those equal to or older than 27\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-and-or-or",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-and-or-or",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by < and > or <= or >=…",
    "text": "Filter by &lt; and &gt; or &lt;= or &gt;=…\n\nDAT %&gt;% dplyr::filter(., Age &lt; 40)  # keep those less than \n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 102   Male  27     yes\n4 100   male  25     yes\n\nDAT %&gt;% dplyr::filter(., Age &gt; 40)  # keep older than\n\n   Id Sex Age Renting\n1 104 man  44      no\n\nDAT %&gt;% dplyr::filter(., Age &gt;= 40)  # keep equal to or older than\n\n   Id     Sex Age Renting\n1 103    &lt;NA&gt;  40    &lt;NA&gt;\n2 104     man  44      no\n3 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-by-conditional-x-or-y-using-operator",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-by-conditional-x-or-y-using-operator",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter Cases by Conditional X or Y Using | Operator…",
    "text": "Filter Cases by Conditional X or Y Using | Operator…\nUsing the “OR” operator, |, cases can be included if “this” OR “that” condition.\nFilter numbers:\n\nDAT %&gt;%\n  dplyr::filter(., Age == 25 | Age == 40)    # filter out numeric values IN a range\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 100    male  25     yes\n4 105 neither  40     yes\n\n\nFilter characters:\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'male' | Sex == 'female')\n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 100   male  25     yes\n\n\nAlthough dplyr::filter(sex %in% c('male', 'female')) would be easier.\nFilter rows of variables of both types:\n\nDAT %&gt;%\n  dplyr::filter(., Sex == 'male' | Age == 27)  \n\n   Id  Sex Age Renting\n1 100 male  25     yes\n2 102 Male  27     yes\n3 100 male  25     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-between-values-with-between",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-cases-between-values-with-between",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter Cases Between Values with between()",
    "text": "Filter Cases Between Values with between()\nBetween ages 25 and 33:\n\nDAT %&gt;%\n  dplyr::filter(., between(Age, 27, 33))\n\n   Id    Sex Age Renting\n1 101 female  33    &lt;NA&gt;\n2 102   Male  27     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-range-using-the-in-operator-this-is-in-meaning-in",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-range-using-the-in-operator-this-is-in-meaning-in",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by range using the %in% operator (this is IN meaning in)",
    "text": "Filter by range using the %in% operator (this is IN meaning in)\nThough less flexible than using between(), %in% may be easier to remember:\n\nDAT %&gt;%\n  dplyr::filter(., Age %in% 20:43)    # filter out numeric values IN a range\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nOne’s age is in the range from 20 through 43.\nIf a vector object is already defined (e.g., my_levels = c('male', 'female')), you can use that for filtering also. Such approaches are useful when data manipulation involves reusing a reference as it simplifies coding and reduces errors because the specification is defined only once.\n\nmy_levels = c('male', 'female')\n\nDAT %&gt;%\n  dplyr::filter(., Sex %in% my_levels)\n\n   Id    Sex Age Renting\n1 100   male  25     yes\n2 101 female  33    &lt;NA&gt;\n3 100   male  25     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-exclusion",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-exclusion",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by exclusion",
    "text": "Filter by exclusion\nWhen inclusion of variables is inappropriate, exclusion of them may be useful. The ! operator means “NOT” in R so you can use that to accomplish the opposite of the statement. For example, dplyr::filter(., !sex %in% c('male', NA)) will “filter the data frame to include rows in the sex column for which the value is NOT in the vector”.\nExclude rows in the Sex variable that are NA or 'male':\n\nDAT %&gt;%\n  dplyr::filter(., !Sex %in% c('male', NA))  # keep only if NOT in vector\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 102    Male  27     yes\n3 104     man  44      no\n4 105 neither  40     yes\n\n\nExclude rows in the Sex variable that are Men or 'male':\n\nDAT %&gt;%\n  dplyr::filter(., !Sex %in% c('male', 'Men'))  # keep only if NOT in vector\n\n   Id     Sex Age Renting\n1 101  female  33    &lt;NA&gt;\n2 102    Male  27     yes\n3 103    &lt;NA&gt;  40    &lt;NA&gt;\n4 104     man  44      no\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-conditional-x-and-y-using-operator",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-by-conditional-x-and-y-using-operator",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter by conditional X and Y using & operator…",
    "text": "Filter by conditional X and Y using & operator…\nBy range:\n\nDAT %&gt;%\n  dplyr::filter(., Id &gt;= 102 & Age &lt;= 43)    \n\n   Id     Sex Age Renting\n1 102    Male  27     yes\n2 103    &lt;NA&gt;  40    &lt;NA&gt;\n3 105 neither  40     yes\n\n\n\nDAT %&gt;%\n  dplyr::filter(., Age &gt;= 20 & Age &lt;= 43)    \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 103    &lt;NA&gt;  40    &lt;NA&gt;\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nNote: Age 20:43 won’t work. Can you figure out why?"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-na.omit",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-na.omit",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter using na.omit():",
    "text": "Filter using na.omit():\n\nDAT %&gt;%\n  na.omit(.) #%&gt;%     # omit any rows with NAs \n\n   Id     Sex Age Renting\n1 100    male  25     yes\n3 102    Male  27     yes\n5 104     man  44      no\n6 100    male  25     yes\n7 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-is.na-and-is.na",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-is.na-and-is.na",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter using is.na() and !is.na():",
    "text": "Filter using is.na() and !is.na():\n\nDAT %&gt;%\n  filter(., is.na(Sex))       # keep NAs by variable\n\n   Id  Sex Age Renting\n1 103 &lt;NA&gt;  40    &lt;NA&gt;\n\n\nBut your goal may likely be to keep everything that is not NA:\n\nDAT %&gt;%\n  filter(., !is.na(Sex))      # remove NAs by variable\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 101  female  33    &lt;NA&gt;\n3 102    Male  27     yes\n4 104     man  44      no\n5 100    male  25     yes\n6 105 neither  40     yes\n\n\nAnd filter step-by-step for each variable using %&gt;% and separate function calls:\n\nDAT %&gt;%\n  filter(., !is.na(Sex)) %&gt;%      \n  filter(., !is.na(Renting))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes\n\n\nSo why use separate lines of code if you can use & all in one line? One reason is that separate function calls written as separate lines of code make code inclusion/exclusion extremely easy.\nComment out what you don’t want using #:\n\nDAT %&gt;%\n  #filter(., !is.na(Sex)) %&gt;%      \n  filter(., !is.na(Renting))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-complete.cases",
    "href": "modules/04_data_frame_manipulation_and_wrangling.html#filter-using-complete.cases",
    "title": "Data frame manipulation and wrangling",
    "section": "Filter using complete.cases():",
    "text": "Filter using complete.cases():\nThe complete.cases() function returns a logical vector for which TRUE reflects the row has complete information and no missing cases. Using complete.cases() along with filter(), you would retain all rows TRUE rows.\n\nDAT %&gt;%\n  dplyr::filter(., complete.cases(.))\n\n   Id     Sex Age Renting\n1 100    male  25     yes\n2 102    Male  27     yes\n3 104     man  44      no\n4 100    male  25     yes\n5 105 neither  40     yes"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html",
    "href": "modules/07_data_subsets_and_summaries.html",
    "title": "Data subsets and summaries",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#readings",
    "href": "modules/07_data_subsets_and_summaries.html#readings",
    "title": "Data subsets and summaries",
    "section": "Readings",
    "text": "Readings"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#task",
    "href": "modules/07_data_subsets_and_summaries.html#task",
    "title": "Data subsets and summaries",
    "section": "Task",
    "text": "Task"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#libraries",
    "href": "modules/07_data_subsets_and_summaries.html#libraries",
    "title": "Data subsets and summaries",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{lubridate} 1.9.2: for handling date and time vectors"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#external-functions",
    "href": "modules/07_data_subsets_and_summaries.html#external-functions",
    "title": "Data subsets and summaries",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#libraries-1",
    "href": "modules/07_data_subsets_and_summaries.html#libraries-1",
    "title": "Data subsets and summaries",
    "section": "Libraries",
    "text": "Libraries\nWe will work with a few different libraries for data manipulation. Let’s load them into our work space using library().\n\nlibrary(magrittr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#creating-a-new-variable",
    "href": "modules/07_data_subsets_and_summaries.html#creating-a-new-variable",
    "title": "Data subsets and summaries",
    "section": "Creating a new variable",
    "text": "Creating a new variable\nWe will pass the data frame into mutate() and then specify a name-value variable pair. When using %&gt;%, the data frame piped into the function will be represented as .. This . is not needed but serves as a good reminder that the data frame that is passed into mutate() is from the previous line of code. In order to keep the print out manageable, we will also use the slice() function.\nmutate(data_frame, \n    new_variable_name = variable\n    )\nCreate new variables that are set to a constant number or string:\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., newvar1 = 9999) %&gt;%\n  mutate(., newvar2 = \"Student\") \n\n   time             name year   event   team newvar1 newvar2\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena    9999 Student\n2 23.31    Ava Sealander 2022 50 FREE Athena    9999 Student\n3 23.49        Kelly Ngo 2016 50 FREE Athena    9999 Student\n4 23.71        Helen Liu 2014 50 FREE Athena    9999 Student\n5 23.76      Michele Kee 2014 50 FREE Athena    9999 Student\n\n\nYou can see that each row in the data frame will take on the paired value."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#modifying-a-new-variable",
    "href": "modules/07_data_subsets_and_summaries.html#modifying-a-new-variable",
    "title": "Data subsets and summaries",
    "section": "Modifying a new variable",
    "text": "Modifying a new variable\nNew variables are modified using the same name-value pairing approach. When you modify a variable, you are taking an existing variable to setting it to another value.\n\nSet an existing variable equal to a constant\nJust use an existing variable name (left of = in name-value pair).\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., time = 1) %&gt;%\n  mutate(., name = \"0\") \n\n  time name year   event   team\n1    1    0 2019 50 FREE Athena\n2    1    0 2022 50 FREE Athena\n3    1    0 2016 50 FREE Athena\n4    1    0 2014 50 FREE Athena\n5    1    0 2014 50 FREE Athena\n\n\nOK, that’s not very helpful. We just replaced our existing variables with nothing useful. You can see that name is still a &lt;chr&gt; type.\n\n\nSet an existing variable equal to another value\nAs long as {dplyr} can result the character elements of the vector, as.numeric() will convert the character strings to numbers. For example:\n\nas.numeric(c(\"1\", \"3.2\", \"6.99\"))\n\n[1] 1.00 3.20 6.99\n\n\nWe can illustrate in a data frame by creating character value that will serve as the constant, and use as.numeric() just to illustrate this example.\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., name = as.numeric(\"0\")) \n\n   time name year   event   team\n1 23.29    0 2019 50 FREE Athena\n2 23.31    0 2022 50 FREE Athena\n3 23.49    0 2016 50 FREE Athena\n4 23.71    0 2014 50 FREE Athena\n5 23.76    0 2014 50 FREE Athena\n\n\nAnd now name is a &lt;dbl&gt;, which is a type of numeric. We can see this by selecting columns from the data frame where() the variable is.numeric().\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., name = as.numeric(\"0\")) %&gt;%\n  select(., where(~is.numeric(.)))\n\n  name\n1    0\n2    0\n3    0\n4    0\n5    0\n\n\nBut if we try to convert time to numeric this way, you will see that the complex numbers will be converted to NAs, or missing.\n\nas.numeric(DAT$time)\n\nWarning: NAs introduced by coercion\n\n\n  [1] 23.29 23.31 23.49 23.71 23.76 23.77 23.77 23.87 23.93 24.02 51.05 51.24\n [13] 51.41 51.56 51.56 51.88 52.05 52.05 52.14 52.17    NA    NA    NA    NA\n [25]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [37]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [49]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [61] 55.66 55.67 55.91 56.11 56.74 56.83 57.18 57.36 57.47 57.56    NA    NA\n [73]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [85]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n [97]    NA    NA    NA    NA 54.76 54.92 54.93 55.23 55.74 56.04 56.27 56.42\n[109] 56.47 56.56    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[121]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA 22.69 22.92\n[133] 22.93 22.95 23.27 23.31 23.33 23.38 23.45 23.47 50.65 50.67 50.92 51.19\n[145] 51.27 51.28 51.29 51.37 51.45 51.56    NA    NA    NA    NA    NA    NA\n[157]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[169]    NA    NA 25.94 26.22 26.28 26.57 26.82 26.90 27.14 27.14 27.16 27.17\n[181] 28.33 28.96 29.05 29.06 29.09 29.09 29.24 29.26 29.46 29.55 24.05 24.28\n[193] 24.58 24.59 24.65 24.85 25.05 25.08 25.24 25.34 54.65 54.81 54.91 55.11\n[205] 55.13 55.25 55.27 55.45 55.62 56.21    NA    NA    NA    NA    NA    NA\n[217]    NA    NA    NA    NA 19.98 20.21 20.22 20.36 20.51 20.65 20.69 20.71\n[229] 20.79 20.82 44.06 44.21 44.73 44.94 45.24 45.31 45.32 45.45 45.50 45.50\n[241]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[253]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[265]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[277]    NA    NA    NA    NA 46.99 47.57 49.32 49.97 50.03 50.29 50.35 50.41\n[289] 50.51 50.59    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[301] 54.88 55.80 55.92 56.03 56.27 56.35 56.36 56.45 56.49 56.49    NA    NA\n[313]    NA    NA    NA    NA    NA    NA    NA    NA 47.45 47.56 47.80 48.74\n[325] 48.91 49.26 49.31 49.34 49.68 49.74    NA    NA    NA    NA    NA    NA\n[337]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[349]    NA    NA 19.47 19.63 19.96 20.08 20.10 20.14 20.18 20.22 20.25 20.28\n[361] 43.28 43.69 43.74 44.43 44.57 44.59 44.81 44.81 44.83 44.87    NA    NA\n[373]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n[385]    NA    NA    NA    NA    NA    NA 22.32 22.50 22.84 23.00 23.24 23.45\n[397] 23.72 23.74 23.85 23.87 24.73 24.81 24.88 25.10 25.20 25.47 25.55 25.63\n[409] 26.01 26.05 20.60 21.38 21.48 21.58 21.60 21.81 21.83 22.00 22.06 22.07\n[421] 47.01 47.72 48.39 48.50 48.54 48.82 49.00 49.45 49.52 49.60 54.52 55.15\n[433] 55.21 55.47 55.62 56.04 56.13 56.19 56.35 56.48\n\n\nThe problem we have is that the data are not in a clean form. In this data frame, some elements of time are composed of numbers, decimals, and colons (e.g., x.xx, xx:xx.xx, etc.). which all make up elements that would be numbers.\n\n\nConverting variables that are time related using {lubridate}\n{lubridate} is a library for dealing with dates and times. It is also part of the tidyverse} ecosystem.\nThe period_to_seconds() function will convert periods to seconds depending on the period format. We need to pass to it an object that equates to a period of seconds.\nFor time, the format is: hour minute second (e.g., hms). And there is a hms() function to handle this. Let’s see how it works before modifying the data frame. Load the library if it is not loaded.\nWe will pass a single character string and convert it to hms with hms() and then convert that to seconds using period_to_seconds(). Because 60 minutes and 1 hour is the same number of seconds, we should end up with the same values. We can also use ms() to convert the format into minutes and seconds and pass to period_to_seconds(). Following the examples, we will apply to the vector in the data frame.\nlubridate::period_to_seconds(lubridate::ms())\nlubridate::period_to_seconds(lubridate::hms())\nSixty minutes and one hour to hms:\n\nlubridate::hms(\"00:60:00\")\n\n[1] \"60M 0S\"\n\nlubridate::hms(\"01:00:00\")\n\n[1] \"1H 0M 0S\"\n\n\nOne day to hms:\n\nhms(\"24:00:00\")\n\n[1] \"24H 0M 0S\"\n\n\nSixty minutes and one hour to hms to seconds:\n\nlubridate::period_to_seconds(lubridate::hms(\"00:60:00\"))\n\n[1] 3600\n\nlubridate::period_to_seconds(lubridate::hms(\"01:00:00\"))\n\n[1] 3600\n\n\nOK, good. So let’s see if we can convert time. Because hms() is passed into period_to_seconds(), we first need to verify that hms() can handle it.\n\nhms(DAT$time)\n\nWarning in .parse_hms(..., order = \"HMS\", quiet = quiet): Some strings failed\nto parse, or all strings are NAs\n\n\n  [1] NA            NA            NA            NA            NA           \n  [6] NA            NA            NA            NA            NA           \n [11] NA            NA            NA            NA            NA           \n [16] NA            NA            NA            NA            NA           \n [21] \"1H 50M 30S\"  \"1H 51M 89S\"  \"1H 52M 40S\"  \"1H 52M 55S\"  \"1H 52M 57S\" \n [26] \"1H 52M 67S\"  \"1H 52M 80S\"  \"1H 52M 83S\"  \"1H 52M 88S\"  \"1H 52M 89S\" \n [31] \"4H 57M 37S\"  \"4H 59M 22S\"  \"4H 59M 78S\"  \"5H 0M 6S\"    \"5H 0M 21S\"  \n [36] \"5H 0M 47S\"   \"5H 1M 17S\"   \"5H 1M 99S\"   \"5H 2M 16S\"   \"5H 2M 23S\"  \n [41] \"10H 14M 33S\" \"10H 15M 40S\" \"10H 22M 59S\" \"10H 22M 84S\" \"10H 24M 14S\"\n [46] \"10H 24M 82S\" \"10H 26M 34S\" \"10H 26M 89S\" \"10H 33M 15S\" \"10H 36M 60S\"\n [51] \"16H 58M 48S\" \"17H 3M 21S\"  \"17H 6M 78S\"  \"17H 9M 9S\"   \"17H 9M 26S\" \n [56] \"17H 12M 18S\" \"17H 12M 46S\" \"17H 13M 58S\" \"17H 21M 98S\" \"17H 24M 49S\"\n [61] NA            NA            NA            NA            NA           \n [66] NA            NA            NA            NA            NA           \n [71] \"1H 59M 91S\"  \"2H 2M 10S\"   \"2H 3M 73S\"   \"2H 3M 85S\"   \"2H 3M 92S\"  \n [76] \"2H 5M 10S\"   \"2H 5M 56S\"   \"2H 5M 71S\"   \"2H 5M 76S\"   \"2H 6M 13S\"  \n [81] \"1H 1M 84S\"   \"1H 3M 28S\"   \"1H 3M 51S\"   \"1H 3M 91S\"   \"1H 4M 16S\"  \n [86] \"1H 4M 19S\"   \"1H 4M 65S\"   \"1H 4M 66S\"   \"1H 4M 77S\"   \"1H 4M 94S\"  \n [91] \"2H 14M 83S\"  \"2H 15M 62S\"  \"2H 18M 99S\"  \"2H 19M 6S\"   \"2H 19M 78S\" \n [96] \"2H 20M 1S\"   \"2H 21M 17S\"  \"2H 21M 77S\"  \"2H 22M 34S\"  \"2H 22M 83S\" \n[101] NA            NA            NA            NA            NA           \n[106] NA            NA            NA            NA            NA           \n[111] \"2H 1M 84S\"   \"2H 2M 58S\"   \"2H 3M 80S\"   \"2H 4M 5S\"    \"2H 4M 42S\"  \n[116] \"2H 4M 81S\"   \"2H 6M 40S\"   \"2H 7M 12S\"   \"2H 7M 33S\"   \"2H 7M 42S\"  \n[121] \"2H 0M 69S\"   \"2H 3M 59S\"   \"2H 3M 79S\"   \"2H 4M 74S\"   \"2H 5M 41S\"  \n[126] \"2H 6M 82S\"   \"2H 7M 12S\"   \"2H 7M 14S\"   \"2H 7M 81S\"   \"2H 7M 94S\"  \n[131] NA            NA            NA            NA            NA           \n[136] NA            NA            NA            NA            NA           \n[141] NA            NA            NA            NA            NA           \n[146] NA            NA            NA            NA            NA           \n[151] \"1H 50M 91S\"  \"1H 50M 98S\"  \"1H 51M 39S\"  \"1H 51M 41S\"  \"1H 51M 56S\" \n[156] \"1H 51M 64S\"  \"1H 51M 95S\"  \"1H 52M 53S\"  \"1H 52M 78S\"  \"1H 53M 4S\"  \n[161] \"4H 15M 73S\"  \"4H 27M 18S\"  \"4H 30M 33S\"  \"4H 30M 77S\"  \"4H 31M 96S\" \n[166] \"4H 32M 45S\"  \"4H 32M 57S\"  \"4H 32M 68S\"  \"4H 34M 16S\"  \"4H 34M 27S\" \n[171] NA            NA            NA            NA            NA           \n[176] NA            NA            NA            NA            NA           \n[181] NA            NA            NA            NA            NA           \n[186] NA            NA            NA            NA            NA           \n[191] NA            NA            NA            NA            NA           \n[196] NA            NA            NA            NA            NA           \n[201] NA            NA            NA            NA            NA           \n[206] NA            NA            NA            NA            NA           \n[211] \"1H 1M 10S\"   \"1H 2M 88S\"   \"1H 2M 89S\"   \"1H 3M 67S\"   \"1H 4M 10S\"  \n[216] \"1H 4M 16S\"   \"1H 4M 24S\"   \"1H 4M 26S\"   \"1H 4M 35S\"   \"1H 4M 43S\"  \n[221] NA            NA            NA            NA            NA           \n[226] NA            NA            NA            NA            NA           \n[231] NA            NA            NA            NA            NA           \n[236] NA            NA            NA            NA            NA           \n[241] \"1H 38M 35S\"  \"1H 38M 88S\"  \"1H 39M 7S\"   \"1H 39M 35S\"  \"1H 39M 63S\" \n[246] \"1H 39M 80S\"  \"1H 39M 82S\"  \"1H 40M 30S\"  \"1H 40M 31S\"  \"1H 40M 50S\" \n[251] \"4H 25M 67S\"  \"4H 28M 11S\"  \"4H 28M 89S\"  \"4H 29M 32S\"  \"4H 31M 64S\" \n[256] \"4H 32M 52S\"  \"4H 32M 65S\"  \"4H 32M 94S\"  \"4H 32M 98S\"  \"4H 34M 70S\" \n[261] \"9H 14M 11S\"  \"9H 24M 43S\"  \"9H 35M 78S\"  \"9H 36M 64S\"  \"9H 39M 27S\" \n[266] \"9H 40M 2S\"   \"9H 41M 48S\"  \"9H 45M 72S\"  \"9H 46M 63S\"  \"9H 47M 9S\"  \n[271] \"15H 17M 24S\" \"15H 32M 19S\" \"15H 45M 57S\" \"15H 47M 40S\" \"15H 52M 94S\"\n[276] \"15H 53M 75S\" \"15H 56M 57S\" \"15H 57M 89S\" \"16H 2M 45S\"  \"16H 3M 38S\" \n[281] NA            NA            NA            NA            NA           \n[286] NA            NA            NA            NA            NA           \n[291] \"1H 45M 5S\"   \"1H 45M 67S\"  \"1H 46M 51S\"  \"1H 48M 84S\"  \"1H 49M 1S\"  \n[296] \"1H 49M 38S\"  \"1H 50M 32S\"  \"1H 50M 43S\"  \"1H 51M 7S\"   \"1H 51M 57S\" \n[301] NA            NA            NA            NA            NA           \n[306] NA            NA            NA            NA            NA           \n[311] \"1H 59M 90S\"  \"2H 1M 18S\"   \"2H 1M 45S\"   \"2H 1M 60S\"   \"2H 1M 66S\"  \n[316] \"2H 1M 77S\"   \"2H 1M 78S\"   \"2H 2M 89S\"   \"2H 3M 19S\"   \"2H 3M 23S\"  \n[321] NA            NA            NA            NA            NA           \n[326] NA            NA            NA            NA            NA           \n[331] \"1H 43M 96S\"  \"1H 48M 70S\"  \"1H 49M 24S\"  \"1H 49M 95S\"  \"1H 49M 96S\" \n[336] \"1H 50M 34S\"  \"1H 50M 47S\"  \"1H 50M 49S\"  \"1H 50M 51S\"  \"1H 50M 76S\" \n[341] \"1H 46M 97S\"  \"1H 48M 74S\"  \"1H 49M 74S\"  \"1H 50M 51S\"  \"1H 50M 78S\" \n[346] \"1H 51M 11S\"  \"1H 51M 24S\"  \"1H 51M 48S\"  \"1H 51M 82S\"  \"1H 51M 83S\" \n[351] NA            NA            NA            NA            NA           \n[356] NA            NA            NA            NA            NA           \n[361] NA            NA            NA            NA            NA           \n[366] NA            NA            NA            NA            NA           \n[371] \"1H 37M 98S\"  \"1H 38M 49S\"  \"1H 39M 9S\"   \"1H 39M 19S\"  \"1H 39M 66S\" \n[376] \"1H 40M 21S\"  \"1H 40M 22S\"  \"1H 40M 44S\"  \"1H 40M 70S\"  \"1H 40M 70S\" \n[381] \"3H 55M 61S\"  \"3H 56M 68S\"  \"3H 56M 88S\"  \"3H 59M 2S\"   \"3H 59M 13S\" \n[386] \"3H 59M 17S\"  \"4H 0M 63S\"   \"4H 1M 14S\"   \"4H 2M 38S\"   \"4H 2M 99S\"  \n[391] NA            NA            NA            NA            NA           \n[396] NA            NA            NA            NA            NA           \n[401] NA            NA            NA            NA            NA           \n[406] NA            NA            NA            NA            NA           \n[411] NA            NA            NA            NA            NA           \n[416] NA            NA            NA            NA            NA           \n[421] NA            NA            NA            NA            NA           \n[426] NA            NA            NA            NA            NA           \n[431] NA            NA            NA            NA            NA           \n[436] NA            NA            NA            NA            NA           \n\n\nYikes! Note the warning and look at the output. Some strings failed and turned to NA. Looking and the time vector again, we see that contains both values like 1:52.83 and 23.87. If there is only one :, we should be able to use ms().\n\nms(DAT$time)\n\n  [1] \"23M 29S\"    \"23M 31S\"    \"23M 49S\"    \"23M 71S\"    \"23M 76S\"   \n  [6] \"23M 77S\"    \"23M 77S\"    \"23M 87S\"    \"23M 93S\"    \"24M 2S\"    \n [11] \"51M 5S\"     \"51M 24S\"    \"51M 41S\"    \"51M 56S\"    \"51M 56S\"   \n [16] \"51M 88S\"    \"52M 5S\"     \"52M 5S\"     \"52M 14S\"    \"52M 17S\"   \n [21] \"1M 50.3S\"   \"1M 51.89S\"  \"1M 52.4S\"   \"1M 52.55S\"  \"1M 52.57S\" \n [26] \"1M 52.67S\"  \"1M 52.8S\"   \"1M 52.83S\"  \"1M 52.88S\"  \"1M 52.89S\" \n [31] \"4M 57.37S\"  \"4M 59.22S\"  \"4M 59.78S\"  \"5M 0.06S\"   \"5M 0.21S\"  \n [36] \"5M 0.47S\"   \"5M 1.17S\"   \"5M 1.99S\"   \"5M 2.16S\"   \"5M 2.23S\"  \n [41] \"10M 14.33S\" \"10M 15.4S\"  \"10M 22.59S\" \"10M 22.84S\" \"10M 24.14S\"\n [46] \"10M 24.82S\" \"10M 26.34S\" \"10M 26.89S\" \"10M 33.15S\" \"10M 36.6S\" \n [51] \"16M 58.48S\" \"17M 3.21S\"  \"17M 6.78S\"  \"17M 9.09S\"  \"17M 9.26S\" \n [56] \"17M 12.18S\" \"17M 12.46S\" \"17M 13.58S\" \"17M 21.98S\" \"17M 24.49S\"\n [61] \"55M 66S\"    \"55M 67S\"    \"55M 91S\"    \"56M 11S\"    \"56M 74S\"   \n [66] \"56M 83S\"    \"57M 18S\"    \"57M 36S\"    \"57M 47S\"    \"57M 56S\"   \n [71] \"1M 59.91S\"  \"2M 2.1S\"    \"2M 3.73S\"   \"2M 3.85S\"   \"2M 3.92S\"  \n [76] \"2M 5.1S\"    \"2M 5.56S\"   \"2M 5.71S\"   \"2M 5.76S\"   \"2M 6.13S\"  \n [81] \"1M 1.84S\"   \"1M 3.28S\"   \"1M 3.51S\"   \"1M 3.91S\"   \"1M 4.16S\"  \n [86] \"1M 4.19S\"   \"1M 4.65S\"   \"1M 4.66S\"   \"1M 4.77S\"   \"1M 4.94S\"  \n [91] \"2M 14.83S\"  \"2M 15.62S\"  \"2M 18.99S\"  \"2M 19.06S\"  \"2M 19.78S\" \n [96] \"2M 20.01S\"  \"2M 21.17S\"  \"2M 21.77S\"  \"2M 22.34S\"  \"2M 22.83S\" \n[101] \"54M 76S\"    \"54M 92S\"    \"54M 93S\"    \"55M 23S\"    \"55M 74S\"   \n[106] \"56M 4S\"     \"56M 27S\"    \"56M 42S\"    \"56M 47S\"    \"56M 56S\"   \n[111] \"2M 1.84S\"   \"2M 2.58S\"   \"2M 3.8S\"    \"2M 4.05S\"   \"2M 4.42S\"  \n[116] \"2M 4.81S\"   \"2M 6.4S\"    \"2M 7.12S\"   \"2M 7.33S\"   \"2M 7.42S\"  \n[121] \"2M 0.69S\"   \"2M 3.59S\"   \"2M 3.79S\"   \"2M 4.74S\"   \"2M 5.41S\"  \n[126] \"2M 6.82S\"   \"2M 7.12S\"   \"2M 7.14S\"   \"2M 7.81S\"   \"2M 7.94S\"  \n[131] \"22M 69S\"    \"22M 92S\"    \"22M 93S\"    \"22M 95S\"    \"23M 27S\"   \n[136] \"23M 31S\"    \"23M 33S\"    \"23M 38S\"    \"23M 45S\"    \"23M 47S\"   \n[141] \"50M 65S\"    \"50M 67S\"    \"50M 92S\"    \"51M 19S\"    \"51M 27S\"   \n[146] \"51M 28S\"    \"51M 29S\"    \"51M 37S\"    \"51M 45S\"    \"51M 56S\"   \n[151] \"1M 50.91S\"  \"1M 50.98S\"  \"1M 51.39S\"  \"1M 51.41S\"  \"1M 51.56S\" \n[156] \"1M 51.64S\"  \"1M 51.95S\"  \"1M 52.53S\"  \"1M 52.78S\"  \"1M 53.04S\" \n[161] \"4M 15.73S\"  \"4M 27.18S\"  \"4M 30.33S\"  \"4M 30.77S\"  \"4M 31.96S\" \n[166] \"4M 32.45S\"  \"4M 32.57S\"  \"4M 32.68S\"  \"4M 34.16S\"  \"4M 34.27S\" \n[171] \"25M 94S\"    \"26M 22S\"    \"26M 28S\"    \"26M 57S\"    \"26M 82S\"   \n[176] \"26M 90S\"    \"27M 14S\"    \"27M 14S\"    \"27M 16S\"    \"27M 17S\"   \n[181] \"28M 33S\"    \"28M 96S\"    \"29M 5S\"     \"29M 6S\"     \"29M 9S\"    \n[186] \"29M 9S\"     \"29M 24S\"    \"29M 26S\"    \"29M 46S\"    \"29M 55S\"   \n[191] \"24M 5S\"     \"24M 28S\"    \"24M 58S\"    \"24M 59S\"    \"24M 65S\"   \n[196] \"24M 85S\"    \"25M 5S\"     \"25M 8S\"     \"25M 24S\"    \"25M 34S\"   \n[201] \"54M 65S\"    \"54M 81S\"    \"54M 91S\"    \"55M 11S\"    \"55M 13S\"   \n[206] \"55M 25S\"    \"55M 27S\"    \"55M 45S\"    \"55M 62S\"    \"56M 21S\"   \n[211] \"1M 1.1S\"    \"1M 2.88S\"   \"1M 2.89S\"   \"1M 3.67S\"   \"1M 4.1S\"   \n[216] \"1M 4.16S\"   \"1M 4.24S\"   \"1M 4.26S\"   \"1M 4.35S\"   \"1M 4.43S\"  \n[221] \"19M 98S\"    \"20M 21S\"    \"20M 22S\"    \"20M 36S\"    \"20M 51S\"   \n[226] \"20M 65S\"    \"20M 69S\"    \"20M 71S\"    \"20M 79S\"    \"20M 82S\"   \n[231] \"44M 6S\"     \"44M 21S\"    \"44M 73S\"    \"44M 94S\"    \"45M 24S\"   \n[236] \"45M 31S\"    \"45M 32S\"    \"45M 45S\"    \"45M 50S\"    \"45M 50S\"   \n[241] \"1M 38.35S\"  \"1M 38.88S\"  \"1M 39.07S\"  \"1M 39.35S\"  \"1M 39.63S\" \n[246] \"1M 39.8S\"   \"1M 39.82S\"  \"1M 40.3S\"   \"1M 40.31S\"  \"1M 40.5S\"  \n[251] \"4M 25.67S\"  \"4M 28.11S\"  \"4M 28.89S\"  \"4M 29.32S\"  \"4M 31.64S\" \n[256] \"4M 32.52S\"  \"4M 32.65S\"  \"4M 32.94S\"  \"4M 32.98S\"  \"4M 34.7S\"  \n[261] \"9M 14.11S\"  \"9M 24.43S\"  \"9M 35.78S\"  \"9M 36.64S\"  \"9M 39.27S\" \n[266] \"9M 40.02S\"  \"9M 41.48S\"  \"9M 45.72S\"  \"9M 46.63S\"  \"9M 47.09S\" \n[271] \"15M 17.24S\" \"15M 32.19S\" \"15M 45.57S\" \"15M 47.4S\"  \"15M 52.94S\"\n[276] \"15M 53.75S\" \"15M 56.57S\" \"15M 57.89S\" \"16M 2.45S\"  \"16M 3.38S\" \n[281] \"46M 99S\"    \"47M 57S\"    \"49M 32S\"    \"49M 97S\"    \"50M 3S\"    \n[286] \"50M 29S\"    \"50M 35S\"    \"50M 41S\"    \"50M 51S\"    \"50M 59S\"   \n[291] \"1M 45.05S\"  \"1M 45.67S\"  \"1M 46.51S\"  \"1M 48.84S\"  \"1M 49.01S\" \n[296] \"1M 49.38S\"  \"1M 50.32S\"  \"1M 50.43S\"  \"1M 51.07S\"  \"1M 51.57S\" \n[301] \"54M 88S\"    \"55M 80S\"    \"55M 92S\"    \"56M 3S\"     \"56M 27S\"   \n[306] \"56M 35S\"    \"56M 36S\"    \"56M 45S\"    \"56M 49S\"    \"56M 49S\"   \n[311] \"1M 59.9S\"   \"2M 1.18S\"   \"2M 1.45S\"   \"2M 1.6S\"    \"2M 1.66S\"  \n[316] \"2M 1.77S\"   \"2M 1.78S\"   \"2M 2.89S\"   \"2M 3.19S\"   \"2M 3.23S\"  \n[321] \"47M 45S\"    \"47M 56S\"    \"47M 80S\"    \"48M 74S\"    \"48M 91S\"   \n[326] \"49M 26S\"    \"49M 31S\"    \"49M 34S\"    \"49M 68S\"    \"49M 74S\"   \n[331] \"1M 43.96S\"  \"1M 48.7S\"   \"1M 49.24S\"  \"1M 49.95S\"  \"1M 49.96S\" \n[336] \"1M 50.34S\"  \"1M 50.47S\"  \"1M 50.49S\"  \"1M 50.51S\"  \"1M 50.76S\" \n[341] \"1M 46.97S\"  \"1M 48.74S\"  \"1M 49.74S\"  \"1M 50.51S\"  \"1M 50.78S\" \n[346] \"1M 51.11S\"  \"1M 51.24S\"  \"1M 51.48S\"  \"1M 51.82S\"  \"1M 51.83S\" \n[351] \"19M 47S\"    \"19M 63S\"    \"19M 96S\"    \"20M 8S\"     \"20M 10S\"   \n[356] \"20M 14S\"    \"20M 18S\"    \"20M 22S\"    \"20M 25S\"    \"20M 28S\"   \n[361] \"43M 28S\"    \"43M 69S\"    \"43M 74S\"    \"44M 43S\"    \"44M 57S\"   \n[366] \"44M 59S\"    \"44M 81S\"    \"44M 81S\"    \"44M 83S\"    \"44M 87S\"   \n[371] \"1M 37.98S\"  \"1M 38.49S\"  \"1M 39.09S\"  \"1M 39.19S\"  \"1M 39.66S\" \n[376] \"1M 40.21S\"  \"1M 40.22S\"  \"1M 40.44S\"  \"1M 40.7S\"   \"1M 40.7S\"  \n[381] \"3M 55.61S\"  \"3M 56.68S\"  \"3M 56.88S\"  \"3M 59.02S\"  \"3M 59.13S\" \n[386] \"3M 59.17S\"  \"4M 0.63S\"   \"4M 1.14S\"   \"4M 2.38S\"   \"4M 2.99S\"  \n[391] \"22M 32S\"    \"22M 50S\"    \"22M 84S\"    \"23M 0S\"     \"23M 24S\"   \n[396] \"23M 45S\"    \"23M 72S\"    \"23M 74S\"    \"23M 85S\"    \"23M 87S\"   \n[401] \"24M 73S\"    \"24M 81S\"    \"24M 88S\"    \"25M 10S\"    \"25M 20S\"   \n[406] \"25M 47S\"    \"25M 55S\"    \"25M 63S\"    \"26M 1S\"     \"26M 5S\"    \n[411] \"20M 60S\"    \"21M 38S\"    \"21M 48S\"    \"21M 58S\"    \"21M 60S\"   \n[416] \"21M 81S\"    \"21M 83S\"    \"22M 0S\"     \"22M 6S\"     \"22M 7S\"    \n[421] \"47M 1S\"     \"47M 72S\"    \"48M 39S\"    \"48M 50S\"    \"48M 54S\"   \n[426] \"48M 82S\"    \"49M 0S\"     \"49M 45S\"    \"49M 52S\"    \"49M 60S\"   \n[431] \"54M 52S\"    \"55M 15S\"    \"55M 21S\"    \"55M 47S\"    \"55M 62S\"   \n[436] \"56M 4S\"     \"56M 13S\"    \"56M 19S\"    \"56M 35S\"    \"56M 48S\"   \n\n\nGreat! All elements are in the form of \"xxM XXs\". But does {lubridate} also convert seconds to a numeric value when using period_to_seconds()? If loaded, we can also remove the name of the library when calling the functions.\n\nis.numeric(period_to_seconds(ms(DAT$time)))\n\n[1] TRUE\n\n\nSo let’s go ahead and modify the character vector named time to a numeric vector representing seconds.\n\nperiod_to_seconds(ms(DAT$time))\n\n  [1] 1409.00 1411.00 1429.00 1451.00 1456.00 1457.00 1457.00 1467.00 1473.00\n [10] 1442.00 3065.00 3084.00 3101.00 3116.00 3116.00 3148.00 3125.00 3125.00\n [19] 3134.00 3137.00  110.30  111.89  112.40  112.55  112.57  112.67  112.80\n [28]  112.83  112.88  112.89  297.37  299.22  299.78  300.06  300.21  300.47\n [37]  301.17  301.99  302.16  302.23  614.33  615.40  622.59  622.84  624.14\n [46]  624.82  626.34  626.89  633.15  636.60 1018.48 1023.21 1026.78 1029.09\n [55] 1029.26 1032.18 1032.46 1033.58 1041.98 1044.49 3366.00 3367.00 3391.00\n [64] 3371.00 3434.00 3443.00 3438.00 3456.00 3467.00 3476.00  119.91  122.10\n [73]  123.73  123.85  123.92  125.10  125.56  125.71  125.76  126.13   61.84\n [82]   63.28   63.51   63.91   64.16   64.19   64.65   64.66   64.77   64.94\n [91]  134.83  135.62  138.99  139.06  139.78  140.01  141.17  141.77  142.34\n[100]  142.83 3316.00 3332.00 3333.00 3323.00 3374.00 3364.00 3387.00 3402.00\n[109] 3407.00 3416.00  121.84  122.58  123.80  124.05  124.42  124.81  126.40\n[118]  127.12  127.33  127.42  120.69  123.59  123.79  124.74  125.41  126.82\n[127]  127.12  127.14  127.81  127.94 1389.00 1412.00 1413.00 1415.00 1407.00\n[136] 1411.00 1413.00 1418.00 1425.00 1427.00 3065.00 3067.00 3092.00 3079.00\n[145] 3087.00 3088.00 3089.00 3097.00 3105.00 3116.00  110.91  110.98  111.39\n[154]  111.41  111.56  111.64  111.95  112.53  112.78  113.04  255.73  267.18\n[163]  270.33  270.77  271.96  272.45  272.57  272.68  274.16  274.27 1594.00\n[172] 1582.00 1588.00 1617.00 1642.00 1650.00 1634.00 1634.00 1636.00 1637.00\n[181] 1713.00 1776.00 1745.00 1746.00 1749.00 1749.00 1764.00 1766.00 1786.00\n[190] 1795.00 1445.00 1468.00 1498.00 1499.00 1505.00 1525.00 1505.00 1508.00\n[199] 1524.00 1534.00 3305.00 3321.00 3331.00 3311.00 3313.00 3325.00 3327.00\n[208] 3345.00 3362.00 3381.00   61.10   62.88   62.89   63.67   64.10   64.16\n[217]   64.24   64.26   64.35   64.43 1238.00 1221.00 1222.00 1236.00 1251.00\n[226] 1265.00 1269.00 1271.00 1279.00 1282.00 2646.00 2661.00 2713.00 2734.00\n[235] 2724.00 2731.00 2732.00 2745.00 2750.00 2750.00   98.35   98.88   99.07\n[244]   99.35   99.63   99.80   99.82  100.30  100.31  100.50  265.67  268.11\n[253]  268.89  269.32  271.64  272.52  272.65  272.94  272.98  274.70  554.11\n[262]  564.43  575.78  576.64  579.27  580.02  581.48  585.72  586.63  587.09\n[271]  917.24  932.19  945.57  947.40  952.94  953.75  956.57  957.89  962.45\n[280]  963.38 2859.00 2877.00 2972.00 3037.00 3003.00 3029.00 3035.00 3041.00\n[289] 3051.00 3059.00  105.05  105.67  106.51  108.84  109.01  109.38  110.32\n[298]  110.43  111.07  111.57 3328.00 3380.00 3392.00 3363.00 3387.00 3395.00\n[307] 3396.00 3405.00 3409.00 3409.00  119.90  121.18  121.45  121.60  121.66\n[316]  121.77  121.78  122.89  123.19  123.23 2865.00 2876.00 2900.00 2954.00\n[325] 2971.00 2966.00 2971.00 2974.00 3008.00 3014.00  103.96  108.70  109.24\n[334]  109.95  109.96  110.34  110.47  110.49  110.51  110.76  106.97  108.74\n[343]  109.74  110.51  110.78  111.11  111.24  111.48  111.82  111.83 1187.00\n[352] 1203.00 1236.00 1208.00 1210.00 1214.00 1218.00 1222.00 1225.00 1228.00\n[361] 2608.00 2649.00 2654.00 2683.00 2697.00 2699.00 2721.00 2721.00 2723.00\n[370] 2727.00   97.98   98.49   99.09   99.19   99.66  100.21  100.22  100.44\n[379]  100.70  100.70  235.61  236.68  236.88  239.02  239.13  239.17  240.63\n[388]  241.14  242.38  242.99 1352.00 1370.00 1404.00 1380.00 1404.00 1425.00\n[397] 1452.00 1454.00 1465.00 1467.00 1513.00 1521.00 1528.00 1510.00 1520.00\n[406] 1547.00 1555.00 1563.00 1561.00 1565.00 1260.00 1298.00 1308.00 1318.00\n[415] 1320.00 1341.00 1343.00 1320.00 1326.00 1327.00 2821.00 2892.00 2919.00\n[424] 2930.00 2934.00 2962.00 2940.00 2985.00 2992.00 3000.00 3292.00 3315.00\n[433] 3321.00 3347.00 3362.00 3364.00 3373.00 3379.00 3395.00 3408.00\n\n\nPerfect! Let’s mutate() that variable in the data frame.\n\nDAT %&gt;%\n  slice(., 1:5) %&gt;%   # rows 1 through 5\n  mutate(., time = period_to_seconds(ms(time)))  \n\n  time             name year   event   team\n1 1409 Jocelyn Crawford 2019 50 FREE Athena\n2 1411    Ava Sealander 2022 50 FREE Athena\n3 1429        Kelly Ngo 2016 50 FREE Athena\n4 1451        Helen Liu 2014 50 FREE Athena\n5 1456      Michele Kee 2014 50 FREE Athena\n\n\nLet’s look at DAT now and see those seconds. You can look at the entire data frame if you wish rather than its head().\n\nhead(DAT)\n\n   time             name year   event   team\n1 23.29 Jocelyn Crawford 2019 50 FREE Athena\n2 23.31    Ava Sealander 2022 50 FREE Athena\n3 23.49        Kelly Ngo 2016 50 FREE Athena\n4 23.71        Helen Liu 2014 50 FREE Athena\n5 23.76      Michele Kee 2014 50 FREE Athena\n6 23.77 Natalia Orbach-M 2020 50 FREE Athena\n\n\nThe data frame has not changed. The final step is to assign assign the returned data frame to an object. Remove the slice() so we get the entire data frame.\n\nDAT &lt;- DAT %&gt;%\n  mutate(., time = period_to_seconds(ms(time)))  \n\nNow let’s write this to /data. But we don’t want to overwrite this file. {here} won’t be as effective but we can concatenate the file_name string object with a prefix like \"cleaned\" using the paste() function in base R. We will add a hyphen, -, by passing it to the sep argument.\n\npaste(\"cleaned\", file_name, sep = \"-\")\n\n[1] \"cleaned-cms-top-all-time-2023-swim.xlsx\"\n\n\nWhen paired with here::here(), does the full file path look right?\n\nhere::here(\"data\", paste(\"cleaned\", file_name, sep = \"-\"))\n\n[1] \"C:/Users/gcook/Sync/git/dataviz23/data/cleaned-cms-top-all-time-2023-swim.xlsx\"\n\n\nWe also want to write a .csv file. Let’s use gsub() to look or the string pattern \".xlxs\" and replace it with \".csv\" for the file path string.\n\nnew_name &lt;- gsub(pattern = \".xlsx\", \n                 replacement = \".csv\", \n                 x = here::here(\"data\", paste(\"cleaned\", file_name, sep = \"-\"))\n                 )\n\nGot our new file name! Let’s write!\n\nreadr::write_csv(DAT, new_name)\n\nDone!"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarize-across-by-numeric-variables",
    "href": "modules/07_data_subsets_and_summaries.html#summarize-across-by-numeric-variables",
    "title": "Data subsets and summaries",
    "section": "Summarize across by numeric variables:",
    "text": "Summarize across by numeric variables:\n\nDAT %&gt;%\n  summarise(., across(.cols = where(is.numeric), \n                      .fns  = ~mean(.x, na.rm = TRUE))\n            )\n\n      time\n1 1309.388\n\n\nWell, that’s now actually impressive because there is only one numeric variable. What if we had more that were piped to summarize()?\n\nDAT %&gt;%\n  mutate(., \n         num1 = time,\n         num2 = time,\n         num3 = time\n         ) %&gt;%\n  summarise(., across(.cols = where(is.numeric), \n                      .fns  = ~mean(.x, na.rm = TRUE))\n            )\n\n      time     num1     num2     num3\n1 1309.388 1309.388 1309.388 1309.388\n\n\nThat was easy.\nBecause across() is so powerful, let’s just add another variable to the data frame for using in examples. You might also wish to reorder the position of variables in the data frame so that they are grouped in some way. We can use dplyr::relocate() to accomplish this. We will move the time column to the position .before one of the new variables using relocate(., time, .before = min).\nDoing so will also show you some ways to create variables.\n\nDAT &lt;- DAT %&gt;%\n  mutate(., \n         sec = time,  # will be redundant with time but named accurately\n         min  = time/60,\n         hour = time/(60*60)\n         ) %&gt;%\n  relocate(., time, .before = sec)\n\nTake a look:\n\nhead(DAT)\n\n              name year   event   team time  sec      min      hour\n1 Jocelyn Crawford 2019 50 FREE Athena 1409 1409 23.48333 0.3913889\n2    Ava Sealander 2022 50 FREE Athena 1411 1411 23.51667 0.3919444\n3        Kelly Ngo 2016 50 FREE Athena 1429 1429 23.81667 0.3969444\n4        Helen Liu 2014 50 FREE Athena 1451 1451 24.18333 0.4030556\n5      Michele Kee 2014 50 FREE Athena 1456 1456 24.26667 0.4044444\n6 Natalia Orbach-M 2020 50 FREE Athena 1457 1457 24.28333 0.4047222\n\n\nVariable names created with across() is controlled using the .names argument. The default is equivalent to .names = {.col}, which means that the name(s) are inherited from the .cols argument; the names are a stand-in for the name specification. If you wish to have control over the names, you can pass a string that that either appends (e.g.,\"{.col}suffix\") or prepends (e.g.,\"prefix{.col}\") a string to each column name. This string looks odd because it’s a special glue specification that glues together with a string with an object. We will use this concept later when using the {glue} library.\nWhen modifying .names, include a character like \"_\" (e.g.,\"{.col}_suffix\") so that the column names and the appended text are separated, making the name easily legible. If you summarize to create means, a good suggestion is something like (e.g.,\"{.col}_mean\" or (e.g.,\"{.col}_mn\")) so that you know the variable is a mean. If you prefer the function name first, you can use a prefix (e.g.,\"mean_{.col}\").\n\nDAT %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\", \"hour\"), \n                      .fns  = ~mean(.x, na.rm = TRUE),\n                      .names = \"{.col}_mean\"\n                      )\n            )\n\n  sec_mean min_mean hour_mean\n1 1309.388 21.82313 0.3637189\n\n\nYou can see how all variables in the summary end in \"_mean\".\nYou can also glue the function and the column names together by passing .names = \"{.col}_{.fn}\".\n\nDAT %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\", \"hour\"), \n                      .fns  = ~mean(.x, na.rm = TRUE),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            )\n\n     sec_1    min_1    hour_1\n1 1309.388 21.82313 0.3637189\n\n\nYou you will see there is a number that is appended to the variable name. This is because there is only one function passed to .fns. You can pass more using a special object called a list (see ?list). Unlike vectors, elements of lists need not be the same kind. Elements of lists can combinations of characters, numbers, data frames, functions, etc."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#passing-multiple-functions-from-a-list-in-across",
    "href": "modules/07_data_subsets_and_summaries.html#passing-multiple-functions-from-a-list-in-across",
    "title": "Data subsets and summaries",
    "section": "Passing multiple functions from a list() in across()",
    "text": "Passing multiple functions from a list() in across()\nPassing functions as a list requires a little fancy coding. We will pass two functions as a list so that we can calculate both the mean() and the sd() on the variables passed to across().\nA list is a special object (e.g., container) for which its elements can be different types of objects. Whereas elements of vectors can be only character or only numeric, elements of lists can hold different object. One element can be a numeric vector, another element a data frame, another element a character vector, etc. Many functions used in R will actually return lists for which elements contain different types of objects.\nOK back to two or more functions. If you pass a list() with arguments for the mean and the sd (e.g., list(mean, sd), you can summarize by both. If you want to prevent errors (yes you do) and want to keep the summaries separate (probably so), you can modify .names to pass both the column and the function (e.g., \"{.col}_{.fn}\"). The underscore is not needed here; it only helps with readability of the variables so that you don’t end up with variable names like var1mean but instead var1_mean.\nLet’s pass the summary procedures as a list to include measures of mean and standard deviation for the variables.\n\nDAT %&gt;%\n  summarise(., across(.cols  = c(\"sec\", \"min\", \"hour\"), \n                      .fns   = list(mean, sd),\n                      .names = \"{.col}_{.fn}\")\n            )\n\n     sec_1    sec_2    min_1    min_2    hour_1    hour_2\n1 1309.388 1225.964 21.82313 20.43274 0.3637189 0.3405456\n\n\nWell those are not exactly the names we want but it illustrates how names are created. Because we have two summary functions for each column variable passed to across(), they are enumerated according to the order in the list (e.g., mean then standard deviation).\n\nFixing .names when passing lists to .cols in across()\nEnumeration is not helpful for remembering variable names. There are different ways to do fix this problem, some of which may be better under certain scenarios. You have to determine what approach is best but I’ll lay out some limitations. If you pass only the functions into the list, then when you pass {.fn} to .names, the variable names in the returned data frame will take on a numeric value representing the order/element position of the functions as you entered them in the list. In this coding instance, means would be named with\"_1\" and standard deviation names with \"_2\". This approach, however, leads to confusing variable names because you have to remember which is 1 and which is 2 and of course explain this to anyone with whom you share the data. Let’s take a look.\nA better approach could be to assign the mean and sd functions their own names in the list() function call. By doing so, the name is appended and the new variable is named meaningfully.\nLet’s modify what we pass to .fns by passing a list containing 3 functions (e.g., mean(), sd(), and length()) and give each there name. I know this part is confusing because the () are dropped inside the list. This is just how R works. Don’t blame the messenger.\n\nDAT %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\", \"hour\"), \n                      .fns  = list(mean = mean, \n                                   sd = sd,\n                                   n = length\n                                   ),\n                      .names = \"{.col}_{.fn}\")\n            )\n\n  sec_mean   sec_sd sec_n min_mean   min_sd min_n hour_mean   hour_sd hour_n\n1 1309.388 1225.964   440 21.82313 20.43274   440 0.3637189 0.3405456    440\n\n\nImportantly, however, certain functions like mean() will operate in ways you might not expect. One one hand, it does what we expect when all elements can be used to calculate the mean.\n\nmean(DAT$time)\n\n[1] 1309.388\n\n\nOn the other hand, if there is a missing value, it does not computer the mean but instead something else. Let’s add an NA to the vector using c() to see what happens.\n\nmean(c(DAT$time, NA))\n\n[1] NA\n\n\n\nUnderstanding NAs when passing lists to .cols in across()\nThe mean() function returns NA rather than a mean. If there is just one NA, mean() returns NA. By design this is actually good.\nLet’s also try sd() for the standard deviation of a vector:\n\nsd(c(DAT$time, NA))\n\n[1] NA\n\n\nThe median of a vector, median():\n\nmedian(c(DAT$time, NA))\n\n[1] NA\n\n\nThe length of a vector, length():\n\nlength(c(DAT$time, NA))\n\n[1] 441\n\n\nWell, that’s interesting. By default length() will return the number of elements of the vector including NAs but by default mean() will not return the mean of a vector with NAs because na.rm = FALSE by default. If you wish to calculate the mean by removing the NAs, pass na.rm = TRUE.\n\nmean(c(DAT$time, NA), na.rm = T)\n\n[1] 1309.388\n\n\nMake note, however, that the length of this vector without NAs is shorter than the length with NAs. We can test this hypothesis on a vector with and without the NA by using na.omit() to omit any of them. Using our vector we added an NA, let’s omit it.\n\nna.omit(c(DAT$time, NA))\n\n  [1] 1409.00 1411.00 1429.00 1451.00 1456.00 1457.00 1457.00 1467.00 1473.00\n [10] 1442.00 3065.00 3084.00 3101.00 3116.00 3116.00 3148.00 3125.00 3125.00\n [19] 3134.00 3137.00  110.30  111.89  112.40  112.55  112.57  112.67  112.80\n [28]  112.83  112.88  112.89  297.37  299.22  299.78  300.06  300.21  300.47\n [37]  301.17  301.99  302.16  302.23  614.33  615.40  622.59  622.84  624.14\n [46]  624.82  626.34  626.89  633.15  636.60 1018.48 1023.21 1026.78 1029.09\n [55] 1029.26 1032.18 1032.46 1033.58 1041.98 1044.49 3366.00 3367.00 3391.00\n [64] 3371.00 3434.00 3443.00 3438.00 3456.00 3467.00 3476.00  119.91  122.10\n [73]  123.73  123.85  123.92  125.10  125.56  125.71  125.76  126.13   61.84\n [82]   63.28   63.51   63.91   64.16   64.19   64.65   64.66   64.77   64.94\n [91]  134.83  135.62  138.99  139.06  139.78  140.01  141.17  141.77  142.34\n[100]  142.83 3316.00 3332.00 3333.00 3323.00 3374.00 3364.00 3387.00 3402.00\n[109] 3407.00 3416.00  121.84  122.58  123.80  124.05  124.42  124.81  126.40\n[118]  127.12  127.33  127.42  120.69  123.59  123.79  124.74  125.41  126.82\n[127]  127.12  127.14  127.81  127.94 1389.00 1412.00 1413.00 1415.00 1407.00\n[136] 1411.00 1413.00 1418.00 1425.00 1427.00 3065.00 3067.00 3092.00 3079.00\n[145] 3087.00 3088.00 3089.00 3097.00 3105.00 3116.00  110.91  110.98  111.39\n[154]  111.41  111.56  111.64  111.95  112.53  112.78  113.04  255.73  267.18\n[163]  270.33  270.77  271.96  272.45  272.57  272.68  274.16  274.27 1594.00\n[172] 1582.00 1588.00 1617.00 1642.00 1650.00 1634.00 1634.00 1636.00 1637.00\n[181] 1713.00 1776.00 1745.00 1746.00 1749.00 1749.00 1764.00 1766.00 1786.00\n[190] 1795.00 1445.00 1468.00 1498.00 1499.00 1505.00 1525.00 1505.00 1508.00\n[199] 1524.00 1534.00 3305.00 3321.00 3331.00 3311.00 3313.00 3325.00 3327.00\n[208] 3345.00 3362.00 3381.00   61.10   62.88   62.89   63.67   64.10   64.16\n[217]   64.24   64.26   64.35   64.43 1238.00 1221.00 1222.00 1236.00 1251.00\n[226] 1265.00 1269.00 1271.00 1279.00 1282.00 2646.00 2661.00 2713.00 2734.00\n[235] 2724.00 2731.00 2732.00 2745.00 2750.00 2750.00   98.35   98.88   99.07\n[244]   99.35   99.63   99.80   99.82  100.30  100.31  100.50  265.67  268.11\n[253]  268.89  269.32  271.64  272.52  272.65  272.94  272.98  274.70  554.11\n[262]  564.43  575.78  576.64  579.27  580.02  581.48  585.72  586.63  587.09\n[271]  917.24  932.19  945.57  947.40  952.94  953.75  956.57  957.89  962.45\n[280]  963.38 2859.00 2877.00 2972.00 3037.00 3003.00 3029.00 3035.00 3041.00\n[289] 3051.00 3059.00  105.05  105.67  106.51  108.84  109.01  109.38  110.32\n[298]  110.43  111.07  111.57 3328.00 3380.00 3392.00 3363.00 3387.00 3395.00\n[307] 3396.00 3405.00 3409.00 3409.00  119.90  121.18  121.45  121.60  121.66\n[316]  121.77  121.78  122.89  123.19  123.23 2865.00 2876.00 2900.00 2954.00\n[325] 2971.00 2966.00 2971.00 2974.00 3008.00 3014.00  103.96  108.70  109.24\n[334]  109.95  109.96  110.34  110.47  110.49  110.51  110.76  106.97  108.74\n[343]  109.74  110.51  110.78  111.11  111.24  111.48  111.82  111.83 1187.00\n[352] 1203.00 1236.00 1208.00 1210.00 1214.00 1218.00 1222.00 1225.00 1228.00\n[361] 2608.00 2649.00 2654.00 2683.00 2697.00 2699.00 2721.00 2721.00 2723.00\n[370] 2727.00   97.98   98.49   99.09   99.19   99.66  100.21  100.22  100.44\n[379]  100.70  100.70  235.61  236.68  236.88  239.02  239.13  239.17  240.63\n[388]  241.14  242.38  242.99 1352.00 1370.00 1404.00 1380.00 1404.00 1425.00\n[397] 1452.00 1454.00 1465.00 1467.00 1513.00 1521.00 1528.00 1510.00 1520.00\n[406] 1547.00 1555.00 1563.00 1561.00 1565.00 1260.00 1298.00 1308.00 1318.00\n[415] 1320.00 1341.00 1343.00 1320.00 1326.00 1327.00 2821.00 2892.00 2919.00\n[424] 2930.00 2934.00 2962.00 2940.00 2985.00 2992.00 3000.00 3292.00 3315.00\n[433] 3321.00 3347.00 3362.00 3364.00 3373.00 3379.00 3395.00 3408.00\nattr(,\"na.action\")\n[1] 441\nattr(,\"class\")\n[1] \"omit\"\n\n\nAnd then get the length when NAs are omitted:\n\nlength(na.omit(c(DAT$time, NA)))\n\n[1] 440\n\n\nThis behavior is important because if you want to obtain the mean of a variable with NAs and the sample size using length(), your sample size will be inaccurate.\nIn order to see these operations on a data frame and in the context of dplyr::summarize(), let’s modify the data frame to include an additional row with some mission values. One simple approach is to use base R to use rbind() to bind a new row to the end of the data frame. In this case, the contents of that new row will be the same as the first row of the data frame (e.g., DAT[1,]). Then the name will be changed and some values will be made missing.\n\nDAT &lt;- rbind(DAT, \n             DAT[1,]\n             )\n\nModify the cells in the data frame using bracket notation from base R. When using brackets, the data frame can be referenced using row and column arguments.\nExamples:\nDAT[]       # all rows and columns\n\nDAT[,]      # all rows and columns (preferred separation with comma)\n\nDAT[1, ]    # row 1, all columns\n\nDAT[,1]     # all rows, column 1\n\nDAT[1:5, \"name\"]    # rows 1 through 5, \"name\" column\n\nDAT[, c(\"name\", \"year\"]    # all rows, \"name\" and \"year\" columns\n\nDAT[15, \"name\"]    # row 15 through 5, \"name\" column\nYou can also obtain the dimensions of a data frame using dim() from base R.\n\ndim(DAT)\n\n[1] 441   8\n\n\ndim() returns a vector with two elements: the number of rows and the number of columns. We can use this to reference the last row in the data frame in order to modify it for this example.\nFollowing from above, examine the last row, change the \"name\" to “Anonymous” and then put NAs in the \"sec\" and \"min\" columns for the same row. Remember, vectors are pure characters or numeric, they cannot contain a mixture of them. Because \"name\" is character vector and \"sec\" and \"min\" are numeric vectors, we need to fix them separately. There are other ways to accomplish this goal but this example illustrates the approach in base R so that you have some exposure.\n\nDAT[dim(DAT)[1], ]                              # the current row contents\n\n                name year   event   team time  sec      min      hour\n441 Jocelyn Crawford 2019 50 FREE Athena 1409 1409 23.48333 0.3913889\n\nDAT[dim(DAT)[1], \"name\"] &lt;- \"Anonymous\"         # make name anonymous\n\nDAT[dim(DAT)[1], c(\"sec\", \"min\")] &lt;- c(NA, NA)  # set these cells to NA\n\nAre NAs across the last row now?\n\nDAT %&gt;% tail()\n\n             name year               event   team time  sec      min      hour\n436 Aaron Lutzker 2019 100 BRST-Relay Spl.   Stag 3364 3364 56.06667 0.9344444\n437  Sean Hoerger 2020 100 BRST-Relay Spl.   Stag 3373 3373 56.21667 0.9369444\n438   Tyler Welty 2017 100 BRST-Relay Spl.   Stag 3379 3379 56.31667 0.9386111\n439  Brad Perfect 2013 100 BRST-Relay Spl.   Stag 3395 3395 56.58333 0.9430556\n440  Grant Murray 2018 100 BRST-Relay Spl.   Stag 3408 3408 56.80000 0.9466667\n441     Anonymous 2019             50 FREE Athena 1409   NA       NA 0.3913889\n\n\n\n\nComparing some functionality when passing lists to .cols in across()\nWhen functions do not contain argument for dealing with NAs, there is na.omit(), a function that takes an object and removes NAs. So you can just pass the variable to na.omit() and then wrap it in the metric function of interest. Also, because na.rm = T cannot be used for length(), na.omit() offers consistency across all functions and as a result, I believe, less confusion.\nUnfortunately, accomplishing this task can be rather tricky and requires some new syntax. This requires usage of what’s called a “lambda” technique. You will want to incorporate ~ and .x into your code. The ~ is used to indicate that you are supplying a lambda function and use of .x is to indicate where the variable in across() is used. Using this type of syntax, we can pass functions to the .fns argument that operate across a set of variables. The ?across() documentation calls this “a {purrr}-style lambda” in the arguments section. This approach can be a little bit confusing, so I’m going to show you an example, and then walk through it step by step. You can always create code snippets so you don’t have to rely on memory write complicated code like this.\nAnyway, we will precede the function with ~ and reference the vector using .x. Let’s do this and change the .fns argument slightly.\nHere is a general example:\nname = ~function(na.omit(.x))\nWe will summarize only time and sec because those variables are identical except for the row we added. We will also add dplyr::n() to see what’s going on with that function.\n\nDAT %&gt;%\n  summarise(., across(.cols = c(\"time\", \"sec\"), \n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   #sd = ~sd(na.omit(.x)),\n                                   len = ~length(na.omit(.x)),\n                                   n = ~dplyr::n()\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n  time_mean time_len time_n sec_mean sec_len sec_n\n1  1309.614      441    441 1309.388     440   441\n\n\nSo what happened? The means and lengths for time and sec are not the same. Means differ because they are calculated by different values depending on the presence of NAs. But notice that the n’s are the same based on dplyr::n(). How can the means and differ if the n’s are the same?\nSo what’s the point of all of this? Well, you need to be careful not to apply functions and assume they are doing what you believe you are doing. You always need to be smarter than the code you use. Also, there is no single answer for dealing with data. Sometimes one approach will be appropriate and in other instances another approach will be. You as the data scientist need to know that there are different methods so that you an decide where to apply those different methods."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarize-by-groups-using-group_by",
    "href": "modules/07_data_subsets_and_summaries.html#summarize-by-groups-using-group_by",
    "title": "Data subsets and summaries",
    "section": "Summarize by Groups Using group_by()",
    "text": "Summarize by Groups Using group_by()\n\nIdentifying how to group\nWhen you have subgroups in your data, you will often want to create summary statistics by those group levels. A typical grouping approach is by some categorical or factor variable present in a data frame. Using glympse(), we can view all variables to see what might be of interest.\n\nglimpse(DAT)\n\nRows: 441\nColumns: 8\n$ name  &lt;chr&gt; \"Jocelyn Crawford\", \"Ava Sealander\", \"Kelly Ngo\", \"Helen Liu\", \"…\n$ year  &lt;chr&gt; \"2019\", \"2022\", \"2016\", \"2014\", \"2014\", \"2020\", \"2020\", \"2010\", …\n$ event &lt;chr&gt; \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\", \"50 FREE\"…\n$ team  &lt;chr&gt; \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Athena\", \"Ath…\n$ time  &lt;dbl&gt; 1409.00, 1411.00, 1429.00, 1451.00, 1456.00, 1457.00, 1457.00, 1…\n$ sec   &lt;dbl&gt; 1409.00, 1411.00, 1429.00, 1451.00, 1456.00, 1457.00, 1457.00, 1…\n$ min   &lt;dbl&gt; 23.483333, 23.516667, 23.816667, 24.183333, 24.266667, 24.283333…\n$ hour  &lt;dbl&gt; 0.39138889, 0.39194444, 0.39694444, 0.40305556, 0.40444444, 0.40…\n\n\nLooks like some factor variables we can group by include name, year, event, and team."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarize-a-one-specific-variable-by-groups-using-group_by",
    "href": "modules/07_data_subsets_and_summaries.html#summarize-a-one-specific-variable-by-groups-using-group_by",
    "title": "Data subsets and summaries",
    "section": "Summarize A (one) Specific Variable by Groups Using group_by()",
    "text": "Summarize A (one) Specific Variable by Groups Using group_by()\n\nA single summary metric\nPerhaps you only want to obtain the mean() or the sum() or the sd() for a variable. If so, this is easiest.\n\nGrouping by one variable:\nThe data in cms-top-all-time-2023-swim.xlsx contain the top records for swimming events. You might be curious what year was the best of all time or what swimmer (e.g., name) has attained the most records of all time. There are different ways to accomplish this goal.\nOne approach that might be the most straight forward to new programmers is to mutate a constant count variable on each row which can be used to sum the counts for different groups.\n\nDAT %&gt;%\n  mutate(., count = 1) %&gt;%         # mutate a new variable where all rows get a 1\n  group_by(., name) %&gt;%            # group by the swimmer name\n  summarise(., count = sum(count)) # sum the count and assign it the name count\n\n# A tibble: 142 × 2\n   name            count\n   &lt;chr&gt;           &lt;dbl&gt;\n 1 A Breazeale         8\n 2 A Roeseler          2\n 3 Aaron Lutzker       6\n 4 Abel Sapirstein     1\n 5 Alec Vercruysse     4\n 6 Alex Mendoza        2\n 7 Alex Poltash        6\n 8 Allyson Yao         3\n 9 Amy Fuller          1\n10 Andrew Cox          4\n# ℹ 132 more rows\n\n\nBy default, the data frame is arranged by the grouping variable (e.g., name). We can change the order of the rows by count using arrange() but this function by default sorts in an ascending manner. If you want a descending sorting, pass count to desc() to arrange the data frame in this way. We can also assign it to an object.\n\nNAME_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  group_by(., name) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n\nNAME_count\n\n# A tibble: 142 × 2\n   name          count\n   &lt;chr&gt;         &lt;dbl&gt;\n 1 Michele Kee      11\n 2 Augusta Lewis    10\n 3 Matt Williams    10\n 4 Kelly Ngo         9\n 5 A Breazeale       8\n 6 Ava Sealander     8\n 7 Gary Simon        8\n 8 Marco Conati      8\n 9 Nic Tekieli       7\n10 Aaron Lutzker     6\n# ℹ 132 more rows\n\n\nWe can see that the top counts of all time are by Michele Kee for a total of 11. Kudos to Michele!\n\nYEAR_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  group_by(., year) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n\nYEAR_count\n\n# A tibble: 32 × 2\n   year  count\n   &lt;chr&gt; &lt;dbl&gt;\n 1 2022     81\n 2 2023     59\n 3 2020     41\n 4 2017     38\n 5 2014     27\n 6 2019     23\n 7 2013     22\n 8 2015     20\n 9 2016     17\n10 2018     16\n# ℹ 22 more rows\n\n\nWe can see that the year with the most best are by 2022 for a total of 81. Hooray for 2022!\n\n\nGrouping by two or more variables:\nWe can also summarize both the teams as well in order to see the top swimmer by team. If you want to summarize more than one variable, pass them both in group_by():\n\nTEAM_NAME_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  group_by(., team, name) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n\nTEAM_NAME_count\n\n# A tibble: 142 × 3\n# Groups:   team [2]\n   team   name          count\n   &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;\n 1 Athena Michele Kee      11\n 2 Athena Augusta Lewis    10\n 3 Stag   Matt Williams    10\n 4 Athena Kelly Ngo         9\n 5 Athena Ava Sealander     8\n 6 Stag   A Breazeale       8\n 7 Stag   Gary Simon        8\n 8 Stag   Marco Conati      8\n 9 Stag   Nic Tekieli       7\n10 Athena Ella Blake        6\n# ℹ 132 more rows\n\n\n\n\nFiltering rows and then grouping by one variable:\nFor Athenas:\n\nATHENA_NAME_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  filter(., team == \"Athena\") %&gt;%\n  group_by(., name) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n\nATHENA_NAME_count\n\n# A tibble: 67 × 2\n   name               count\n   &lt;chr&gt;              &lt;dbl&gt;\n 1 Michele Kee           11\n 2 Augusta Lewis         10\n 3 Kelly Ngo              9\n 4 Ava Sealander          8\n 5 Ella Blake             6\n 6 Jamee Mitchum          6\n 7 Katie Bilotti          6\n 8 Mackenzie Mayfield     6\n 9 Annika Jessen          5\n10 Jocelyn Crawford       5\n# ℹ 57 more rows\n\n\nWe can see that the top counts of all time are by Michele Kee with a total of 11. Nice work Michele!\nAnd for Stags:\n\nSTAG_NAME_count &lt;- DAT %&gt;%\n  mutate(., count = 1) %&gt;%\n  filter(., team == \"Stag\") %&gt;%\n  group_by(., name) %&gt;%\n  summarise(., count = sum(count)) %&gt;%\n  arrange(., desc(count))\n\n\nSTAG_NAME_count\n\n# A tibble: 75 × 2\n   name          count\n   &lt;chr&gt;         &lt;dbl&gt;\n 1 Matt Williams    10\n 2 A Breazeale       8\n 3 Gary Simon        8\n 4 Marco Conati      8\n 5 Nic Tekieli       7\n 6 Aaron Lutzker     6\n 7 Alex Poltash      6\n 8 Blake Weber       6\n 9 Sam Willett       5\n10 Tom Harrison      5\n# ℹ 65 more rows\n\n\nWe can see that the top counts of all time are by Matt Williams with 10. Go Matt!\nTo wrap up this example, sometimes working with separate data frames using filter() can provide more useful or manageable summaries.Perhaps you only want to obtain the mean() or the sum() or the sd() for a single variable. If so, this approach may be easiest.\nIf you are curious, here is a story covering “How CMS teams became the Stags and Athenas”.\n\n\n\nMultiple summary metrics\nSometimes you need more than one summary statistic, for example, the mean() and the sd(). This is a little more complex to code.\nNote: In these code blocks, some arguments may be removed for readability.\n\nGrouping by one variable:\n\nDAT %&gt;%\n  group_by(., event) %&gt;%\n  summarise(., \n            sec_mean = mean(sec, na.rm = T),  \n            sec_median = median(sec, na.rm = T)\n            )\n\n# A tibble: 22 × 3\n   event               sec_mean sec_median\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK               3209.      3212.\n 2 100 BREAST             1725.      1696.\n 3 100 BRST-Relay Spl.    1710.      1678.\n 4 100 FLY                3158.      3165 \n 5 100 FLY-Relay Spl.     3135.      3152.\n 6 100 FREE               2917.      2908.\n 7 100 FREE-Relay Spl.    2888.      2896 \n 8 1000 FREE               601.       601.\n 9 1650 FREE               990.       991.\n10 200 BACK                116.       116.\n# ℹ 12 more rows\n\n\nWe can also write the summary functions as a list inside across() along with passing .names = \"{.col}_{.fn}\" if you want the variables named automatically. This approach is more complex but is more flexible.\nWhen you want to summarize across multiple variables using a list of functions, you will want to make sure your .fns argument passes a function using a {purrr}-style lambda (e.g.,~) for that the function is applied across the variables. You will also want to edit .names = \"{.col}_{.fn}\" so that the naming is done automatically rather than hard coding the names.\n\nDAT %&gt;%\n  group_by(., event) %&gt;%\n  summarise(., across(.cols = \"sec\",\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   median = ~median(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n# A tibble: 22 × 3\n   event               sec_mean sec_median\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK               3209.      3212.\n 2 100 BREAST             1725.      1696.\n 3 100 BRST-Relay Spl.    1710.      1678.\n 4 100 FLY                3158.      3165 \n 5 100 FLY-Relay Spl.     3135.      3152.\n 6 100 FREE               2917.      2908.\n 7 100 FREE-Relay Spl.    2888.      2896 \n 8 1000 FREE               601.       601.\n 9 1650 FREE               990.       991.\n10 200 BACK                116.       116.\n# ℹ 12 more rows\n\n\n\n\nGrouping by two or more variables:\n\nDAT %&gt;%\n  group_by(., event, team) %&gt;%\n  summarise(., \n            sec_mean = mean(sec, na.rm = T),  \n            sec_median = median(sec, na.rm = T)\n            )\n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   event [22]\n   event               team   sec_mean sec_median\n   &lt;chr&gt;               &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK            Athena   3421.      3436  \n 2 100 BACK            Stag     2996.      3032  \n 3 100 BREAST          Athena     64.0       64.2\n 4 100 BREAST          Stag     3386.      3394. \n 5 100 BRST-Relay Spl. Athena     63.6       64.1\n 6 100 BRST-Relay Spl. Stag     3356.      3363  \n 7 100 FLY             Athena   3365.      3369  \n 8 100 FLY             Stag     2950.      2968. \n 9 100 FLY-Relay Spl.  Athena   3332.      3326  \n10 100 FLY-Relay Spl.  Stag     2938.      2937  \n# ℹ 34 more rows\n\n\nOr pass the list:\n\nDAT %&gt;%\n  group_by(., event, team) %&gt;%\n  summarise(., across(.cols = \"sec\",\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   median = ~median(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   event [22]\n   event               team   sec_mean sec_median\n   &lt;chr&gt;               &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK            Athena   3421.      3436  \n 2 100 BACK            Stag     2996.      3032  \n 3 100 BREAST          Athena     64.0       64.2\n 4 100 BREAST          Stag     3386.      3394. \n 5 100 BRST-Relay Spl. Athena     63.6       64.1\n 6 100 BRST-Relay Spl. Stag     3356.      3363  \n 7 100 FLY             Athena   3365.      3369  \n 8 100 FLY             Stag     2950.      2968. \n 9 100 FLY-Relay Spl.  Athena   3332.      3326  \n10 100 FLY-Relay Spl.  Stag     2938.      2937  \n# ℹ 34 more rows"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarizing-multiple-variables-by-groups-using-group_by",
    "href": "modules/07_data_subsets_and_summaries.html#summarizing-multiple-variables-by-groups-using-group_by",
    "title": "Data subsets and summaries",
    "section": "Summarizing Multiple Variables by Groups Using group_by()",
    "text": "Summarizing Multiple Variables by Groups Using group_by()\nSo far, we have shown how to summarize a single variable either with or without grouping by levels of another variable. Summaries, however, are often done for multiple variables in data frame. For example, you might want to obtain the mean() for multiple variables or obtain the mean() and the max() (or some other summary statistic) for multiple variables. The following examples prepare you for such tasks.\n\nA single summary metric\n\nGrouping by one variable:\n\nDAT %&gt;%\n  group_by(., event) %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\"),\n                      .fns = ~mean(.x, na.rm = T),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n# A tibble: 22 × 3\n   event               sec_1 min_1\n   &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n 1 100 BACK            3209. 53.5 \n 2 100 BREAST          1725. 28.8 \n 3 100 BRST-Relay Spl. 1710. 28.5 \n 4 100 FLY             3158. 52.6 \n 5 100 FLY-Relay Spl.  3135. 52.2 \n 6 100 FREE            2917. 48.6 \n 7 100 FREE-Relay Spl. 2888. 48.1 \n 8 1000 FREE            601. 10.0 \n 9 1650 FREE            990. 16.5 \n10 200 BACK             116.  1.94\n# ℹ 12 more rows\n\n\n\n\nGrouping by two or more variables:\n\nDAT %&gt;%\n  group_by(., event, team) %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\"),\n                      .fns = ~mean(.x, na.rm = T),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   event [22]\n   event               team    sec_1 min_1\n   &lt;chr&gt;               &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 100 BACK            Athena 3421.  57.0 \n 2 100 BACK            Stag   2996.  49.9 \n 3 100 BREAST          Athena   64.0  1.07\n 4 100 BREAST          Stag   3386.  56.4 \n 5 100 BRST-Relay Spl. Athena   63.6  1.06\n 6 100 BRST-Relay Spl. Stag   3356.  55.9 \n 7 100 FLY             Athena 3365.  56.1 \n 8 100 FLY             Stag   2950.  49.2 \n 9 100 FLY-Relay Spl.  Athena 3332.  55.5 \n10 100 FLY-Relay Spl.  Stag   2938.  49.0 \n# ℹ 34 more rows\n\n\n\n\n\nMultiple summary metrics\nAnd if you need to summarize using multiple metrics, then pass the list into .fns:\n\nGrouping by one variable:\n\nDAT %&gt;%\n  group_by(., event) %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\"),\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   median = ~median(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n# A tibble: 22 × 5\n   event               sec_mean sec_median min_mean min_median\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK               3209.      3212.    53.5       53.5 \n 2 100 BREAST             1725.      1696.    28.8       28.3 \n 3 100 BRST-Relay Spl.    1710.      1678.    28.5       28.0 \n 4 100 FLY                3158.      3165     52.6       52.8 \n 5 100 FLY-Relay Spl.     3135.      3152.    52.2       52.5 \n 6 100 FREE               2917.      2908.    48.6       48.5 \n 7 100 FREE-Relay Spl.    2888.      2896     48.1       48.3 \n 8 1000 FREE               601.       601.    10.0       10.0 \n 9 1650 FREE               990.       991.    16.5       16.5 \n10 200 BACK                116.       116.     1.94       1.93\n# ℹ 12 more rows\n\n\n\n\nGrouping by two or more variables:\n\nDAT %&gt;%\n  group_by(., event, team) %&gt;%\n  summarise(., across(.cols = c(\"sec\", \"min\"),\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   median = ~median(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'event'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 6\n# Groups:   event [22]\n   event               team   sec_mean sec_median min_mean min_median\n   &lt;chr&gt;               &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 100 BACK            Athena   3421.      3436      57.0       57.3 \n 2 100 BACK            Stag     2996.      3032      49.9       50.5 \n 3 100 BREAST          Athena     64.0       64.2     1.07       1.07\n 4 100 BREAST          Stag     3386.      3394.     56.4       56.6 \n 5 100 BRST-Relay Spl. Athena     63.6       64.1     1.06       1.07\n 6 100 BRST-Relay Spl. Stag     3356.      3363      55.9       56.0 \n 7 100 FLY             Athena   3365.      3369      56.1       56.2 \n 8 100 FLY             Stag     2950.      2968.     49.2       49.5 \n 9 100 FLY-Relay Spl.  Athena   3332.      3326      55.5       55.4 \n10 100 FLY-Relay Spl.  Stag     2938.      2937      49.0       49.0 \n# ℹ 34 more rows\n\n\nDepends on the order in group_by(), so change the order:\n\nDAT %&gt;%\n  group_by(., team, event) %&gt;%\n  summarise(., across(.cols = \"sec\",\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   n = ~length(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   team [2]\n   team   event               sec_mean sec_n\n   &lt;chr&gt;  &lt;chr&gt;                  &lt;dbl&gt; &lt;int&gt;\n 1 Athena 100 BACK              3421.     10\n 2 Athena 100 BREAST              64.0    10\n 3 Athena 100 BRST-Relay Spl.     63.6    10\n 4 Athena 100 FLY               3365.     10\n 5 Athena 100 FLY-Relay Spl.    3332.     10\n 6 Athena 100 FREE              3115.     10\n 7 Athena 100 FREE-Relay Spl.   3088.     10\n 8 Athena 1000 FREE              625.     10\n 9 Athena 1650 FREE             1031.     10\n10 Athena 200 BACK               124.     10\n# ℹ 34 more rows\n\n\nNotice the change in the order of the column variables. But remember, you can change the order later using select() and/or relocate()."
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#summarizing-multiple-variables-with-reference-by-name",
    "href": "modules/07_data_subsets_and_summaries.html#summarizing-multiple-variables-with-reference-by-name",
    "title": "Data subsets and summaries",
    "section": "Summarizing Multiple Variables With Reference by Name`",
    "text": "Summarizing Multiple Variables With Reference by Name`\n\nVariables that are numeric\nYou can also pass variables that are a certain type, like numeric.\n\nDAT %&gt;%\n  group_by(., team, event) %&gt;%\n  summarise(., across(.cols = where(is.numeric), \n                      .fns = ~mean(.x, na.rm = TRUE), \n                      .names = \"{.col}\")\n            )\n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 6\n# Groups:   team [2]\n   team   event                 time    sec   min   hour\n   &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Athena 100 BACK            3421.  3421.  57.0  0.950 \n 2 Athena 100 BREAST            64.0   64.0  1.07 0.0178\n 3 Athena 100 BRST-Relay Spl.   63.6   63.6  1.06 0.0177\n 4 Athena 100 FLY             3365.  3365.  56.1  0.935 \n 5 Athena 100 FLY-Relay Spl.  3332.  3332.  55.5  0.926 \n 6 Athena 100 FREE            3115.  3115.  51.9  0.865 \n 7 Athena 100 FREE-Relay Spl. 3088.  3088.  51.5  0.858 \n 8 Athena 1000 FREE            625.   625.  10.4  0.174 \n 9 Athena 1650 FREE           1031.  1031.  17.2  0.286 \n10 Athena 200 BACK             124.   124.   2.07 0.0345\n# ℹ 34 more rows\n\n\n\n\nVariables by pattern match\nThis approach is fun, especially if you have already named variables in ways that make selection really useful. This data frame is constrained a bit so the examples may be silly.\n\nUsing starts_with()\n\nDAT %&gt;%\n  group_by(., team, event) %&gt;%\n  summarise(., across(.cols = starts_with(\"t\"),\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   n = ~length(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 4\n# Groups:   team [2]\n   team   event               time_mean time_n\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;dbl&gt;  &lt;int&gt;\n 1 Athena 100 BACK               3421.      10\n 2 Athena 100 BREAST               64.0     10\n 3 Athena 100 BRST-Relay Spl.      63.6     10\n 4 Athena 100 FLY                3365.      10\n 5 Athena 100 FLY-Relay Spl.     3332.      10\n 6 Athena 100 FREE               3115.      10\n 7 Athena 100 FREE-Relay Spl.    3088.      10\n 8 Athena 1000 FREE               625.      10\n 9 Athena 1650 FREE              1031.      10\n10 Athena 200 BACK                124.      10\n# ℹ 34 more rows\n\n\n\n\nUsing & for complex selection\nYou obviously cannot calculate numeric metrics for character variables. But how might you select variables that contain a certain character pattern but are also numeric? You cannot nest these functions (e.g., where(is.numeric(contains(\"pattern\")))). You can, however, pass the functions separately.\n\nDAT %&gt;%\n  group_by(., team, event) %&gt;%\n  summarise(., across(.cols = contains(\"e\") & where(is.numeric),\n                      .fns  = list(mean = ~mean(na.omit(.x)),\n                                   n = ~length(na.omit(.x))\n                                   ),\n                      .names = \"{.col}_{.fn}\"\n                      )\n            ) \n\n`summarise()` has grouped output by 'team'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 44 × 6\n# Groups:   team [2]\n   team   event               time_mean time_n sec_mean sec_n\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;dbl&gt;  &lt;int&gt;    &lt;dbl&gt; &lt;int&gt;\n 1 Athena 100 BACK               3421.      10   3421.     10\n 2 Athena 100 BREAST               64.0     10     64.0    10\n 3 Athena 100 BRST-Relay Spl.      63.6     10     63.6    10\n 4 Athena 100 FLY                3365.      10   3365.     10\n 5 Athena 100 FLY-Relay Spl.     3332.      10   3332.     10\n 6 Athena 100 FREE               3115.      10   3115.     10\n 7 Athena 100 FREE-Relay Spl.    3088.      10   3088.     10\n 8 Athena 1000 FREE               625.      10    625.     10\n 9 Athena 1650 FREE              1031.      10   1031.     10\n10 Athena 200 BACK                124.      10    124.     10\n# ℹ 34 more rows"
  },
  {
    "objectID": "modules/07_data_subsets_and_summaries.html#a-functional-approach",
    "href": "modules/07_data_subsets_and_summaries.html#a-functional-approach",
    "title": "Data subsets and summaries",
    "section": "A Functional Approach",
    "text": "A Functional Approach\nYou can also throw your summaries into functions if you wish. We will create a new object that is a function object. We need to give it a name and we need to define arguments to make the function operate. We will want to make sure we have numeric variables.\n\nsummarizer &lt;- function(data, \n                       cols = NULL, \n                       ...\n                       ) {\n  data %&gt;%\n    group_by(...) %&gt;%\n    summarise(., across(.cols = {{cols}} & where(is.numeric),\n                     .fns = list(\n                          mean = ~mean(.x, na.rm = TRUE),\n                          sd   = ~sd(.x, na.rm = TRUE)\n                          ), \n                     .names = \"{col}_{fn}\")\n              )\n}\n\nTest the function:\nWithout grouping:\n\nsummarizer(DAT, cols = contains(\"e\"))\n\n# A tibble: 1 × 4\n  time_mean time_sd sec_mean sec_sd\n      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1     1310.   1225.    1309.  1226.\n\n\nWith grouping:\n\nsummarizer(DAT, cols = c(min, hour), event)\n\n# A tibble: 22 × 5\n   event               min_mean min_sd hour_mean hour_sd\n   &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 100 BACK               53.5   3.76     0.891  0.0626 \n 2 100 BREAST             28.8  28.4      0.479  0.473  \n 3 100 BRST-Relay Spl.    28.5  28.1      0.475  0.469  \n 4 100 FLY                52.6   3.63     0.877  0.0605 \n 5 100 FLY-Relay Spl.     52.2   3.44     0.871  0.0573 \n 6 100 FREE               48.6   3.43     0.810  0.0571 \n 7 100 FREE-Relay Spl.    48.1   3.46     0.802  0.0576 \n 8 1000 FREE              10.0   0.432    0.167  0.00719\n 9 1650 FREE              16.5   0.728    0.275  0.0121 \n10 200 BACK                1.94  0.136    0.0324 0.00227\n# ℹ 12 more rows\n\n\nAnd of course, when you really get excited, you could add functions so that you can perform different metrics. When you are done, you can save your favorite function to a file you can source()."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html",
    "title": "{ggplot} and the grammar of graphics",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#readings",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#readings",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Introduction to Vizualization\nWilke (2019). Fundamentals of Data Visualization. Aesthetic Mapping\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Introduction\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Understanding the Grammar\n\nOptional (more on the grammar):\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Build a plot layer by layer"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#load-libraries",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#load-libraries",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#external-functions",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#external-functions",
    "title": "{ggplot} and the grammar of graphics",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#ggplot-plot-composition",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#ggplot-plot-composition",
    "title": "{ggplot} and the grammar of graphics",
    "section": "{ggplot} Plot Composition",
    "text": "{ggplot} Plot Composition\nThere are five mapping components:\n\nLayer containing geometric elements and statistical transformations:\n\n\nData a tidy data frame, most typically in long/narrow format\nMapping defining how vector variables are visualized (e.g., aesthetics like shape, color, position, hue, etc.)\nStatistical Transformation (stat) representing some summarizing of data (e.g., sums, fitted curves, etc.)\nGeometric object (geom) controlling the type of visualization\nPosition Adjustment (position) controlling where visual elements are positioned\n\n\nScales that map values in the data space to values in aesthetic space\nA Coordinate System for mapping coordinates to the plane of a graphic\nA Facet for arranging the data into a grid; plotting subsets of data\nA Theme controlling the niceties of the plot, like font, background, grids, axes, typeface etc.\n\nThe grammar does not:\n\nMake suggestions about what graphics to use\nDescribe interactivity with a graphic; {ggplot2} graphics are static images, though they can be animated"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#initializing-the-plot-object",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#initializing-the-plot-object",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Initializing the Plot Object",
    "text": "Initializing the Plot Object\nWhat is a ?ggplot object? Review the docs first. Let’s apply the base layer using ggplot(). This function takes a data set and simply initializes the plot object so that you can build other components on top of it. By default, data = NULL so, you will need to pass some data argument. There is also a mapping parameter for mapping the aesthetics of the plot, by default, mapping = aes(). If you don’t pass a data frame to data, what happens?\n\nggplot()\n\n\n\n\nAn object is created but it contains no data. The default is some rectangle in space."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#passing-the-data-to-ggplot",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#passing-the-data-to-ggplot",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Passing the Data to ggplot()",
    "text": "Passing the Data to ggplot()\nYou cannot have a plot without data, so we need some data in a tidy format. We can read in a data set or create one.\n\nSWIM &lt;- readr::read_csv(here::here(\"data\", \"cleaned-cms-top-all-time-2023-swim.csv\"))\n\nRows: 440 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): name, year, event, team\ndbl (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nDATA &lt;- data.frame(\n A = c(1, 2, 3, 4), \n B = c(2, 5, 3, 8), \n C = c(10, 15, 32, 28), \n D = c(\"Task A\", \"Task A\", \"Task B\", \"Task B\"),\n E = c(\"circle\", \"circle\", \"square\", \"square\")\n)\n\nLet’s also quickly change the variable names to titlecase() so that the first letter is capitalize.\n\nnames(SWIM) &lt;- tools::toTitleCase(names(SWIM))\n\nNow we can pass this data frame to data.\n\nggplot(data = SWIM)\n\n\n\n\nOK, so still nothing. That’s because we haven’t told ggplot() what visual properties or aesthetics to include in the plot. Importantly, you do not have to provide this information in a base layer. {ggplot2} is flexible insofar as you can pass data in different places depending what data you want to use and at which layer on how you will use it.\nIf you set data = SWIM, the subsequent layers of the plot will inherit that data frame if you do not pass the argument in a different layer. However, you are not limited to passing only one data set. You might wish to plot the aesthetics of one data frame in one layer and then add another layer of aesthetics taken from a different data frame. TLDR; you can pass data, or not pass data, in the initialization of the base layer."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#scalingscale-transformation",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#scalingscale-transformation",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Scaling/Scale Transformation",
    "text": "Scaling/Scale Transformation\n\nprint(SWIM)\n\n# A tibble: 440 × 5\n    Time Name             Year  Event   Team  \n   &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n 1  1409 Jocelyn Crawford 2019  50 FREE Athena\n 2  1411 Ava Sealander    2022  50 FREE Athena\n 3  1429 Kelly Ngo        2016  50 FREE Athena\n 4  1451 Helen Liu        2014  50 FREE Athena\n 5  1456 Michele Kee      2014  50 FREE Athena\n 6  1457 Natalia Orbach-M 2020  50 FREE Athena\n 7  1457 Suzia Starzyk    2020  50 FREE Athena\n 8  1467 Katie Bilotti    2010  50 FREE Athena\n 9  1473 Jenni Rinker     2011  50 FREE Athena\n10  1442 Annika Sharma    2023  50 FREE Athena\n# ℹ 430 more rows\n\n\nLooking at the data, we have a tidy file composed of columns and rows. Looking at the data frame, you see the ‘identity’ of each case. This term is important to {ggplot}. By identity we mean variables are a numeric value, character, or factor. What you see in the data frame is the identity of the variables. Of course, we can change the identity of a variable in some way by transforming the values to z scores, log values, or each average them together to take their count and then plot any of those data. But those transformations do not represent true identities as they appear in a data set.\nIn order to take the data units in the data frame so that they can be represented as physical units on a plot (e.g., points, bars, lines, etc.), there needs to be some scaling transformation. The plot function needs to understand how many pixels high and wide to create a plot and the plot needs to know the limits of the axes for example. Similarly, the plot function needs to know what shapes to present, how many, etc. By default, the statistical transformation is an ‘identity’ transformation, or one that just takes the values and plots them as their appear in the data (their identity). More on this when we start plotting."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#choosing-a-coordinate-system",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#choosing-a-coordinate-system",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Choosing a Coordinate System",
    "text": "Choosing a Coordinate System\nAll we have now is the base layer that is taking on some coordinates. For example, where are the points plotted on the plot? The system can follow the Cartesian coordinate system or a Polar coordinate system. An example of this will follow later. For now, the default is chosen for you. What might you think it is?"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#adding-aesthetic-mappings",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#adding-aesthetic-mappings",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Adding Aesthetic Mappings",
    "text": "Adding Aesthetic Mappings\nIf you wanted your plot geometry (the geom() you add later) to inherit properties of the initialized base layer, you could pass aesthetics to the mapping argument mapping = aes() in the ggplot() function. Notice that the argument that we pass to mapping is another function, aes().\nFor example:\n\nggplot(data = SWIM, mapping = aes())\n\n\n\n\nBut this still does not present anything you can see. You might have guessed that the reason you do not see anything is because nothing was passed to aes(). Here is where you map data to aesthetics by specifying the variable information and passing them to aes(). Looking at ?aes, we see that aes() maps how properties of the data connect to, or map, onto with the features of the visualization (e.g., axis position, color, size, etc.). The aesthetics are the visual properties of the visualization, so they are essential to map by passing arguments to aes().\nHow many and what variables do pass? Looking at ?aes, you see that x and y are needed.\nBecause we passed data = SWIM in ggplot(), we can reference the variables by their column names without specifying the data frame.\nIf x = Year and y = Time:\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       )\n\n\n\n\nOK, now we can see something. Although this is progress, what is visible is rather empty and ugly. We can see that the aesthetic layer now applied to the plot scales the data to present Year along the x-axis with a range from lowest to highest value from that vector. Similarly, the mapping presents Time along the y-axis with a range from lowest to highest value in the vector. Also, the aesthetics include the variable name as a the label for the x and y axes. Of course, you can change these details later in a layer as well. More on that later.\nYou might have been tempted to pass the variable names a quoted strings (e.g., “A” and “B) but if you do that, you’ll get something different.\n\nggplot(data = SWIM, \n       mapping = aes(x = \"Year\", y = \"Time\")\n       )\n\n\n\n\nIf we want to plot the data as they are in the data frame, we would apply the ‘identity’ transformation. Again, by identity, we just need to instruct ggplot() to use the data values in the data frame. If you wanted to plot the means, frequency count, or something else, we would need to tell ggplot() how to transform the data. We are not at that point yet though."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#adding-plot-geometries",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#adding-plot-geometries",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Adding Plot Geometries",
    "text": "Adding Plot Geometries\nWe do not yet have any geometries, or geoms, added. All geom functions will take the form geom_*(). As you will see, geoms can take many forms, including, points, lines, bars, text, etc. If we want the values in Year and Time to be plotted as x and y coordinates representing points on the plot, we can add a point geometry using geom_point().\nBy adding a layer, {ggplot2} really means add, as in +. We will take the initialize plot object that contains some data along with some mapping of variables to x an y coordinates and add to it a geometry. Combined, these functions will display data which adheres to some statistical transformation at some position along some scale an in some theme.\n\nggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point()\n\n\n\n\nAt some point, you will want to assign the plot to an object. When you do, the plot will not actually render for you to view.\n\nmy_first_plot &lt;- ggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point()\n\nThen:\n\nmy_first_plot\n\n\n\n\nPro Tip: You would need to call the plot to render it as illustrated above … unless you wrap it in ().\n\n(my_first_plot &lt;- ggplot(data = SWIM, \n       mapping = aes(x = Year, y = Time)\n       ) +\n  geom_point())\n\n\n\n\nYou now have a data visualization! The points geometry, geom_point(), inherits the aesthetic mapping from above and plots them as points."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#how-and-where-to-map-aesthetics",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#how-and-where-to-map-aesthetics",
    "title": "{ggplot} and the grammar of graphics",
    "section": "How and Where to Map Aesthetics?",
    "text": "How and Where to Map Aesthetics?\nYou might be wondering how you map these aesthetic properties so that when you attempt to do so, you don’t get a bunch of errors. There are two places you can map aesthetics:\nEither in the initialized plot object:\n\nggplot(data = data, mapping = aes(x, y)) + geom_point()\n\nOr in the geometry:\n\nggplot() +geom_point(data = data, mapping = aes(x, y))\n\nWe can map aesthetics in the initialized plot object by also assigning this to an object named map just so we can reference it as need.\nWhen we do this mapping:\n\nmap &lt;- ggplot(data = SWIM, \n              mapping = aes(Year, Time))\n\nThe aesthetics are inherited by the geometries that follow, which then do not require any mapping of their own…\n\nmap + \n  geom_point() + \n  geom_line()\n\n\n\n\nBut when aesthetics are NOT mapped in initialized plot:\n\nmap &lt;- ggplot() \n\nThere are no aesthetics to be inherited by the plot geometry functions because they are not passed to the ggplot() object. In this case they must be mapped as arguments the geometries themselves.\nPlot points:\n\nmap + \n  geom_point(data = SWIM, \n             mapping = aes(Year, Time)) \n\n\n\n\nPlot a line:\n\nmap + \n  geom_line(data = SWIM, \n            mapping = aes(x = Year, y = Time))\n\n\n\n\nIn a later section, we will differentiate between setting and mapping aesthetic attributes."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-as-is-from-the-data-frame",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-as-is-from-the-data-frame",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Mapping a variable as-is from the data frame`",
    "text": "Mapping a variable as-is from the data frame`\nggplot() defines the data as well as variables in aes(). You can easily map the x or y variable to the geom_*().\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = Year))"
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-differs-from-whats-in-the-data-frame",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-differs-from-whats-in-the-data-frame",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Mapping a variable that differs from what’s in the data frame",
    "text": "Mapping a variable that differs from what’s in the data frame\nYou can also change a variable type in the scope of the plot without modifying it in the data frame. Let’s change Year to numeric to see what happens:\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = as.numeric(Year)))\n\nWarning in FUN(X[[i]], ...): NAs introduced by coercion\n\nWarning in FUN(X[[i]], ...): NAs introduced by coercion\n\n\n\n\n\nSimilarly, if we had a numeric variable and wanted to make a factor():\n\nSWIM &lt;- SWIM %&gt;%\n  mutate(., Year2 = as.numeric(Year))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Year2 = as.numeric(Year)`.\nCaused by warning:\n! NAs introduced by coercion\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = as.factor(Year2)))\n\n\n\n\nOr make a character:\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = as.character(Year2)))\n\n\n\n\nYou may have noticed that when mapped variables are numeric, the aesthetics are applied continuously and when they are character (e.g., categorical, factors), they are applied discretely. Here is a good example of mapping variable Year not as itself but by changing it to a as.numeric() or changing numeric variables to either a factor() or a character vector. You might notice that the content in the legend is messy now. Fixing this is something we will work on as we progress."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-is-not-defined-in-the-aes-mapping-of-ggplot",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#mapping-a-variable-that-is-not-defined-in-the-aes-mapping-of-ggplot",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Mapping a variable that is not defined in the aes() mapping of ggplot()",
    "text": "Mapping a variable that is not defined in the aes() mapping of ggplot()\nSometimes you may wish to map a variable that is not defined in ggplot(). We can map a variable that is neither x nor y:\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(aes(color = Team))\n\n\n\n\nThis is no problem because Team exists in the SWIM data passed to data in the ggplot() object."
  },
  {
    "objectID": "modules/08_ggplot_and_the_grammar_of_graphics.html#setting-and-mapping-combinations",
    "href": "modules/08_ggplot_and_the_grammar_of_graphics.html#setting-and-mapping-combinations",
    "title": "{ggplot} and the grammar of graphics",
    "section": "Setting and Mapping Combinations",
    "text": "Setting and Mapping Combinations\nWe can also combine setting aesthetics and mapping them as long as the mapping takes place outside inside aes() and the setting takes place outside.\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(color = \"maroon\", aes(shape = Team))\n\n\n\n\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(color = \"blue\", aes(size = Time))\n\n\n\n\n\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n  geom_point(shape = 21, aes(color = Event))\n\n\n\n\nImportantly, just as you cannot pass constant values as aesthetics in aes(), you cannot pass a variable to an aesthetic in the geom_*() outside of aes().\nFor example, passing color = Team outside of aes() in this instance will throw an error.\nggplot(data = SWIM, aes(x = Year, y = Time)) + \n     geom_point(color = Team)\n\nError: object 'Team' not found\nIn summary, when you want to set an aesthetic to a constant value, do so in the geom_*() function, otherwise pass an aesthetic to aes() inside the geometry function. Color options can be discovered using colors(). Linetype has fewer options. To make the color more or less transparent, adjust alpha transparency (from 0 = invisible to 1).\n\nggplot(SWIM, aes(x = Year, y = Time)) +\n  geom_point() +\n  geom_line(linetype = \"dashed\",\n            color = \"red\",\n            alpha = .3)"
  },
  {
    "objectID": "modules/10_visualizing_associations.html",
    "href": "modules/10_visualizing_associations.html",
    "title": "Visualizing associations",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/10_visualizing_associations.html#readings",
    "href": "modules/10_visualizing_associations.html#readings",
    "title": "Visualizing associations",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from FDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing associations"
  },
  {
    "objectID": "modules/10_visualizing_associations.html#external-functions",
    "href": "modules/10_visualizing_associations.html#external-functions",
    "title": "Visualizing associations",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/10_visualizing_associations.html#libraries",
    "href": "modules/10_visualizing_associations.html#libraries",
    "title": "Visualizing associations",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting"
  },
  {
    "objectID": "modules/10_visualizing_associations.html#load-libraries",
    "href": "modules/10_visualizing_associations.html#load-libraries",
    "title": "Visualizing associations",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/10_visualizing_associations.html#a-simple-scatterplot-with-geom_point",
    "href": "modules/10_visualizing_associations.html#a-simple-scatterplot-with-geom_point",
    "title": "Visualizing associations",
    "section": "A Simple Scatterplot with geom_point()",
    "text": "A Simple Scatterplot with geom_point()\nThe typical xy scatter plot is used to visualize the relationship between two numeric variables. Those numeric variables may be continuous or discrete, though you will see that data visualizations involving discrete numeric data do have some limitations. We will attempt to circumvent some of those limitations using different functions from {ggplot2} in the examples presented. These approaches used can also be applied to continuous data.\nAs with all geoms, geom_point() can accept its own data and aesthetics or inherit them from the initialized ggplot() object. Similar to geom_col(), we need an x and a y variable to create a point plot. The specification of x or y may depended on variables as predictors or outcomes or based on the goal of the plot.\nBecause we have swim data represeting completion times for events of different distances, we will set x = Distance and y = Time so that we can visualize Time as a function of Distance.\nTaking the data frame and piping that to ggplot(), we declare the data and the mapping to x and y.\ngeom_point(\n  mapping = NULL,\n  data = NULL,\n  stat = \"identity\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\nWe can add the geom_point() layer that instructs how to display the data. Right out of the box, we get:\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Distance, y = Time)) +\n  geom_point()\n\n\n\n\nYour first point plot! You see small black points, axis labels, tick marks for intervals, and some apparent clustering of points around certain distances. You also see the association between distances and time, a positive association.\nWe will filter some of the event data to illustrate the {ggplot2} functionality.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point()\n\n\n\n\nThe association is still apparent in the plot. The tick marks along the x-axis changed but the clustering of points is still present. We will reserve discussion of axes for a later topic but the clustering is still present. This issue will often present itself when plotting a continuous variable like time against a discrete variable like event distance.\nIn another world, the variables may be reversed such that swimmers are tasked with swimming for a given time t, and their performance outcome is the distance they traveled. On one hand, this approach may be efficient because there would be no waiting around for slower swimmers to finish an event. On the other hand, measurement of distance in a liquid medium may be extremely difficult and time consuming, event completion may be lack luster for athletes, and the wait for results would be annoyingly painful for fans as they wait in agony for the measurement results to declare a winner. In the end, we would still have a discrete variable, now time, and a continuous variable, now distance. The data would still plague the visualization in the same way.\n\nAssociations with some smoothing\ngeom_smooth() is {ggplot2}’s solution to seeing some patterns of association in the data.\ngeom_smooth(\n  mapping = NULL,\n  data = NULL,\n  stat = \"smooth\",\n  position = \"identity\",\n  ...,\n  method = NULL,\n  formula = NULL,\n  se = TRUE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\nBy default, geom_smooth() does not add a linear fit to the data. Instead, method = 'loess' applies a Loess function on y ~ x, which will highlight curvature or wiggliness of the fit moving through data. The amounts of movement of Loess can also be controlled by the span arguemnt. You can also add your own formula to the smoothing function by passing it to the formula argument.\nAdding a geom_smooth() layer:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\nYou see the function curving in blue through the data and a gray shading around it.\nImportantly, you might want to apply another method of fit, for example a linear model, which you can achieve using method = \"lm\".\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nNow you see a line of best fit along with that gray shading again. That shading represents error variance in the model, which we will address in a topic on visualizing uncertainty. We can turn it off by setting se = FALSE.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nOf some plots, you may also not see the fit line through the entire plot. For example, changing the limits on the x axis, from 0 to 800 by adding plot layer, xlim(0, 800), will demonstrate a problem that you might experience and wish to fix.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() + \n  xlim(0, 800) +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe can change the default behavior using fullrange = T:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() + \n  xlim(0, 800) +\n  geom_smooth(method = \"lm\", \n              fullrange = T\n              )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe line now extends to the limets. geom_smooth() has many options but for now you see how we can plot points and add various fits to them."
  },
  {
    "objectID": "modules/10_visualizing_associations.html#geom_point-when-a-variable-is-a-factor",
    "href": "modules/10_visualizing_associations.html#geom_point-when-a-variable-is-a-factor",
    "title": "Visualizing associations",
    "section": "geom_point() when a variable is a factor",
    "text": "geom_point() when a variable is a factor\nPoint plots can all be used for plotting individual data points for categorical data.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point()\n\n\n\n\nYou see now that geom_point() will plot only the existing levels of Distance in the data set and provides the level label at each tick mark. If your goal is to change your tick marks for numeric data, this is not the solution because the scale will violate rules of mathematics.\n\nSetting aesthetic\nWe can change color, fill, shape, size, and alpha of points in the plot either by setting a constant or mapping color to an aesthetic. We will address setting here and mapping later.\nHere we plot open circles in black, filled with green, and make them somewhat transparent.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(shape = 21, \n             size = 3,\n             col = \"black\", \n             fill = \"green\",\n             alpha = .3\n             )\n\n\n\n\nThe procedure of mapping aesthetics introduces other variables from the data set into the plot. We do not need to change the color or shape of points for each event distance for the viewer to understand the plot. Position along x already communicates the distance. Mapping aesthetics of variables already present would confound the data and result in a plot that manipulates both position and color to communicate one variable, distance. This is not needed. By contrast, mapping variables that are not already present in the data introduces new information and complexity. These represent a different class of plots altogether."
  },
  {
    "objectID": "modules/10_visualizing_associations.html#multiclass-scatterplots",
    "href": "modules/10_visualizing_associations.html#multiclass-scatterplots",
    "title": "Visualizing associations",
    "section": "Multiclass Scatterplots",
    "text": "Multiclass Scatterplots\nThe typical xy scatter plot is used to visualize the relationship between two continuous variables. When your data vary in a different way and you don’t want to create a 3-dimensional plot (you really don’t want to anyway), you can map a third variable to the point plot to create a multiclass scatterplot that decorates the plot with a new aesthetic (e.g., color, size, transparency, etc.).\nIn most instances, you will want to map categorical variable to aesthetics like size or shape and numeric variables to aesthetics like size and alpha.\n\nMapping existing variables to aesthetics\nWe can map an existing variable to a new aesthetic. For example, Distance is already present in the plot but we can map it the color aesthetic. using aes(col = Distance). Well, because color may best be used or categorical variables, we will make it factor on the fly.\nUsing aes(col = factor(Distance)), we get:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = factor(Distance)),\n    alpha = .3,\n    position = \"jitter\"\n    )\n\n\n\n\nWe are not encoding a third variable in this plot but rather confounding color with an existing variable in the point plot. This approach can bias attention to particular subsets of the data unintentionally especially when some colors share properties with some colors used in the plot but not others.\nWe could also map an existing numeric variable to the color aesthetic. Using aes(col = factor(Distance)), we get:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = Distance),\n    alpha = .3,\n    position = \"jitter\"\n    )\n\n\n\n\nThe darker blue points are now associated with shorter distances, which itself may be conceptually difficult but the point here is that a data element can be mapped to an aesthetic.\nThese two examples, however, do not may new variables that introduce new information to understand subsets of the data.\n\n\nMapping new variables to aesthetics\nWe can map a new variable to the plot. Looking at the variables present, we can map School to the color in order to see whether time and distance are related in the same way across schools. The legend will be really big, so we will also remove it for now.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = School),\n    alpha = .5,\n    position = \"jitter\",\n    show.legend=F\n    )\n\n\n\n\nAnd for men and women:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(col = Team),\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    )\n\n\n\n\n\n\nAdding model fits using geom_smooth():\nIn order to see a linear association, however, we might want to fit a linear model to the subsets. We will need to make sure there are no factor() or as.character() functions for the variables or you will not see a line.\nSpecifically, we will use geom_smooth() to add a fit line to the plot.\nThe pattern for all schools:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(col = School),\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", se = F,\n    show.legend = F\n    )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe will that a line is fit through ALL of the data illustrating of course that time increases as a function of distance. Yes, this is silly but the main goal here is to understand how {ggplot} works.\nIn order to examine the linear fit pattern for all schools, we would map the School variable as an aesthetic to geom_smooth().\nNotice, however, that we are now passing aes(col = School) in geom_point() to make points for schools vary by color and in geom_smooth() to apply fit lines for each school. Remember that geom_*() aesthetics are inderited from ggplot() by default (e.g., inherit.aes = TRUE).\nLet’s just map aes(col = School) in ggplot() instead so that both geom_*()s inherit it.\nThe pattern across schools:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., \n         aes(x = Distance, y = Time, col = School),\n         ) +\n  geom_point(\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", se = F,\n    show.legend = F\n    )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nYou see that the linear fits are almost identical for the two schools. You can comment out show.legend = F to see the school names.\nWhat about across male and female swimmers?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000,\n         Team != \"Mixed\"\n         ) %&gt;%\n  ggplot(., \n         aes(x = Distance, y = Time, col = Team),\n         ) +\n  geom_point(\n    alpha = .5,\n    position = \"jitter\",\n    show.legend = F\n    ) +\n  geom_smooth(\n    method = \"lm\", se = F,\n    show.legend = F\n    )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe visualization now shows that the slope differs by subgroup, in particular that the slope is steeper for female swimmers. Again, comment out show.legend = F to see. We can add confidence intervals or error to the fit line on the plot but doing so is something we will deal with in the topic on visualizing uncertainty. That being said, the astute student of statistics should also know there is uncertainty to the lint-of-best-fit because it represents a fit of the current data, which may have sampling error. Bootstrapping the model fit will allow or visualization of uncertainty of the model fit.\n\n\nBubble Plots\nWhen the decorative element is point size, the plot type is referred to as a bubble plot and this is a special case of a multiclass scatterplot. Though some may refer to is as such, technically speaking, adding a color element is not bubble plot for obvious reasons.\n\n\nMapping existing variables to aesthetics\nWe will map a variable to the size aesthetic of the point plot. For now, don’t worry about arguments other than size.\nWe can map size = Time:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(size = Time),\n    alpha = .2,\n    position = \"jitter\"\n    )\n\n\n\n\nThe bubbles here simply represent the y variable mapped to the size aesthetic. We are not conveying a third variable in this plot but rather confounding size with an existing variable in the point plot. One thing to know is that the visual system loves size and to shading (e.g,. contrast). Both are present here, so be mindful of bias such a plot has on visual attention and perception. We will address such issues when we address concepts of attentional control.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(\n    aes(size = Time),\n    alpha = .2,\n    position = \"jitter\"\n    )\n\n\n\n\n\n\nMapping new variables to aesthetics\nWe will look at the data in a different way now. The data frame contains split times for the first 50. A split time is a time measurement of partial distance in swimming. For example, for a 200 meter event, you can measure split times for ways you a split the event (e.g., 25, 50, 100 meters). A swimmer who maintains the same time across splits is performing differently from one who swims at different paces across splits.\nLet’s look at split times for 50 meters as a function of distance. You will notice that Distance = 50 is dropped out of the plots because there is no split time.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Split50)) +\n  geom_point(\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nYou can see that the split times for the first 50 meters seems to increase as the distance of the event increases. Swimmers are pacing differently.\nAnd for splits and even time:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Split50, y = Time)) +\n  geom_point(\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLonger split times are associated with overall longer event times.\nMapping a new variable like Distance to point size will adjust the size of the points by the event distance.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Split50, y = Time)) +\n  geom_point(\n    aes(size = Distance),\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can see that the point diameter increases with distance. Although this bubble plot introduces a new variable, Distance, to the plot which was not visualized before, it really fails to communicate something useful in the data that was not already presented.\nWhat if we plotted Time as as function of Distance and mapped Split50 to the size aesthetic?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50),\n    alpha = .4,\n    position = \"jitter\"\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThis bubble plot now illustrates that the split times vary within the event distance and is associate with longer event times.\nAnd if we map event types to color:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event),\n    alpha = .3,\n    position = \"jitter\",\n    show.legend = F\n    )\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can see that the larger point sizes reflecting longer split times also appears to be associated with the event participated in. Notice the color palette used and the size of the points in the legend. Some color are difficult to differentiate when the alpha is dialed down. But without lowering alpha, the points would have a different problem. If this were a plot we wanted to share, we would need to fix it a lot. Later on, we will cover ways to change colors, the size of the points in the legend later, change the scale and tick marks on the axes, etc.\nYou can see how in some cases, bubble plots may be appropriate for presenting 4-Dimensional data for which two variables are numeric (X and Y), an additional variable is categorical and mapped to color (or shape) and another variable is numeric and mapped to size.\n{ggplot2}} will also provide warnings when applying a discrete variable to an aesthetic like size, for example, Using size for a discrete variable is not advised."
  },
  {
    "objectID": "modules/10_visualizing_associations.html#connected-scatterplots",
    "href": "modules/10_visualizing_associations.html#connected-scatterplots",
    "title": "Visualizing associations",
    "section": "Connected Scatterplots",
    "text": "Connected Scatterplots\nThere are instances when you may wish to visualize the order of events in a scatterplot. For example, the demand and price or a good may be associated but those may also change at different time points. These are sometimes presented as connected scatterplots.\nWhereas geom_line() will create a line between x and y data (imaging invisible points), geom_path() will connect those x and y positions to reveal other associations like the time pattern.\nLet’s compare the two functions using some made up data.\n\nDAT &lt;- data.frame(\n  x = c(1, 2, 3, 4, 5, 4, 7),\n  y = c(12, 16, 13, 15, 19, 20, 22),\n  label = c(2013:2019)\n  ) \n\nA geom_line():\n\nDAT %&gt;%\n  ggplot(., aes(x = x, y = y)) +\n  geom_line()\n\n\n\n\nA geom_path():\n\nDAT %&gt;%\n  ggplot(., aes(x = x, y = y)) +\n  geom_path(col = \"red\")\n\n\n\n\nAdding labels as text (and changing their color and size):\n\nDAT %&gt;%\n  ggplot(., aes(x = x, y = y)) +\n  geom_path(col = \"red\") +\n  geom_text(aes(label = label,\n                size = factor(label), \n                col = label)\n            )\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\nNote that geom_line() does not work well with the existing swim data. Points will be connected.\n\nSWIM %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_line()\n\n\n\n\nAnd geom_path() will connect the based on the order of the date but this type of plot is not relevant here as there is no order or time course.\n\nSWIM %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_path()"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html",
    "href": "modules/11_spatial_position_and_adjustment.html",
    "title": "Spatial position and adjustment",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#readings",
    "href": "modules/11_spatial_position_and_adjustment.html#readings",
    "title": "Spatial position and adjustment",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Overlapping points\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Overplotting"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#external-functions",
    "href": "modules/11_spatial_position_and_adjustment.html#external-functions",
    "title": "Spatial position and adjustment",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#libraries",
    "href": "modules/11_spatial_position_and_adjustment.html#libraries",
    "title": "Spatial position and adjustment",
    "section": "Libraries",
    "text": "Libraries\n\n{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{ggplot2} 3.4.3: for plotting"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#load-libraries",
    "href": "modules/11_spatial_position_and_adjustment.html#load-libraries",
    "title": "Spatial position and adjustment",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#default-point-position",
    "href": "modules/11_spatial_position_and_adjustment.html#default-point-position",
    "title": "Spatial position and adjustment",
    "section": "Default Point Position",
    "text": "Default Point Position\nWe will use the SWIM data from 2023 to manipulate point position. To illustrate the effect best, we will also trim out some long times/events.\nFirst, we should remind ourselves that the default setting for points plotting using geom_point() is the “identity” for the x and y mappings.\nThe default position argument is position = \"identity\":*\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = \"identity\")"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#adjusting-point-position",
    "href": "modules/11_spatial_position_and_adjustment.html#adjusting-point-position",
    "title": "Spatial position and adjustment",
    "section": "Adjusting Point Position",
    "text": "Adjusting Point Position\nThere are two main ways of adjusting the spatial position for point plots. One solution is to adjust the position argument within geom_point() and the other is to use a sister function geom_jitter(). However, you adjust your data, you must acknowledge that you are the creator of the graphic and that are are making the decision to change those point positioning. The adjustment will influence how users perceive, attend to, and interpret the visualization you produce and distribute. You must consider the degree of the adjustment and weigh the costs and benefits of “massaging” the data visualized. You also much assume responsibility and accountability for doing so.\n\ngeom_point(position = \"jitter\")\ngeom_jitter()\n\n\nChanging the position argument of geom_point()\nUsing gome_point(), we can pass position = \"jitter\" instead of position = \"identity\":\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = \"jitter\")\n\n\n\n\n\n\nUsing geom_jitter()\nWe can use geom_jitter() to jitter the points for us. The default argument for position adjustment in this function is position = \"jitter\". For more details, you can read the documentation of geom_jitter().\nUsing geom_jitter() rather than geom_point():\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_jitter()\n\n\n\n\n\nCustomizing jitter spread\nGiven position = \"jitter\" applies a stochastic function to reposition points along both x and y axes, one should not be surprised that to see functions contain arguments allowing for more control over movement along each axis (e.g., height and width).\nIn general, smaller values passed to these arguments will result in less dispersion of the points from their original positions. For both arguments, a jittering of points is applied in both positive and negative directions, so the total spread is twice the value specified in the argument. For example, passing width = 1 will jitter points having an “identity” position of x along that x axis, ranging from x - 1 to x + 1. You should also be mindful of the scales because an adjustment of 1 on some scales will be minimal and an adjustment of .3 on other scales may be quite dramatic. For example, on these scales, you really wont perceive much change if you used .3.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_jitter(height = 5, \n              width  = 10\n              )\n\n\n\n\nDespite setting these arguments to values, keep in mind that they do not control all points in exactly the same manner each time. The function still has some random component to it, so you will not be able to reproduce the plot with any consistency. We will address the topic of plot replication versus reproduction later.\n\n\n\nChanging the position of a categorical variable\nAnother limitation that you see in this example is the limited movement of the points. They are fairly locked along the Distance variable. Part of the reason is that these values are discrete, or categorical rather than continuous so the movement is very constrained relative to what you might normally see in a numeric by numeric scatterplot.\nLet’s change Distance to a character (e.g,. is.character()) or a factor (e.g., factor(), as.factor(), etc.) on the fly inside ggplot():\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point()\n\n\n\n\nYou will immediately notice that the x axis has changed. Disregard the label change as that is a simple fix with xlab(\"Distance\") and is irrelevant to this current discussion. Importantly, factorizing the variable will make visible all levels of the factor variable present in the data. For example, you now see 50 which was not displayed before. This outcome illustrates the difference in default scale_*() functions for numeric and categorical data but we will address scale manipulations later. You will also notice that the interval between factor levels is equivalent along the x axis despite them not being numerically equal by nature. That behavior is a trade off by default which you can fix should you consider the perceptual implications of this approach problematic.\nThe main point here is to illustrate position manipulation. Let’s use geom_jitter() for comparison.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter() \n\n\n\n\nBy default, you see sufficient movement in points, which may be too much or too little jitter depending on the data. We can adjust the height and width of the jitter here too but notice the value change when the variable is a factor.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = 2,\n              height = 0\n              )\n\n\n\n\nLet’s pass larger values:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = 5,\n              height = 0\n              )\n\n\n\n\nAnd larger values:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = 10,\n              height = 0\n              )\n\n\n\n\nThe more you jitter, the more the data take a position different from their “identity”. The adjustment is obviously more misleading when made on Time variable. Let’s dial the movement down a bit using a decimal value:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_jitter(width = .3,\n              height = 0\n              )\n\n\n\n\nYou will see that the height position did not change but the width did. Note that for categorical data (e.g., characters and factors), a width adjustment of 0.5 will jitter points in a way that makes them difficult if not impossible to determine the category level they belong to. In other words, the points from the levels of Distance overlap even though they should not. The last plot is the only one of those above that jitters in a way that still allows you to the the groups from which the data belong.\nAs a final note, be mindful of jitter adjustments applied by default. If you have a discrete variable, jitter along the corresponding axis and leave the other at 0. If both x and y are numeric/continuous, jitter only enough to fix your problem without altering the data more than necessary because otherwise you are lying with data visualizations whether intentionally or unintentionally so.\n\n\nReproducing Plots\nYou can observe the behavior of the functions used above by replicating the function calls. By doing so, you will see that the position of the points changed across those calls. Although we can replicate a procedure to address overplotting, we can not do so in a way that makes the position reproducible across multiple function calls because of the stochastic function applied to do so.\nBy reproduction, we mean that you return the same plot for every single call of the same code. Reproduction minimizes the confusion that occurs when your visualization changes when presented to your audience (including you) on different occasions.\n\nSetting a seed in geom_point()\nIn order to reproduce point position instead of replicating something very similar, use position_jitter() along with the seed argument. The seed determines the calculation of the jitter, so setting it will result in returning the same plot every single call.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15)\n             )\n\n\n\n\nFor this reason, I recommend using geom_point() over geom_jitter()."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#adjusting-point-transparency",
    "href": "modules/11_spatial_position_and_adjustment.html#adjusting-point-transparency",
    "title": "Spatial position and adjustment",
    "section": "Adjusting Point Transparency",
    "text": "Adjusting Point Transparency\nWhen points are opaque, your only option is to change their position. But changing position means changing the data from identity to something else. This may not be your first line of attack.\nNow that we have set a seed or reproduction, we can also adjust the transparency of the points by passing values from 0 to 1 to the alpha argument. In conjunction with position adjustments, alpha adjustments will facilitate the perception of two points (compared with one) with minimal position adjustment.\nBy default points are opaque, alpha = 1:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = 1)\n\n\n\n\nAnd can be made invisible by passing alpha = 0:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = 0)\n\n\n\n\nValues in between can be used to find the correct balance between points being too transparent, too dark, and too difficult to see when multiple points take the same position. Of course, with this data example, the identity of all points are the same at each level of the event by nature. As a result, you see a lot of variation that is not really present in the data.\nToo light to perceive?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = .2)\n\n\n\n\nToo dark to discriminate?\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = .4)\n\n\n\n\nKeep in mind also that alpha transparency will interact with point color, so there is never a particular rule of thumb."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#adding-group-level-data",
    "href": "modules/11_spatial_position_and_adjustment.html#adding-group-level-data",
    "title": "Spatial position and adjustment",
    "section": "Adding Group Level Data",
    "text": "Adding Group Level Data\nOne problem with all the points is the inability to either see or process all of the points in the plot. Extracting out mean Time for the Distance variable is quite the cognitive task.\nRemember that {ggplot} allows for adding layers to plots. We have shown how to add a geom_point() and a geom_bar() to the same plot using the same data. But we could also add the a geom that presents a new data frame. For example, we could obtain the mean Time for each Distance and pass that data frame as a separate geom_point() layer.\nLet’s first get the summarized data frame:\n\nMEAN_TIMES_BY_DIST &lt;- SWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  group_by(., Distance) %&gt;%\n  summarize(., Time = mean(Time))\n\nWe see the association at the group level too.\n\nMEAN_TIMES_BY_DIST %&gt;% knitr::kable()\n\n\n\n\nDistance\nTime\n\n\n\n\n50\n23.59429\n\n\n100\n55.19567\n\n\n200\n121.51304\n\n\n400\n268.98667\n\n\n500\n305.51333\n\n\n\n\n\nNow let’s add that layer and make the points “tomato” colored:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 15),\n             alpha = .4) +\n  geom_point(data = MEAN_TIMES_BY_DIST,\n             mapping = aes(x = Distance, Time),\n             col = \"tomato\", \n             size = 4, \n             alpha = .7)\n\n\n\n\nWe could do the same thing for the counts:\n\nCOUNTS_BY_DIST &lt;- SWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  group_by(., Distance) %&gt;%\n  summarize(., \n            Count = dplyr::n(),\n            Time = mean(Time)\n            )\n\nWe now have a data frame that contains the mean Time and the Count for events. We can add a geom_point() layer that plots the mean Time as a point that varies in size corresponding to the Count.\n\nCOUNTS_BY_DIST %&gt;% knitr::kable()\n\n\n\n\nDistance\nCount\nTime\n\n\n\n\n50\n14\n23.59429\n\n\n100\n67\n55.19567\n\n\n200\n79\n121.51304\n\n\n400\n3\n268.98667\n\n\n500\n6\n305.51333\n\n\n\n\n\nUsing some new aesthetics for geom_point(), we illustrate the addition of the plot here.\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 10),\n             alpha = .4) +\n  geom_point(data = COUNTS_BY_DIST, \n             mapping = aes(size = Count),\n             shape   = 21, # open circle\n             col     = \"black\",\n             fill    = \"tomato\",\n             #stroke = 1, # makes outer ring of 21 thicker\n             alpha   = .65) +\n  theme_minimal()\n\n\n\n\nRemember that plot layer matters. Different orders of layers will render different plots.\nLet’s change the geom layer order and change alpha for each geom:\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(data = COUNTS_BY_DIST, \n             mapping = aes(size = Count),\n             shape   = 21, # open circle\n             col     = \"black\",\n             fill    = \"tomato\",\n             #stroke = 1, # makes outer ring of 21 thicker\n             alpha   = 1) +\n  geom_point(position = position_jitter(seed = 167,\n                                        height = 0,\n                                        width = 10),\n             alpha = .3) +\n  theme_minimal()"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#adjusting-point-size",
    "href": "modules/11_spatial_position_and_adjustment.html#adjusting-point-size",
    "title": "Spatial position and adjustment",
    "section": "Adjusting Point Size",
    "text": "Adjusting Point Size\nAnother option to overcome overplotting is to create what is known as a counts chart. Wherever there is more point overlap, the size of the circle gets bigger. Some people use a geom_count() for this approach. The default statistical transformation for geom_count() is stat = \"sum\", which sums up the count of the points in order to plot points of sizes relative to their counts. Although presenting larger points does not really fall perfectly under the topic of position adjustment, larger points do in fact take up more space on the plot, so in a way they are an adjustment of a point’s spatial position. When using geom_count(), however, you have to tinker a little when you also want to jitter points because by default position = \"jitter\" will also cause your sized points jitter, which is confusing. If size of points can be used, you may find adding a second geom_point() that uses summarized data to be a more intuitive solution."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#creating-a-stacked-bar-plot",
    "href": "modules/11_spatial_position_and_adjustment.html#creating-a-stacked-bar-plot",
    "title": "Spatial position and adjustment",
    "section": "Creating a stacked bar plot",
    "text": "Creating a stacked bar plot\nLet’s add the School variable to the plot using aes(fill = School) to the geom_*() layer:\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event)\n         ) +\n  geom_bar(aes(fill = School))\n\n\n\n\nWe can also have the aesthetic inherited from ggplot() if aes(fill = School) is defined as part of ggplot():\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar()\n\n\n\n\nThe bars take on different representations as you can see. You can also plot the counts with a different aesthetic combination.\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = School, \n                       fill = Event\n                       )\n         ) +\n  geom_bar()\n\n\n\n\nNotice that with stacked bars, you encode the count as the length of the colored rectangle. For the user to compare counts for comparisons, they can use the height position for the first stack only because the bars are on an aligned scale. The other bars in the stack do not have the same starting an ending points. These bars on on an unaligned scale, which makes the decoding task more difficult for the user. In addition to this alignment issue, the bars may also encourage decoding of area, which is also a challenging cognitive task that leads to perceptual errors. For discussion of more of these perceptual issues, see Cleveland & McGill (1984). Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods.\nWhen you want to facilitate comparisons of bars, you might want to change their positions by creating a grouped bar plot."
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#creating-a-grouped-bar-plot",
    "href": "modules/11_spatial_position_and_adjustment.html#creating-a-grouped-bar-plot",
    "title": "Spatial position and adjustment",
    "section": "Creating a grouped bar plot",
    "text": "Creating a grouped bar plot\nStacking is not always the desired outcome. We often want to see the bars for the subgroups. We will need to override the default position. Dodging is a general way to correct for overlapping objects, whether points, bars, box plots, etc. You can practice using it with geom_point() but we will use it here for bars. Specifically, we will override the default position argument, position = \"stacked\" and make is position = \"dodge\" so that the bar positions dodge each other.\nDodging a geom_*() like bars, points, or rectangles, will preserve their vertical position while also adjusting their horizontal position.\nBesides the examples illustrated below, you can find more examples in the tidyverse documentation.\ngeom_bar(position = \"dodge\")\n\nposition = \"dodge\"\nposition = \"dodge2\": adds padding to bars\nposition = position_dodge(): with padding control etc.\nposition = position_dodge2(): with padding control etc.\n\nDefault behavior of position_dodge():\n\nd1_plot &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar(position = position_dodge(), show.legend = F)\n\nYou will need a grouping variable specified in the global or local geom_*() for position_dodge() whereas this is not a requirement for position_dodge2(). Moreover, position_dodge2() differs from position_dodge() insofar as it does not need a grouping variable in a layer and works with bars and rectangles. It it likely your go-to function for positioning box plots because you can adjust their widths.\nDefault behavior of position_dodge2():\n\nd2_plot &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar(position = position_dodge2(), show.legend = F)\n\nAdding a padding to position_dodge2():\n\nd3_plot &lt;- SWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Event, \n                       fill = School\n                       )\n         ) +\n  geom_bar(position = \n             position_dodge2(padding = .5), \n           show.legend = F)"
  },
  {
    "objectID": "modules/11_spatial_position_and_adjustment.html#plotting-a-grid-grob-graphic-object",
    "href": "modules/11_spatial_position_and_adjustment.html#plotting-a-grid-grob-graphic-object",
    "title": "Spatial position and adjustment",
    "section": "Plotting a Grid Grob (Graphic Object)",
    "text": "Plotting a Grid Grob (Graphic Object)\nWe can take the three objects and arrange them in a grid using gridExtra::arrangeGrob(). We can specify the number of colons and or rows as well. In this case, we can plot them all as a single column and they will appear in the order the plots are added in arrangeGrob().\n\nplot(gridExtra::arrangeGrob(d1_plot, \n                            d2_plot,\n                            d3_plot,\n                            ncol = 1)\n     )"
  },
  {
    "objectID": "modules/12_considerations_in_data_visualization.html",
    "href": "modules/12_considerations_in_data_visualization.html",
    "title": "Considerations in data visualization",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/12_considerations_in_data_visualization.html#readings",
    "href": "modules/12_considerations_in_data_visualization.html#readings",
    "title": "Considerations in data visualization",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. The principle of proportional ink\nWilke (2019). Fundamentals of Data Visualization. Common pitfalls of color use\nWilke (2019). Fundamentals of Data Visualization. Telling a story"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html",
    "href": "modules/13_color_scales_and_palettes.html",
    "title": "Color scales and palettes",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#readings",
    "href": "modules/13_color_scales_and_palettes.html#readings",
    "title": "Color scales and palettes",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Color basics\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Color scales"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#external-functions",
    "href": "modules/13_color_scales_and_palettes.html#external-functions",
    "title": "Color scales and palettes",
    "section": "External Functions",
    "text": "External Functions\nProvided in class:\nview_html(): for viewing data frames in html format, from /r/my_functions.R\nYou can use this in your own workspace but I am having a challenge rendering this of the website, so I’ll default to print() on occasion.\n\nsource(here::here(\"r\", \"my_functions.R\"))"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#libraries",
    "href": "modules/13_color_scales_and_palettes.html#libraries",
    "title": "Color scales and palettes",
    "section": "Libraries",
    "text": "Libraries\n\n{colorblindr} 0.1.0: for simulations of color vision deficiencies to ggplot2 objects; post-hoc color editing\n{colorspace} 2.1.0: for manipulating and assessing colors and color palettes\n{cowplot} 1.1.1: for ggplot add-ons; object management\n{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{ggplot2} 3.4.3: for plotting\n{ggthemes} 4.2.4: for palettes and themes\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{patchwork} 1.1.3: for plotting on grids\n{RColorBrewer} 1.1.3: for color palettes"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#load-libraries",
    "href": "modules/13_color_scales_and_palettes.html#load-libraries",
    "title": "Color scales and palettes",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(colorspace)\nlibrary(cowplot)\nlibrary(ggthemes)  # for scale_color_colorblind()\nlibrary(colorblindr)\nlibrary(khroma)"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#to-distinguish-categories-qualitative",
    "href": "modules/13_color_scales_and_palettes.html#to-distinguish-categories-qualitative",
    "title": "Color scales and palettes",
    "section": "To distinguish categories (qualitative)",
    "text": "To distinguish categories (qualitative)\n\nSWIM %&gt;%\n  ggplot(., aes(x = School, fill = Event)) +\n  geom_bar()"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#to-represent-numeric-values-sequential",
    "href": "modules/13_color_scales_and_palettes.html#to-represent-numeric-values-sequential",
    "title": "Color scales and palettes",
    "section": "To represent numeric values (sequential)",
    "text": "To represent numeric values (sequential)\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic()\n\n\n\n\nWhen no fill scale is defined, default is scale_fill_gradient(), which we can change to something else.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_fill_viridis_c()\n\n\n\n\nBut the function won’t change anything if we don’t use the proper scale_*_() function.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_viridis_c()\n\n\n\n\nOr:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_viridis_c(option = \"B\", begin = 0.15)"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#to-represent-numeric-values-diverging",
    "href": "modules/13_color_scales_and_palettes.html#to-represent-numeric-values-diverging",
    "title": "Color scales and palettes",
    "section": "To represent numeric values (diverging):",
    "text": "To represent numeric values (diverging):\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_gradient2()\n\n\n\n\nOr:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_diverging() \n\n\n\n\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_distiller(type = \"div\")\n\n\n\n\nThere are other applications too but we cannot get into them all here."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#color-scales-built-into-ggplot2",
    "href": "modules/13_color_scales_and_palettes.html#color-scales-built-into-ggplot2",
    "title": "Color scales and palettes",
    "section": "Color Scales Built into {ggplot2}",
    "text": "Color Scales Built into {ggplot2}\nThere are colors built into {ggplot2}. The scale_*() functions will also following the naming conventions scale_color_*() or scale_fill_*(). When you have bars, remember that you are changing fill color and with solid circle points you are changing col so your go-to functions should adhere to those naming conventions (e.g., scale_fill_*() and scale_color_*()). Some examples include: scale_color_brewer() or scale_color_distiller() for discrete or continuous scales, respectively.\n{ggplot} functions:\n\nscale_color_hue(): color, data: discrete, palette: qualitative\nscale_fill_hue(): fill, data: discrete, palette: qualitative\nscale_color_gradient(): color, data: continuous, palette: sequential\nscale_color_gradient2(): color, data: continuous, palette: diverging\nscale_fill_viridis_c(): color, data: continuous, palette: sequential\nscale_fill_viridis_d(): fill, data: discrete, palette: sequential\nscale_color_brewer(): color, data: discrete , palette: qualitative, diverging, sequential\nscale_fill_brewer(): fill, data: discrete, palette: qualitative, diverging, sequential\nscale_color_distiller(): color, data: continuous, palette: qualitative, diverging, sequential"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#colorspace-color-palettes",
    "href": "modules/13_color_scales_and_palettes.html#colorspace-color-palettes",
    "title": "Color scales and palettes",
    "section": "{colorspace} Color Palettes",
    "text": "{colorspace} Color Palettes\n\ncolorspace::hcl_palettes(type = \"sequential\", plot = TRUE) # all sequential palettes\n\n\n\n\n\ncolorspace::hcl_palettes(type = \"diverging\", plot = TRUE, n = 9) # all diverging palettes\n\n\n\n\n\ncolorspace::divergingx_palettes(plot = TRUE, n = 9) # all divergingx palettes"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#example-plots",
    "href": "modules/13_color_scales_and_palettes.html#example-plots",
    "title": "Color scales and palettes",
    "section": "Example plots",
    "text": "Example plots\nWe can then specify the function according to our goal using: scale_&lt;aesthetic&gt;_&lt;datatype&gt;_&lt;colorscale&gt;(). We can see an example with filling points.\nContinuous:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous()\n\n\n\n\nContinuous and Sequential:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n#  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_sequential()\n\n\n\n\nDiscrete and Sequential:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = School)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_discrete_sequential()\n\n\n\n\nA specific palette added: palette = \"Inferno\"\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n#  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Time)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_sequential(palette = \"Inferno\")\n\n\n\n\nContinuous and Diverging:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000, Time &lt; 200) %&gt;%\n  filter(., Event == \"Freestyle\") %&gt;%\n  mutate(., Diff = (Time - mean(Time, na.rm = T))) %&gt;%\n  ggplot(., aes(x = Event, y = Time, col = Diff)) +\n  geom_point(position = position_jitter()) + theme_classic() +\n  scale_color_continuous_diverging()"
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#exploring-colorspace",
    "href": "modules/13_color_scales_and_palettes.html#exploring-colorspace",
    "title": "Color scales and palettes",
    "section": "Exploring {colorspace}",
    "text": "Exploring {colorspace}\nFor a dynamic exploration use colorspace::hcl_wizard(), which is a {shiny} app . When you are done exploring, click the “Return to R” box.\n\nColor Picker\n{colorspace} also has a color picker function, colorspace::hclcolorpicker() which will allow you to pick color and obtain the hexidecimal color codes. You can also obtain html color names and rgb codes for colors at websites like htmlcolorcodes.com. With recent updates to RStudio, color names written as character strings when typed in the console or in files will display the color. Hint: you must type the names in lowercase (e.g., “mediumseagreen. If the color is not known by its name, then you won’t see the background string color change."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#discrete-qualitative-scales",
    "href": "modules/13_color_scales_and_palettes.html#discrete-qualitative-scales",
    "title": "Color scales and palettes",
    "section": "Discrete, qualitative scales",
    "text": "Discrete, qualitative scales\nDiscrete, qualitative scales are sometimes best set manually.\nAn example using default color palette:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1000) %&gt;%\n  ggplot(., aes(x = Distance, y = Time, color = School)) +\n  geom_point(position = position_jitter()) +\n  scale_color_hue()\n\n\n\n\nNow consider the following plot.\n\nSWIM %&gt;%\n  ggplot(., aes(x = School, y = Time, fill = Event)) + \n  geom_col() \n\n\n\n\nTo set the color, add a layer:\nFor the hue, scale_&lt;datatype&gt;_hue() could be scale_colour_hue() or scale_fill_hue(). The two function are listed below.\nscale_colour_hue(\n  ...,\n  h = c(0, 360) + 15,\n  c = 100,\n  l = 65,\n  h.start = 0,\n  direction = 1,\n  na.value = \"grey50\",\n  aesthetics = \"colour\"\n)\n\nscale_fill_hue(\n  ...,\n  h = c(0, 360) + 15,\n  c = 100,\n  l = 65,\n  h.start = 0,\n  direction = 1,\n  na.value = \"grey50\",\n  aesthetics = \"fill\"\n)\nWhen you are trying to customize a plot for a client or find issue with the color palettes out-of-the-box, scale_color_manual() or scale_fill_manual() are likely your best friends. As you see in the functions, you need to pass some color values. This is a vector of color by name or hexidecimal code.\nscale_colour_manual(\n  ...,\n  values,\n  aesthetics = \"colour\",\n  breaks = waiver(),\n  na.value = \"grey50\"\n)\n\nscale_fill_manual(\n  ...,\n  values,\n  aesthetics = \"fill\",\n  breaks = waiver(),\n  na.value = \"grey50\"\n)\nBut you need to know how values are mapped to subgroups. How many subgroups are there and what are they?\n\nglimpse(SWIM) \n\nRows: 201\nColumns: 10\n$ Year     &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2…\n$ School   &lt;chr&gt; \"Pomona-Pitzer-CA\", \"Claremont-Mudd-Scripps-CA\", \"Claremont-M…\n$ Team     &lt;chr&gt; \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\"…\n$ Relay    &lt;chr&gt; \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\"…\n$ Distance &lt;dbl&gt; 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 2…\n$ Name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"…\n$ Age      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2…\n$ Event    &lt;chr&gt; \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"…\n$ Time     &lt;dbl&gt; 97.74, 101.34, 101.64, 102.21, 102.83, 102.93, 103.55, 103.63…\n$ Split50  &lt;dbl&gt; 26.35, 24.40, 24.06, 24.99, 24.37, 27.46, 28.54, 26.75, 25.77…\n\nunique(SWIM$Event)\n\n[1] \"Medley\"       \"Freestyle\"    \"IM\"           \"Butterfly\"    \"Breaststroke\"\n[6] \"Backstroke\"  \n\n\nMake note of the order.\nThe order of the colors in the vector passes to values will map to the order of the levels in the data frame. We can demonstrate this by changing the data frame arrangement.\nSorting by ascending or descending order changes the data frame.\n\nSWIM %&gt;% select(., Event) %&gt;% unique()\n\n# A tibble: 6 × 1\n  Event       \n  &lt;chr&gt;       \n1 Medley      \n2 Freestyle   \n3 IM          \n4 Butterfly   \n5 Breaststroke\n6 Backstroke  \n\nSWIM %&gt;% arrange(., desc(Event)) %&gt;% select(., Event) %&gt;% unique()\n\n# A tibble: 6 × 1\n  Event       \n  &lt;chr&gt;       \n1 Medley      \n2 IM          \n3 Freestyle   \n4 Butterfly   \n5 Breaststroke\n6 Backstroke  \n\n\nSo how you sort the data frame matters, right? No. \nIs this vector a factor? Note, you can also see this using glimpse().\n\nis.factor(SWIM$Event)\n\n[1] FALSE\n\n\n\nglimpse(SWIM)\n\nRows: 201\nColumns: 10\n$ Year     &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2…\n$ School   &lt;chr&gt; \"Pomona-Pitzer-CA\", \"Claremont-Mudd-Scripps-CA\", \"Claremont-M…\n$ Team     &lt;chr&gt; \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\", \"Mixed\"…\n$ Relay    &lt;chr&gt; \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\", \"Relay\"…\n$ Distance &lt;dbl&gt; 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 2…\n$ Name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"…\n$ Age      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2…\n$ Event    &lt;chr&gt; \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"Medley\", \"…\n$ Time     &lt;dbl&gt; 97.74, 101.34, 101.64, 102.21, 102.83, 102.93, 103.55, 103.63…\n$ Split50  &lt;dbl&gt; 26.35, 24.40, 24.06, 24.99, 24.37, 27.46, 28.54, 26.75, 25.77…\n\n\nWhat are the levels?\n\nlevels(SWIM$Event)\n\nNULL\n\n\nThe levels() function will only return levels if the vector is a factor.\nLet’s change the variable in the data frame:\n\nSWIM &lt;- SWIM %&gt;% mutate(., Event = factor(Event))\n\n\nlevels(SWIM$Event)\n\n[1] \"Backstroke\"   \"Breaststroke\" \"Butterfly\"    \"Freestyle\"    \"IM\"          \n[6] \"Medley\"      \n\nnum_events &lt;- length(levels(SWIM$Event))\n\n\nis.ordered(SWIM$Event)\n\n[1] FALSE\n\n\nSo it is not an ordered factor but it does have an order and that order will affect the plot.\nThe colors in the vector passed to values will map onto the order of the levels as displayed by levels().\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#reverse-the-using-rev",
    "href": "modules/13_color_scales_and_palettes.html#reverse-the-using-rev",
    "title": "Color scales and palettes",
    "section": "Reverse the using rev()",
    "text": "Reverse the using rev()\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = rev(Event))) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nSomething is wrong. Double check your data and labels."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#mutate-to-change-the-order-of-levels",
    "href": "modules/13_color_scales_and_palettes.html#mutate-to-change-the-order-of-levels",
    "title": "Color scales and palettes",
    "section": "mutate() to change the order of levels",
    "text": "mutate() to change the order of levels\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  mutate(., Event = factor(Event, \n                           levels = c(\"Freestyle\", \"Breaststroke\", \n                                      \"Butterfly\", \"Backstroke\",\n                                      \"IM\", \"Medley\"\n                                      ))\n         ) %&gt;% \n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nOK, so we see that the color changes because the order of the levels changed. They are reordered in the plot legend."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#mutate-to-make-it-an-ordered-factor",
    "href": "modules/13_color_scales_and_palettes.html#mutate-to-make-it-an-ordered-factor",
    "title": "Color scales and palettes",
    "section": "mutate() to make it an ordered factor",
    "text": "mutate() to make it an ordered factor\nThe order of the labels does not make a factor ordered. We need to do something special to accomplish that, which we will do here. However, the example is arbitrary here as there is not order or ranking to how I arrange them.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  mutate(., Event = factor(Event, \n                           levels = c(\"Freestyle\", \"Breaststroke\", \n                                      \"Butterfly\", \"Backstroke\",\n                                      \"IM\", \"Medley\"\n                                       ),\n                           ordered = T)\n         ) %&gt;% \n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#change-the-labels-for-the-levels",
    "href": "modules/13_color_scales_and_palettes.html#change-the-labels-for-the-levels",
    "title": "Color scales and palettes",
    "section": "Change the labels for the levels",
    "text": "Change the labels for the levels\nPass a vector of equal length with label names.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  mutate(., Event = factor(Event, \n                           levels = c(\"Freestyle\", \"Breaststroke\", \n                                      \"Butterfly\", \"Backstroke\",\n                                      \"IM\", \"Medley\"\n                                       ),\n                           labels = c(\"Free\", \"Breast\", \"Fly\",\n                                      \"Back\", \"IM\", \"Medley\"))\n         ) %&gt;% \n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(\"#E69F00\", \"#1E90FF\", \"#009E73\", \n               \"#FFD700\", \"maroon\", \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nColors didn’t change but labels did."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#pair-a-color-with-a-level",
    "href": "modules/13_color_scales_and_palettes.html#pair-a-color-with-a-level",
    "title": "Color scales and palettes",
    "section": "Pair a Color with a Level",
    "text": "Pair a Color with a Level\nI’m not going to get into why this approach is actually a vector but you can test it if you want.\n\nis.vector(c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n            Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n            IM = \"maroon\", Medley = \"gray\"))\n\n[1] TRUE\n\n\nPass a vector of names and color values.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(\n    values = c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n               Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n               IM = \"maroon\", Medley = \"gray\")\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/13_color_scales_and_palettes.html#pass-a-vector-of-colors",
    "href": "modules/13_color_scales_and_palettes.html#pass-a-vector-of-colors",
    "title": "Color scales and palettes",
    "section": "Pass a vector of colors",
    "text": "Pass a vector of colors\nChanging the colors inside the function can be annoying so you might just create a vector object to pass to values.\n\ncolor_vector &lt;- c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n                  Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n                  IM = \"maroon\", Medley = \"gray\")\n  \nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector)\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nVectors containing additional name elements\nIf that vector contains names that are not in the variable vector, then the function will not break. Rather, colors will show for level in the data only. We are going to save this plot object to use later.\n\ncolor_vector &lt;- c(Freestyle = \"#E69F00\", Breaststroke = \"#1E90FF\",\n                  Butterfly = \"#009E73\", Backstroke = \"#FFD700\", \n                  IM = \"maroon\", Medley = \"gray\",\n                  SomethingNew = \"blue\"\n                  )\n\n(SWIM_plot &lt;- SWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector)\n)\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nVectors missing name elements\nBut when names in the data vector are not in the color vector, something interesting happens.\n\n(color_vector &lt;- color_vector[1:3])\n\n   Freestyle Breaststroke    Butterfly \n   \"#E69F00\"    \"#1E90FF\"    \"#009E73\" \n\n\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector)\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFirst, and most obviously, the missing pair is dropped from the legend. So the data points are stripped from the plot too, right? Look closer. No! They are in a there but plotting as \"grey50\". This happens because the default setting na.value = \"grey50\".\nThere is also no warning, so double check your plots!\nMore dramatically, show only the first color element.\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector[1])\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\ncolor_vector\n\n   Freestyle Breaststroke    Butterfly \n   \"#E69F00\"    \"#1E90FF\"    \"#009E73\" \n\nwhich(names(color_vector) == \"Freestyle\")\n\n[1] 1\n\n\nThis approach can be useful if you want to color only certain events by their name. The goal would be to determine which color corresponds to the Freestyle and plot only that. But remember, there are names in the vector and color values.\n\ncolor_vector\n\n   Freestyle Breaststroke    Butterfly \n   \"#E69F00\"    \"#1E90FF\"    \"#009E73\" \n\nnames(color_vector)\n\n[1] \"Freestyle\"    \"Breaststroke\" \"Butterfly\"   \n\n\nWe need to find out the color position corresponding to the name position Using which() we can evaluate the names to determine which position is the Freestyle.\n\nwhich(names(color_vector) == \"Freestyle\")\n\n[1] 1\n\n\nWhat we get returned is position 1. Of course, you knew that but something might change and if it moves position based on a reordering, then hard coding won’t work.\nTo obtain the color associated with element position 1, use [] notation after the vector.\n\ncolor_vector[1] # hard coded solution\n\nFreestyle \n\"#E69F00\" \n\ncolor_vector[which(names(color_vector) == \"Freestyle\")] # flexible solution\n\nFreestyle \n\"#E69F00\" \n\n\nPutting it all together, pass that to values:\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector[which(\n    names(color_vector) == \"Freestyle\")]\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAnd if you wanted more than one event, evaluate with %in% rather than ==. For example, names(color_vector) %in% c(\"Freestyle\", \"Butterfly\").\n\nSWIM %&gt;%\n  filter(., Distance &lt; 300) %&gt;%\n  ggplot(., aes(x = Split50, y = Time, color = Event)) +\n  geom_point() +\n  scale_color_manual(values = color_vector[which(\n    names(color_vector) %in% c(\"Freestyle\", \"Butterfly\"))]\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html",
    "href": "modules/14_histograms_and_density_plots.html",
    "title": "Histograms and density plots",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/14_histograms_and_density_plots.html#readings",
    "href": "modules/14_histograms_and_density_plots.html#readings",
    "title": "Histograms and density plots",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing distributions: Histograms and density plots"
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html",
    "href": "modules/15_coordinates_axes_and_position_scales.html",
    "title": "Coordinates, axes, and position scales",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/15_coordinates_axes_and_position_scales.html#readings",
    "href": "modules/15_coordinates_axes_and_position_scales.html#readings",
    "title": "Coordinates, axes, and position scales",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\nhttps://clauswilke.com/dataviz/coordinate-systems-axes.html"
  },
  {
    "objectID": "modules/16_statistical_transformations.html",
    "href": "modules/16_statistical_transformations.html",
    "title": "Statistical transformations",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/16_statistical_transformations.html#readings",
    "href": "modules/16_statistical_transformations.html#readings",
    "title": "Statistical transformations",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Weighting data\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Stats"
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html",
    "href": "modules/17_visualizing_more_distributions.html",
    "title": "Visualizing more distributions",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/17_visualizing_more_distributions.html#readings",
    "href": "modules/17_visualizing_more_distributions.html#readings",
    "title": "Visualizing more distributions",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing distributions: Visualizing many distributions at once"
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html",
    "href": "modules/18_visualizing_uncertainty.html",
    "title": "Visualizing uncertainty",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/18_visualizing_uncertainty.html#readings",
    "href": "modules/18_visualizing_uncertainty.html#readings",
    "title": "Visualizing uncertainty",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing uncertainty\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Uncertainty"
  },
  {
    "objectID": "modules/19_visualizing_trends.html",
    "href": "modules/19_visualizing_trends.html",
    "title": "Visualizing trends",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/19_visualizing_trends.html#readings",
    "href": "modules/19_visualizing_trends.html#readings",
    "title": "Visualizing trends",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Visualizing Trends\n\nOptional:\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Time series"
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html",
    "href": "modules/20_legends_and_arrangement.html",
    "title": "Legends and arrangement",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/20_legends_and_arrangement.html#readings",
    "href": "modules/20_legends_and_arrangement.html#readings",
    "title": "Legends and arrangement",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Redundant coding"
  },
  {
    "objectID": "modules/21_designing_perceptually_efficient_visualizations.html",
    "href": "modules/21_designing_perceptually_efficient_visualizations.html",
    "title": "Designing perceptually-efficient visualizations",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/21_designing_perceptually_efficient_visualizations.html#readings",
    "href": "modules/21_designing_perceptually_efficient_visualizations.html#readings",
    "title": "Designing perceptually-efficient visualizations",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nFranceroni et al. (2012). The Science of Visual Data Communication: What Works.\nXiong et a. (2023). Seeing What You Believe or Believing What You See? Belief Biases Correlation Estimation.\n\nOptional (for the intellectually curious): - Szafir et al. (2016). Four types of ensemble coding in data visualizations. - Xiong et al. (2021). Visual Arrangements of Bar Charts Influence Comparisons in Viewer Takeaways."
  },
  {
    "objectID": "modules/22_annotation_and_text.html",
    "href": "modules/22_annotation_and_text.html",
    "title": "Annotation and text",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/22_annotation_and_text.html#readings",
    "href": "modules/22_annotation_and_text.html#readings",
    "title": "Annotation and text",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Annotations"
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html",
    "href": "modules/23_multi_panel_plots_faceting.html",
    "title": "Multi-panel plots: Faceting",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/23_multi_panel_plots_faceting.html#readings",
    "href": "modules/23_multi_panel_plots_faceting.html#readings",
    "title": "Multi-panel plots: Faceting",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Multi-panel figures\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Faceting"
  },
  {
    "objectID": "modules/24_attentional_control.html",
    "href": "modules/24_attentional_control.html",
    "title": "Attentional control",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/24_attentional_control.html#readings",
    "href": "modules/24_attentional_control.html#readings",
    "title": "Attentional control",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Balance the data and the context\nWilke (2019). Fundamentals of Data Visualization. Use larger axis labels\nAjani et al. (2022). Declutter and Focus: Empirically Evaluating Design Guidelines for Effective Data Communication"
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html",
    "href": "modules/25_titles_captions_and_tables.html",
    "title": "Title, Captions, and Tables",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/25_titles_captions_and_tables.html#readings",
    "href": "modules/25_titles_captions_and_tables.html#readings",
    "title": "Title, Captions, and Tables",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWilke (2019). Fundamentals of Data Visualization. Titles, captions, and tables"
  },
  {
    "objectID": "modules/26_themes.html",
    "href": "modules/26_themes.html",
    "title": "Figure Design & Themes",
    "section": "",
    "text": "Under construction.\n\n\n\nThis page is a work in progress and may contain areas that need more detail or that required syntactical, grammatical, and typographical changes. If you find some part requiring some editing, please let me know so I can fix it for you."
  },
  {
    "objectID": "modules/26_themes.html#readings",
    "href": "modules/26_themes.html#readings",
    "title": "Figure Design & Themes",
    "section": "Readings",
    "text": "Readings\nReading should take place in two parts:\n\nPrior to class, the goal should be to familiarize yourself and bring questions to class. The readings from TFDV are conceptual and should facilitate readings from EGDA for code implementation.\nAfter class, the goal of reading should be to understand and implement code functions as well as support your understanding and help your troubleshooting of problems.\n\nBefore Class: First, read to familiarize yourself with the concepts rather than master them. Understand why one would want to visualize data in a particular way and also understand some of the functionality of {ggplot2}. I will assume that you attend class with some level of basic understanding of concepts.\nClass: In class, some functions and concepts will be introduced and we will practice implementing {ggplot2} code. On occasion, there will be an assessment involving code identification, correction, explanation, etc. of concepts addressed in previous modules and perhaps some conceptual elements from this week’s readings.\nAfter Class: After having some hands-on experience with coding in class, homework assignments will involve writing your own code to address some problem. These problems will be more complex, will involving problem solving, and may be open ended. This is where the second pass at reading with come in for you to reference when writing your code. The module content presented below is designed to offer you some assistance working through various coding problems but may not always suffice as a replacement for the readings from Wickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e).\n\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Themes(https://ggplot2-book.org/themes)\nWickham, Navarro, & Pedersen (under revision). ggplot2: Elegant Graphics for Data Analysis (3e). Extensions(https://ggplot2-book.org/extensions)"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html",
    "title": "Importing many delimeted files into a single data frame",
    "section": "",
    "text": "{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{vroom}: 1.6.3: for reading many files\n\n\nlibrary(magrittr)"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html#libraries",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html#libraries",
    "title": "Importing many delimeted files into a single data frame",
    "section": "",
    "text": "{here}: 1.0.1: for path management\n{dplyr} 1.1.2: for selecting, filtering, and mutating\n{magrittr} 2.0.3: for code clarity and piping data frame objects\n{vroom}: 1.6.3: for reading many files\n\n\nlibrary(magrittr)"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html#get-the-file-names-by-pattern",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html#get-the-file-names-by-pattern",
    "title": "Importing many delimeted files into a single data frame",
    "section": "Get the File Names by Pattern",
    "text": "Get the File Names by Pattern\nLooking at the pattern of file names for field events, you see .csv file names containing patterns like “DT”, “HT”, “JT”, “LJ”, “PV”, “LJ”, “SP”, and “TJ”. Double check that you have all event name types. I would also recommend keeping events measured on a time scale separate from a distance scale.\nI will demonstrate the process with two field events. You can apply the logic for all events. We will use vroom::vroom() to take the file names (full names mind you), open them all up and combine them into a single data frame.\nLet’s start with field events like discus:\nWe will use some regular expressions, or regex, to help us. Because the data are named by year, we can limit the search to files that contain a 4-digit year \\\\d{4} so that you don’t also match any aggregated uber files that do not contain a year. Then, the dot star .* will help with filler patterns. In particular, . refers to any character (e.g,. digit, alpha character, or any other special character) and * means zero or more times, so this pattern will search for all files that start with 4 digits followed by anything in the name. Then, the _HT.csv pattern will restrict the search to files containing that exact character string. All together, you have a search for pattern = \"\\\\d{4}.*_DT.csv\". This will not return the file without the year.\n\nDT &lt;- list.files(here::here(\"data\", \"tfrrs\"), \n           pattern = \"\\\\d{4}.*_DT.csv\",\n           ignore.case = T,\n           full.names = T\n           ) %&gt;% \n  vroom::vroom(.)\n\nRows: 1743 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Athlete, Year, Mark, Conv, Meet, Meet_Date, Team, Event, Location\ndbl (1): Season\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsaveRDS(DT, here::here(\"data\", \"tfrrs\", \"DT.Rds\"))\n\nNow how about hammer:\n\nHT &lt;- list.files(here::here(\"data\", \"tfrrs\"), \n           pattern = \"\\\\d{4}.*_HT.csv\",\n           full.names = T\n           ) %&gt;% \n  vroom::vroom(.)\n\nRows: 1557 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): Athlete, Year, Mark, Conv, Meet, Meet_Date, Team, Event, Location\ndbl (1): Season\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsaveRDS(HT, here::here(\"data\", \"tfrrs\", \"HT.Rds\"))"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html#get-the-event-files-and-combine",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html#get-the-event-files-and-combine",
    "title": "Importing many delimeted files into a single data frame",
    "section": "Get the Event Files and Combine",
    "text": "Get the Event Files and Combine\nFor some events, the columns may differ, so you might get an error. If you review the names of columns and locate the pesky dplyr::select() columns that you do want. If you have not removed the data frame objects just pass those to dplyr::bind_rows(), which will add the rows of the second data frame below the first data frame so that you have a single data frame.\n\nFIELD &lt;- dplyr::bind_rows(DT, HT)"
  },
  {
    "objectID": "modules/99_importing_many_files_into_a_single_data_frame.html#save-data",
    "href": "modules/99_importing_many_files_into_a_single_data_frame.html#save-data",
    "title": "Importing many delimeted files into a single data frame",
    "section": "Save Data",
    "text": "Save Data\nAnd then combine and write to an uber field event .csv or .Rds file.\n\nsaveRDS(FIELD, here::here(\"data\", \"tfrrs\", \"TFRRS_FIELD.Rds\"))"
  },
  {
    "objectID": "modules/index.html",
    "href": "modules/index.html",
    "title": "Modules",
    "section": "",
    "text": "This course consists of various content modules that introduce students to data visualization techniques using R. Techniques, however, should not be applied haphazardly but instead with respect to the biological and cognitive limitations of the user. The general principles of data visualization taught can be applied to programming languages other than R (e.g., Python, D3, etc.)."
  },
  {
    "objectID": "modules/index.html#module-structure",
    "href": "modules/index.html#module-structure",
    "title": "Modules",
    "section": "Module structure",
    "text": "Module structure\nIn general, modules will contain readings, additional resources, and weekly assignments.\nThe modules will be updated across the semester as needed. There are more modules on this course site because some modules provide other useful information. The names of the modules listed in the syllabus, however, do match the names in the module listing."
  },
  {
    "objectID": "project/project.html",
    "href": "project/project.html",
    "title": "Project",
    "section": "",
    "text": "For the data visualization project, your team will writ code in order to analyze data and create data visualizations in order to communicate a story that would address the client’s interest in determining whether COVID has influenced athlete performance. Given the constraints of data to inform this specific question, the project will involve data exploration to tell a story about athlete performance. Given the client has little information about athlete performance, including data visualizations, this exploration allows for a healthy dose of flexibility in team creativity. This open element will also allow teams to develop ideas independently, thereby producing stories that will likely diverge wildly from each other, making the project an exciting foray into data storytelling for many students.\n\n\nProject roles help streamline events, assist delegation, allow for some accountability, and reduce workload overlap. Project roles are designed to help keep the project organized and reduce confusion about what project elements team members are taking on. Team roles should be decided upon in a way that maximizes member ability so that task demands are equal across team members. These roles provide some guidelines but do not obviate members from contributing to and participating in other tasks subsumed under specific roles. In other words, when the Project Manager falls ill, another team member should step up to facilitate any necessary communication between the liaison of me. Likewise, the Coding Lead would step in to help the Writing Lead revise writing when necessary. Similarly, the Writing Lead or Project Manager should help the Coding Lead with organizing code when appropriate. All team members have have the same goal, which is to develop, code, and communicate the project to the liaison. All members will code, organize, and write and may take lead on sections with which they are most familiar or most qualified in addressing.\nIf the team decides to create roles different from those suggested below, please just let me know.\nSuggested Roles:\n\n\n\nCommunicating with course faculty and liaison(s);\nScheduling and reminding the team meetings and meetings with liaison;\nAssigning tasks to team members (with help from course professor is needed) and based on the project requirements;\nMonitoring and keeping track of each member’s project progress;\nMotivating the team members on their task completion and future goals;\nDealing with any conflicts within the team and updating any concerns with course professor;\nCoordinating team activities such as presentation dry runs;\nHelping maintain equity of tasks across all team members, inclusion the PM;\nThe Project Manager is not responsible to reminding team members to complete their tasks or complete worklogs.\n\n\n\n\n\n1 or 2 members\nPlanning, guiding, and leading report writing;\nDoing background/external research on topic as relevant;\nAssigning sections/chapters of documents to appropriate members;\nKeeping track of the written progress;\nHelping develop a data visualization story line;\nFormatting, text, images, inline code (R code embedded in text), and tables on final document (RMarkdown for final report);\nProofreading/editing deliverable documents like slide presentation, written report, etc.;\nThe Reporting Team is not responsible to all writing.\n\n\n\n\n\n1 or 2 members\nCreating and maintaining organization of the project code (e.g., directories, sourced scripts, etc.)\nLeading coding and code documenting;\nAssigning technical tasks to other team members;\nKeeping track of the progress of the technical tasks;\nHelping other team members troubleshoot code (see also TA and course professor);\nCommunicating with PM, liaison (during liaison meetings), and course professor regarding any technical needs and concerns;\nCommunicating with RL regarding messaging of coded results;\nMaintaining GitHub repo (recommended, please see course professor for assistance);\nThe Coding Team is not responsible for all coding.\n\nBased on abilities and interests of team members, the team should determine how many individuals to assign to a given role, or determine other appropriate roles given the abilities of the team members. There should be unanimity in these decisions. I will not assign you to roles."
  },
  {
    "objectID": "project/project.html#project-description",
    "href": "project/project.html#project-description",
    "title": "Project",
    "section": "",
    "text": "For the data visualization project, your team will writ code in order to analyze data and create data visualizations in order to communicate a story that would address the client’s interest in determining whether COVID has influenced athlete performance. Given the constraints of data to inform this specific question, the project will involve data exploration to tell a story about athlete performance. Given the client has little information about athlete performance, including data visualizations, this exploration allows for a healthy dose of flexibility in team creativity. This open element will also allow teams to develop ideas independently, thereby producing stories that will likely diverge wildly from each other, making the project an exciting foray into data storytelling for many students.\n\n\nProject roles help streamline events, assist delegation, allow for some accountability, and reduce workload overlap. Project roles are designed to help keep the project organized and reduce confusion about what project elements team members are taking on. Team roles should be decided upon in a way that maximizes member ability so that task demands are equal across team members. These roles provide some guidelines but do not obviate members from contributing to and participating in other tasks subsumed under specific roles. In other words, when the Project Manager falls ill, another team member should step up to facilitate any necessary communication between the liaison of me. Likewise, the Coding Lead would step in to help the Writing Lead revise writing when necessary. Similarly, the Writing Lead or Project Manager should help the Coding Lead with organizing code when appropriate. All team members have have the same goal, which is to develop, code, and communicate the project to the liaison. All members will code, organize, and write and may take lead on sections with which they are most familiar or most qualified in addressing.\nIf the team decides to create roles different from those suggested below, please just let me know.\nSuggested Roles:\n\n\n\nCommunicating with course faculty and liaison(s);\nScheduling and reminding the team meetings and meetings with liaison;\nAssigning tasks to team members (with help from course professor is needed) and based on the project requirements;\nMonitoring and keeping track of each member’s project progress;\nMotivating the team members on their task completion and future goals;\nDealing with any conflicts within the team and updating any concerns with course professor;\nCoordinating team activities such as presentation dry runs;\nHelping maintain equity of tasks across all team members, inclusion the PM;\nThe Project Manager is not responsible to reminding team members to complete their tasks or complete worklogs.\n\n\n\n\n\n1 or 2 members\nPlanning, guiding, and leading report writing;\nDoing background/external research on topic as relevant;\nAssigning sections/chapters of documents to appropriate members;\nKeeping track of the written progress;\nHelping develop a data visualization story line;\nFormatting, text, images, inline code (R code embedded in text), and tables on final document (RMarkdown for final report);\nProofreading/editing deliverable documents like slide presentation, written report, etc.;\nThe Reporting Team is not responsible to all writing.\n\n\n\n\n\n1 or 2 members\nCreating and maintaining organization of the project code (e.g., directories, sourced scripts, etc.)\nLeading coding and code documenting;\nAssigning technical tasks to other team members;\nKeeping track of the progress of the technical tasks;\nHelping other team members troubleshoot code (see also TA and course professor);\nCommunicating with PM, liaison (during liaison meetings), and course professor regarding any technical needs and concerns;\nCommunicating with RL regarding messaging of coded results;\nMaintaining GitHub repo (recommended, please see course professor for assistance);\nThe Coding Team is not responsible for all coding.\n\nBased on abilities and interests of team members, the team should determine how many individuals to assign to a given role, or determine other appropriate roles given the abilities of the team members. There should be unanimity in these decisions. I will not assign you to roles."
  },
  {
    "objectID": "project/project.html#project-grading",
    "href": "project/project.html#project-grading",
    "title": "Project",
    "section": "Project Grading",
    "text": "Project Grading\n\nQuality of project deliverable documents (e.g., organization, coherence, story, coding clarity/organiation, plots, etc.)\nProfessionalism (e.g., liaison meeting etiquette and responsibility, timely discord communication, non-tardy attendance at weekly team meeting, weekly worklogs, feedback from liaison, etc.)\nPeer evaluation (e.g., contributions, team player, etc.)\n\nNote: Liaison’s will also participate in evaluating all teams. The team with the most impressive project (e.g., most clear, most useful and actionable, most interesting, most thought provoking, etc.) will receive bonus points."
  },
  {
    "objectID": "project/project.html#presentation",
    "href": "project/project.html#presentation",
    "title": "Project",
    "section": "Presentation",
    "text": "Presentation\n\nPresentation Characteristics\n\nClarity: well-explained; easy to follow/understand; ability to communicate points effectively\nOrganization: structured logically; ability to walk audience through the data journey and communicate a story interpretation about data\nThoroughness: all relevant issues discussed thoroughly\nPresentation Style: degree of preparedness and polish in presentation; smooth and rehearsed; minimum of reading; well-paced; slide quality\n\n\n\nPresentation Tips\n\nSpeak to your audience. Look them in the eyes, tell them about the journey. In other words, don’t just read from your slides.\nDo not overwhelm your audience with too much information, especially verbal information. Doing so causes people to read your slides or look at slide content you are not talking about at the moment. You are the presenter and your slides are your visual aides used to support what you communicate. Elaboration can occur in the written deliverable.\n\nPresent slides topically; do not mix unrelated content; use relevant headers, etc.\nPresent summary points on slides rather than full sentences. Communicate to your audience in sentences but don’t present complete sentences on slides unless imperative for communicating a specific point.\nPresent each point separately; do not present all slide content at once (e.g., points a, b, c); communicate specific points (e.g., a) to your audience. Presenting all points at once prevents your audience from paying attention to you and causes cognitive interference/distraction.\nUse a tool (e.g., pointer, etc.) to direct attention to necessary elements of slides, especially when a slide contains multiple pieces of information. Doing so will reduce unnecessary confusion from some audience members because they will not be looking at the incorrect content.\n\nIntroduce team members, their role, etc. when “passing the the mic”. Your client should be reminded of who the team member is and what their role was."
  },
  {
    "objectID": "project/project.html#weekly-worklogreport",
    "href": "project/project.html#weekly-worklogreport",
    "title": "Project",
    "section": "Weekly Worklog/Report",
    "text": "Weekly Worklog/Report\nTracking individual and team goals weekly ensures progress toward the goal, commitment to the project, accountability for oneself, and a record of accomplishments.\nThe Project Manager should inquire with the team about the best way to submit worklogs or transparency and review. This could be a Google Doc File, a spreadsheet, or even a Google From that contains questions to answer, which then get dumped into a Google Spreadsheet for all to review.\n\nFrequency of Worklog\nWorklogs are to be completed by end-of-day following the team meeting, after communicating future goals (distributed equally) to other team members. Please make public for me to review. Meetings should be physical to facilitate team cohesion and conversation, and limit silly technical issues that just waste meeting time.\n\n\nContents of Worklog\nWorklogs should contain information about the reporting date, the team member reporting, that member’s previous week accomplishments, and that member’s future week goals\n\nFor the past week, I accomplished the following specific goals for my team:\n\n\nThis…\nThat…\nAnd the other…\n\n\nFor this past week, the number of hours allocated toward those goals was: ___\nFor this coming week, my specific goals for the team include:\n\n\nThis…\nThat…\nAnd the other…\n\n\nIf relevant, any items to discuss with liaison."
  },
  {
    "objectID": "resources/dataviz_readings.html",
    "href": "resources/dataviz_readings.html",
    "title": "Readings",
    "section": "",
    "text": "You should read the enumerated items (those prefaced by numbers); others can supplemental.\n\nTopic\n\nxxx\nxxx\n\n\n\nGuided Practice with Posit Primers\n\nBar Plots\nBox Plots\nScatterplots\nLine Plots\n\n\n\nTopic\n\nxxx\nxxx\n\n\n\nThe Grammar of Graphics using ggplot\n\nxxx\n\n\n\nMapping Data to Visual Elements\n\nMapping Data to Aesthetics\nMake a Plot\n\ni) xxx\n\n\nAesthetic Considerations Designing Perceptually Efficient Visualizations\n\n\nSpatial Position and Adjustment (CH 7)\n\nAddressing Overplotting with geom_jitter()\n\n\n\n\nStatistical Transformations: Data as-is Versus Summaries\n\n\nData Preparation using dplyr\n\nSelecting Rows and Columns: select() and filter()\n1.2. Grouping/Pooling Data: `group_by()`\n\nData aggregation: summarize()\n\n\n\n\nScales and Axes (CH 6)\n\n\nVisualizing Comparisons\n\nxxx\nxxx\n\n\n\nVisualizing Uncertainty\n\nHistograms/Density Plots\nxxx\n\n\n\nVisualizing Associations and Trends\n\nScatterplots Using group_by for subgroups\nLine Plots\n\nVisualizing Amounts Visualizing Proportions or Ratios\nhttps://clauswilke.com/dataviz/visualizing-amounts.html\n\n\nMaking Visualizations Better\n\nPrinciple of Proportional Ink\nColor Pitfalls\nStorytelling\nWhy People Make Bad Charts (and What to Do When it Happens)\nRefining Plots\n\n\n\nAnnotation\n\nClaus Wilke, Claus Wilke, *Fundamentals of Data Visualization\n\nredundant-coding.html\nSmall Multiples\nTitle and Captions\nAxis Labesls\n\n\n\n\nEmphasis\n\nCalling Attention to Points\nAnnotating Points\nHighlighting Sections\n\n\n\nImage Formats\n\njpg, png, or svg?\nFile Formats Explained\n\n\nWhats the difference between jpg png and gif\nKieran Healy, Data Visualization\n\nxx\n\n\n[Cara Thompson, “Level Up Your Labels: Tips and Tricks for Annotating Plots”] (https://www.cararthompson.com/talks/user2022)\n\n\nReproduce vs. Replicate\n\nWhat is the reprex library?\nReproducible example with reprex\n\n\n\n\n\nAnimation\n\n\n\n\nflowchart RL\n  B(Data) --&gt; A(Plot) \n  C(Geometry) --&gt; A(Plot) \n  D(Statistics) --&gt; A(Plot)\n  E(Coordinate System) --&gt; A(Plot)\n  F(Theme) --&gt; A(Plot)"
  },
  {
    "objectID": "resources/dataviz_tools.html#websites",
    "href": "resources/dataviz_tools.html#websites",
    "title": "Tools for Data Visualization",
    "section": "Websites",
    "text": "Websites\n\nPractice Coding in R on Posit Cloud\n\nhttps://posit.cloud/learn/primers/\n\n\n\nColor Codes\n\nHTML colors: https://htmlcolorcodes.com/\n\n\n\nVisualize a palette for different types of colorblindness\n\nViz Palette https://projects.susielu.com/viz-palette\n\n\n\nWhat do your photos/images look like to others?\n\nCoblis colorblindness imulator: https://www.color-blindness.com/coblis-color-blindness-simulator/\nPilestone Colorblindness Simulator: https://pilestone.com/pages/color-blindness-simulator-1\nVischeck http://www.vischeck.com/vischeck/vischeckImage.php"
  },
  {
    "objectID": "resources/dataviz_tools.html#books",
    "href": "resources/dataviz_tools.html#books",
    "title": "Tools for Data Visualization",
    "section": "Books",
    "text": "Books\n\nClaus Wilke, Fundamentals of Data Visualization https://clauswilke.com/dataviz/\nhttps://www.bigbookofr.com/data-visualization.html\nhttps://handsondataviz.org/"
  },
  {
    "objectID": "resources/dataviztools.html#websites",
    "href": "resources/dataviztools.html#websites",
    "title": "Tools for Data Visualization",
    "section": "Websites",
    "text": "Websites\n\nPractice Coding in R on Posit Cloud\n\nhttps://posit.cloud/learn/primers/\n\n\n\nColor Codes\n\nHTML colors: https://htmlcolorcodes.com/\n\n\n\nVisualize a palette for different types of colorblindness\n\nViz Palette https://projects.susielu.com/viz-palette\n\n\n\nWhat do your photos/images look like to others?\n\nCoblis colorblindness imulator: https://www.color-blindness.com/coblis-color-blindness-simulator/\nPilestone Colorblindness Simulator: https://pilestone.com/pages/color-blindness-simulator-1\nVischeck http://www.vischeck.com/vischeck/vischeckImage.php"
  },
  {
    "objectID": "resources/dataviztools.html#books",
    "href": "resources/dataviztools.html#books",
    "title": "Tools for Data Visualization",
    "section": "Books",
    "text": "Books\n\nClaus Wilke, Fundamentals of Data Visualization https://clauswilke.com/dataviz/\nhttps://www.bigbookofr.com/data-visualization.html\nhttps://handsondataviz.org/"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#loading-data",
    "href": "slides/Visualizing_Associations.html#loading-data",
    "title": "Visualizing Associations",
    "section": "Loading Data",
    "text": "Loading Data\n\nSWIM &lt;- readr::read_csv(\"https://github.com/slicesofdata/dataviz23/raw/main/data/swim/cleaned-2023-CMS-Invite.csv\", \n                        show_col_types = F)"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#geom_point",
    "href": "slides/Visualizing_Associations.html#geom_point",
    "title": "Visualizing Associations",
    "section": "geom_point()",
    "text": "geom_point()\n\nSWIM %&gt;%\n  ggplot(data = ., \n         mapping = aes(x = Distance, y = Time)) +\n  geom_point()"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#another-example",
    "href": "slides/Visualizing_Associations.html#another-example",
    "title": "Visualizing Associations",
    "section": "Another example",
    "text": "Another example\n\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Split50)) +\n  geom_point()"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#smoothinggeom_smooth",
    "href": "slides/Visualizing_Associations.html#smoothinggeom_smooth",
    "title": "Visualizing Associations",
    "section": "Smoothinggeom_smooth()`",
    "text": "Smoothinggeom_smooth()`\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth()"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#linear-fit",
    "href": "slides/Visualizing_Associations.html#linear-fit",
    "title": "Visualizing Associations",
    "section": "Linear Fit",
    "text": "Linear Fit\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#geom_point-when-a-variable-is-a-factor",
    "href": "slides/Visualizing_Associations.html#geom_point-when-a-variable-is-a-factor",
    "title": "Visualizing Associations",
    "section": "geom_point() when a variable is a factor",
    "text": "geom_point() when a variable is a factor\n\nSWIM %&gt;%\n  filter(., Distance &lt; 1500) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point()"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#multiclass-scatterplots",
    "href": "slides/Visualizing_Associations.html#multiclass-scatterplots",
    "title": "Visualizing Associations",
    "section": "Multiclass Scatterplots",
    "text": "Multiclass Scatterplots\n\nscatterplots with more than 2 variables\ncommunicate relationship with a third variabl\nmapped to an aesthetic like color, size, shape"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-numeric-variable-to-aesthetics",
    "href": "slides/Visualizing_Associations.html#mapping-a-numeric-variable-to-aesthetics",
    "title": "Visualizing Associations",
    "section": "Mapping a numeric variable to aesthetics",
    "text": "Mapping a numeric variable to aesthetics\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(mapping = aes(col = Distance))"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-numeric-variable-to-aesthetics-1",
    "href": "slides/Visualizing_Associations.html#mapping-a-numeric-variable-to-aesthetics-1",
    "title": "Visualizing Associations",
    "section": "Mapping a numeric variable to aesthetics",
    "text": "Mapping a numeric variable to aesthetics"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-categorical-variable-to-aesthetics",
    "href": "slides/Visualizing_Associations.html#mapping-a-categorical-variable-to-aesthetics",
    "title": "Visualizing Associations",
    "section": "Mapping a categorical variable to aesthetics",
    "text": "Mapping a categorical variable to aesthetics\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         \n         ) %&gt;%\n  ggplot(., aes(x = factor(Distance), y = Time)) +\n  geom_point(mapping = aes(col = School))"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-categorical-variable-to-aesthetics-1",
    "href": "slides/Visualizing_Associations.html#mapping-a-categorical-variable-to-aesthetics-1",
    "title": "Visualizing Associations",
    "section": "Mapping a categorical variable to aesthetics",
    "text": "Mapping a categorical variable to aesthetics"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-new-numeric-and-a-new-categorical-variable",
    "href": "slides/Visualizing_Associations.html#mapping-a-new-numeric-and-a-new-categorical-variable",
    "title": "Visualizing Associations",
    "section": "Mapping a new numeric and a new categorical variable",
    "text": "Mapping a new numeric and a new categorical variable\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event))"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#mapping-a-new-numeric-and-a-new-categorical-variable-1",
    "href": "slides/Visualizing_Associations.html#mapping-a-new-numeric-and-a-new-categorical-variable-1",
    "title": "Visualizing Associations",
    "section": "Mapping a new numeric and a new categorical variable",
    "text": "Mapping a new numeric and a new categorical variable"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#suppress-legend",
    "href": "slides/Visualizing_Associations.html#suppress-legend",
    "title": "Visualizing Associations",
    "section": "Suppress Legend",
    "text": "Suppress Legend\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event),\n    show.legend = F\n    )"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#suppress-legend-1",
    "href": "slides/Visualizing_Associations.html#suppress-legend-1",
    "title": "Visualizing Associations",
    "section": "Suppress Legend",
    "text": "Suppress Legend"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#changing-alpha-transparency",
    "href": "slides/Visualizing_Associations.html#changing-alpha-transparency",
    "title": "Visualizing Associations",
    "section": "Changing alpha transparency",
    "text": "Changing alpha transparency\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event),\n    alpha = .4,\n    show.legend = F\n    )"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#changing-alpha-transparency-1",
    "href": "slides/Visualizing_Associations.html#changing-alpha-transparency-1",
    "title": "Visualizing Associations",
    "section": "Changing alpha transparency",
    "text": "Changing alpha transparency"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#changing-point-position",
    "href": "slides/Visualizing_Associations.html#changing-point-position",
    "title": "Visualizing Associations",
    "section": "Changing point position",
    "text": "Changing point position\nSWIM %&gt;%\n  filter(., \n         !is.na(Name),\n         Time &lt; 1000\n         ) %&gt;%\n  ggplot(., aes(x = Distance, y = Time)) +\n  geom_point(\n    aes(size = Split50, col = Event),\n    alpha = .3,\n    position = position_jitter(),\n    show.legend = F\n    )"
  },
  {
    "objectID": "slides/Visualizing_Associations.html#changing-point-position-1",
    "href": "slides/Visualizing_Associations.html#changing-point-position-1",
    "title": "Visualizing Associations",
    "section": "Changing point position",
    "text": "Changing point position"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#loading-data",
    "href": "slides/spatial_position_and_adjustment.html#loading-data",
    "title": "Visualizing Associations",
    "section": "Loading Data",
    "text": "Loading Data\n\nSWIM &lt;- readr::read_csv(\"https://github.com/slicesofdata/dataviz23/raw/main/data/swim/cleaned-2023-CMS-Invite.csv\", \n                        show_col_types = F)"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#geom_point",
    "href": "slides/spatial_position_and_adjustment.html#geom_point",
    "title": "Visualizing Associations",
    "section": "geom_point()",
    "text": "geom_point()\n\n2 + 2\n\n[1] 4\n\n# comment"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#slide-title",
    "href": "slides/spatial_position_and_adjustment.html#slide-title",
    "title": "Visualizing Associations",
    "section": "Slide Title",
    "text": "Slide Title\n\none\ntwo"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#make-this-slide-red",
    "href": "slides/spatial_position_and_adjustment.html#make-this-slide-red",
    "title": "Visualizing Associations",
    "section": "Make this slide Red",
    "text": "Make this slide Red"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#making-a-slide-incremental",
    "href": "slides/spatial_position_and_adjustment.html#making-a-slide-incremental",
    "title": "Visualizing Associations",
    "section": "Making a Slide Incremental",
    "text": "Making a Slide Incremental\nSay you want to reveal the content of slide piecemeal without rewriting separate slides with previous content.\n\nThen add some content…\n\n\nThen some more content"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#omit-this-slide-visibility-hidden",
    "href": "slides/spatial_position_and_adjustment.html#omit-this-slide-visibility-hidden",
    "title": "Visualizing Associations",
    "section": "Omit This Slide {visibility = “hidden”}",
    "text": "Omit This Slide {visibility = “hidden”}"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#add-links",
    "href": "slides/spatial_position_and_adjustment.html#add-links",
    "title": "Visualizing Associations",
    "section": "Add links",
    "text": "Add links\n\ncmc\n\n\n\nFirst item\nSecond item"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#fragments",
    "href": "slides/spatial_position_and_adjustment.html#fragments",
    "title": "Visualizing Associations",
    "section": "Fragments",
    "text": "Fragments\n\nFade in\n\n\nFade out\n\n\nHighlight red\n\n\nFade in, then out"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#fragments-nesting",
    "href": "slides/spatial_position_and_adjustment.html#fragments-nesting",
    "title": "Visualizing Associations",
    "section": "Fragments, nesting",
    "text": "Fragments, nesting\n\n\n\nFade in &gt; Turn red &gt; Semi fade out"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#fragments-spans",
    "href": "slides/spatial_position_and_adjustment.html#fragments-spans",
    "title": "Visualizing Associations",
    "section": "Fragments, spans",
    "text": "Fragments, spans\nThis is an important sentence!\nMind the gap when riding the rail!"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#column-layout",
    "href": "slides/spatial_position_and_adjustment.html#column-layout",
    "title": "Visualizing Associations",
    "section": "Column layout",
    "text": "Column layout\n\n\ncontents…s\n\ncontents…"
  },
  {
    "objectID": "slides/spatial_position_and_adjustment.html#output-location",
    "href": "slides/spatial_position_and_adjustment.html#output-location",
    "title": "Visualizing Associations",
    "section": "Output Location",
    "text": "Output Location\n\n\nlibrary(ggplot2)\n\nmtcars |&gt; \n  ggplot(aes(x = disp, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = \"y~x\")"
  },
  {
    "objectID": "syllabus/syllabus.html",
    "href": "syllabus/syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Semester\nFall 2023\n\n\nSection\nPSYC 167, Sect-01\n\n\nDay Time\nTuesday 2:45 - 05:30PM (Pacific)\n\n\nLocation\nLocation: Roberts South, 104\n\n\nOffice Hours\nSee Discord\n\n\nInstructor\nGabriel I. Cook\n\n\nContact\nEmail: gcook@CMC.edu(please put ’PSYC 167 in subject line)\n\n\nCredit\n3 hours; 1 credits"
  },
  {
    "objectID": "syllabus/syllabus.html#course-description",
    "href": "syllabus/syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nData visualization is the science and art of creating graphical representations of information and data. Visual representations provide accessible ways to see patterns, trends, and outliers in data. Variables like position, size, and orientation can focus attention and guide perception but can also bias interpretation of data. Students will learn how well-designed visualizations can reduce bias and improve comprehension for data thereby facilitating data-driven decision-making. Students will explore techniques for creating effective visualizations based on principles from cognitive and perceptual psychology, art, and design. Students will gain hands-on experience coding real-world data visualizations for local offices, organizations, and industry participants.\nThe course is targeted toward students with expressed interest in cognition and cognitive biases related to data communication, students interested in using visualization to communicate their own messages, and students interested in creating better visualization tools and systems. Students will engage in discussions of the readings, complete programming and data analysis assignments, and prepare a final project involving storytelling with data visualizations.\nPrerequisite: For data-science sequence or majors (level-A data-science course); recommended a course in Perception, Visual Attention, Cognitive Psychology, or Cognitive Science; or permission of instructor\n\nCourse Specific Learning Goals\n\nUnderstand various uses of visual variables to create data visualizations;\nUnderstand both advantages and disadvantages of using visual variables to create data visualizations;\nAnalyze, critique, and revise data visualizations;\nUnderstand the functionality of the ggplot2 library for creating data visualizations;\nPresent data with visual representations for your target audience, task, and data;\nIdentify appropriate data visualization techniques given particular requirements imposed by the data and/or audience; and\nApply appropriate design principles in the creation of presentations and visualizations"
  },
  {
    "objectID": "syllabus/syllabus.html#courses-at-cmc",
    "href": "syllabus/syllabus.html#courses-at-cmc",
    "title": "Syllabus",
    "section": "Courses at CMC",
    "text": "Courses at CMC\n\nFaculty Handbook 5.4.2 Work Load in Classes\n“Courses should involve approximately equal workloads. Generally, students should expect to spend from 6 to 8 hours per week, over and above the time spent in classroom, on each course.” – CMC Faculty Handbook\nIf you do the math, including class time of 2½ hours, you should expect to allocate 8 ½ to 10 ½ hours per week for courses at CMC. “Per week” is a key phrase; courses are not designed for nondistributed cramming."
  },
  {
    "objectID": "syllabus/syllabus.html#course-materials-and-textbook",
    "href": "syllabus/syllabus.html#course-materials-and-textbook",
    "title": "Syllabus",
    "section": "Course Materials and Textbook",
    "text": "Course Materials and Textbook\nAll of the course materials will be available on this course website .\nLink to the course website: https://slicesofdata.github.io/dataviz23\n\nRequired Equipment:\nComputer: current Mac (macOS) or PC (Windows or Linux) with high-speed internet connection, capable of running R and RStudio\n\n\nRequired Software:\nR and RStudio: Students will be required to use R and RStudio software. Note: Install Version will be provided. Before installing RStudio, you must also download and install the base R software at https://www.r-project.org/ that is appropriate for your computer’s operating system. RStudio can be downloaded for free at https://www.rstudio.com. You are expected to install R and RStudio on your personal computer by downloading the software from the links above. You will also have to install appropriate libraries throughout the course. Further instructions will be provided.\n\n\nReading Materials/Textbook(s)\nReadings will be taken from different sources and will appear in each topic module.\n\nWickham, H., Navarro. D., & Pedersen, T. L.. ggplot2: Elegant Graphics for Data Analysis, 3rd ed.\nClaus O. Wilke (2019). Fundamentals of Data Visualization. O’Reilly Media.\nXie, Y., Allaire, J. J., & Grolemund, G. R Markdown: The Definitive Guide\nKieran Healy (2018). Data Visualization: A Practical Introduction. Princeton University Press.\nNordmann, E. & DeBruine, L. (2023). Applied Data Skills: Processing & Presenting Data (2023) . https://psyteachr.github.io/ads-v2\n\nThese textbooks are free and open-source."
  },
  {
    "objectID": "syllabus/syllabus.html#course-structure",
    "href": "syllabus/syllabus.html#course-structure",
    "title": "Syllabus",
    "section": "Course Structure",
    "text": "Course Structure\nStudents are expected to participate in all aspects of the class. This class involves developing topic knowledge and computer programming skills for visualizing data. The assumption is that students possess varying levels of skills related to programming. Class time will be spend engaging in a variety of tasks and activities, including lectures, group-work, applied coding activities, presentations, and discussions."
  },
  {
    "objectID": "syllabus/syllabus.html#course-schedule",
    "href": "syllabus/syllabus.html#course-schedule",
    "title": "Syllabus",
    "section": "Course Schedule",
    "text": "Course Schedule\n\n\n\n\n\n\n\n\n\n\n\nDate\nWeek\nModule\nTopic\n\n\n\n\n29-Aug\n1\n1\nIntroduction & Project Management\n\n\n\n1\n2\nGraphical Perception\n\n\n5-Sep\n2\n3\nData Frame Manipulation and Wrangling\n\n\n\n2\n4\nData Subsets and Summaries\n\n\n12-Sep\n3\n5\nThe Grammar of Graphics\n\n\n\n3\n6\nVisualizing Amounts\n\n\n19-Sep\n4\n7\nVisualizing Associations\n\n\n\n4\n8\nSpatial Position and Adjustment\n\n\n26-Sep\n5\n9\nConsiderations in Data Visualization\n\n\n\n5\n10\nColor Scales and Palettes\n\n\n3-Oct\n6\n11\nHistograms and Density Plots*\n\n\n\n6\n12\nCoordinates, Axes and Position Scales\n\n\n10-Oct\n7\n13\nStatistical Transformations (Data as-is Versus Summaries)\n\n\n\n7\n14\nMore Data Wrangling\n\n\n17-Oct\n8\n\nFall Break (no class)\n\n\n24-Oct\n9\n15\nVisualizing More Distributions\n\n\n\n9\n16\nVisualizing Uncertainty\n\n\n31-Oct\n10\n\nMid-Term Presentation\n\n\n7-Nov\n11\n17\nVisualizing Trends\n\n\n\n11\n18\nLegends and Arrangement\n\n\n14-Nov\n12\n19\nDesigning Perceptually Efficient Visualizations\n\n\n\n12\n20\nAnnotation and Text\n\n\n21-Nov\n13\n21\nMulti-Panel Plots: Faceting and Layers\n\n\n\n13\n22\nAttentional Control and Tradeoffs\n\n\n28-Nov\n14\n23\nTitles Captions & Tables\n\n\n\n14\n24\nFigure Design (Themes)\n\n\n5-Dec\n15\n\nPresentation (Last day of Instruction)"
  },
  {
    "objectID": "syllabus/syllabus.html#assignments-and-grading",
    "href": "syllabus/syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThis is an engagement and skills-acquisition based course. At the beginning of the course and throughout, students will be given instruction on building and maintaining a website using quarto and github pages. Each week students will contribute blog posts and other content to their websites in response to module assignments. Students will be expected to submit URL links to their blogs using Blackboard. Students are expected to attend and participate in each class. The final project includes conducting, communicating, and preserving a reproducible data analysis project.\n\n**Evaluation and Grading*\n\n\n\n\n\nItem\nTotal Points\n\n\n\n\nKnowledge Assessments\n10\n\n\nWeekly Conceptual and Programming\n30\n\n\nMidterm Presentation\n20\n\n\nFinal Project (pres and report)\n40\n\n\n\n\n\nPercentage grades are converted to letter grades according to the following rubric.\n\n\n\n\n\nLetter\nPoint Range\n\n\n\n\nA\n94 - 100\n\n\nA-\n90 - 93.99\n\n\nB+\n87 - 89.99\n\n\nB\n84 - 86.99\n\n\nB-\n80 - 83.99\n\n\nC+\n77 - 79.99\n\n\nC\n74 - 76.99\n\n\nC-\n70 - 73.99\n\n\nD+\n67 - 69.99\n\n\nD\n64 - 66.99\n\n\nD-\n60 - 63.99\n\n\nF\n0 - 59.99"
  },
  {
    "objectID": "syllabus/syllabus.html#attendance",
    "href": "syllabus/syllabus.html#attendance",
    "title": "Syllabus",
    "section": "Attendance",
    "text": "Attendance\nStudents are expected to attend and participate in each class."
  },
  {
    "objectID": "syllabus/syllabus.html#course-policies",
    "href": "syllabus/syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course Policies",
    "text": "Course Policies\n\nDue dates\nDue dates are suggestions for completing coursework on a weekly basis. You may be able to work ahead, but you are not encouraged to fall behind.\nYou should email me if you have an exceptional circumstance preventing you from taking an assessment during an assessment week.\n\n\nChanges to the syllabus\nThe syllabus may be updated for clarity or to make adjustments for pedagogical purposes. The most current version of the syllabus is always available from the course website.\n\n\nAccessibility\nIn order to receive disability-related academic accommodations students must first be registered with the Center for Student Disability Services. Students who have a documented disability or suspect they may have a disability are invited to set up an appointment with the Director of the Center for Student Disability Services, at 718-951-5538. If you have already registered with the Center for Student Disability Services, please provide your professor with the course accommodation form and discuss your specific accommodation with him/her.\n\n\n\nEmail Correspondence\nI will regularly use e-mail but you should contact me on the Discord channel, which is where I will post announcements, changes in the syllabus, reminders, etc. You are responsible for monitoring Discord and e-mail regularly.\nIf you have questions please email me:\n\nAlways add ’PSYC 167” to the subject line\nemail me at: gcook@cmc.edu"
  },
  {
    "objectID": "syllabus/syllabus.html#universitys-policy-on-academic-integrity",
    "href": "syllabus/syllabus.html#universitys-policy-on-academic-integrity",
    "title": "Syllabus",
    "section": "University’s policy on Academic Integrity",
    "text": "University’s policy on Academic Integrity\nThe faculty and administration of Claremont McKenna College support an environment free from cheating and plagiarism. Each student is responsible for being aware of what constitutes cheating and plagiarism and for avoiding both.\n\nViolations of Academic integrity\nEach student is responsible for understanding and acting in accordance with the College’s policy on Academic Integrity, described below.\n\n\nAcademic Integrity\nAlthough you may find yourself working on assignments with a partner or discussing them with classmates, all assignments should be your one original work. You are not to share materials with other students if that material has the potential of being copied, even if your intention is not to allow a classmate to copy your work. Any signs of academic dishonesty, even those raised by concerned peers, will be submitted to the Academic Standards Committee for review. Although I do not anticipate any events of academic dishonesty, any form of dishonestly of any form will not be tolerated. Many students are unclear of the definition of plagiarism so I have posted some CMC links to information that I believe will clarify the issue. In addition, any work completed for another course, past or present, may not be submitted for a grade for this course and would be a violation of integrity. http://registrar.academic.claremontmckenna.edu/acpolicy/default.asp\n\nStatement of Reasonable Accommodations\nYour experience in this class is important to me. If you have already established accommodations with Disability & Accessibility Services at CMC, please communicate your approved accommodations to me during the first week of the semester so we can discuss your needs in this course ASAP. You can start this conversation by forwarding me your accommodation letter. If you have not yet established accommodations through Accessibility Services but have a temporary health condition or permanent disability (conditions include but are not limited to: mental health, attention-related, learning, vision, hearing, physical or health), you are encouraged to contact Assistant Dean for Disability Services & Academic Success, Kari Rood, at AccessibilityServices@cmc.edu to ask questions and/or begin the process. General information and accommodations request information be found at the CMC DOS Accessibility Service’s website. Please note that arrangements must be made with advance notice in order to access the reasonable accommodations. You are able to request accommodations from CMC Accessibility Services at any point in the semester. Be mindful that this process may take some time to complete and accommodations are not retroactive. I would err on the side of caution and make sure your accommodations are sent to me even if you do not believe you need them as some students only learn they may need time after completing assessment. The Americans With Disabilities Act (ADA) and Section 504 of the Rehabilitation Act do not make accommodations retroactive. If you are approved for extra testing time for example, you must do so before an electronic assessment is posted in order for it to be integrated into the assessment. Claremont McKenna College values creating inclusive and accessible learning environments consistent with federal and state law. If you are not a CMC student, please connect with the Disability & Accessibility Services Coordinator on your campus regarding a similar process.\n\n\n\nFYI on cheating etc.\nRemember, you are responsible for not cheating or violating CMC’s Academic Integrity Policy. You are responsible for understanding that policy, and for conducting yourself in a manner such that you do not violate the policy.\nThe above link lists many examples of cheating and plagiarism that are not allowed. There are many more specific acts that you should NOT do. Here is an additional list of activities that will be sufficient cause for immediate failure in the course.\n\nDo not take pictures of exam or quiz questions and share them with other students\nDo not give other students answers during an exam or quiz, or any other assignment that is an individual assignment\nDo not copy work from another source and submit it as your own\nDo not copy and paste text from the internet and submit it as your own words\nDo not copy and paste text and slightly alter wording to pass the work off as your own\nDo not hire someone else to do the coursework for you\nDo not copy and paste text into a paraphrasing app, and then submit the output of the paraphrasing app as your own work\nDo not copy random words from the internet that have nothing to do with the assignment and submit them as your own work.\nDo not work on individual assignments with other students, share answers or other material, and then all hand in versions of the same thing that are slightly different.\nDo not plagiarize yourself by submitting work that you have previously completed in another class.\n\n\n\nMandate to report violations\nIf a faculty member suspects a violation of academic integrity and, upon investigation, confirms that violation, or if the student admits the violation, the faculty member MUST report the violation. Students should be aware that faculty may use plagiarism detection software.\nThere is no excuse for cheating. Students who are caught cheating may receive a failing grade for the entire course. All students who violate the academic integrity will receive a Faculty Action Report, which will go on their personal file at the Academic Integrity Office."
  },
  {
    "objectID": "syllabus/syllabus.html#faq",
    "href": "syllabus/syllabus.html#faq",
    "title": "Syllabus",
    "section": "FAQ",
    "text": "FAQ\nIf you have questions about the syllabus, let’s talk about it in class, and/or please create a thread to discuss the question on the discussion board for this course on Blackboard."
  }
]