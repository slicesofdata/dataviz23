---
title: "GCDS: Data Frame Manipulation and Wrangling"
author: ""
#date: "`r Sys.Date()`"
date: "`r format(Sys.time(), '%d %B, %Y')`"   # date
output: 
  html_document:
    toc: true     # this will create a table of contents 
                  # of hyperlinks (change true to omit)
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include=FALSE}
#################################################################
############### Remember to run this block first ################
#################################################################

rm(list = ls(all.names = TRUE))      # remove objects in R

#source("https://pastebin.com/raw/8mXH02yg")   # run and comment out before knitting
source("https://pastebin.com/raw/97NNTTzu")   # run to include in function definitions

# set the paths for project, script, and data dirs
proj_dir <- gsub("GCDS.*.Rmd", "GCDS", get_ActivePath())
proj_name = ""
r_dir    <- paste(proj_dir, "r", sep = "/")    # r subdir
data_dir <- paste(proj_dir, "data", sep = "/") # data subdir
if ( proj_name != "" & !dir.exists(paste(proj_dir, proj_name, sep = "/")) ) {
  # create project dir
  suppressWarnings(dir.create(paste(proj_dir, proj_name, sep = "/")))
  r_dir <- gsub("/r", paste0("/", proj_name, "/r"), r_dir)
  data_dir <- gsub("/data", paste0("/", proj_name, "/data"), data_dir)
  # create sub directories
  suppressWarnings(dir.create(r_dir))
  suppressWarnings(dir.create(data_dir)) }
```

# **Libraries for Data Frame Manipulation** 

- `magrittr`: for piping data frame objects
- `dplyr`: for selecting, filtering, and mutating
- `stringr`: for working with strings

```{r}
library(magrittr)
library(dplyr)
library(stringr)
```

Read the data

```{r}
dat_file_name <- "Games_Survey_numeric_cleaned.csv"
dat_file_path
paste(data_dir, dat_file_name, sep = "/")

```
# **A Grammar for Data Wrangling** 

The `dplyr` package presents a type of grammar for wrangling data (H. Wickham and Francois 2020). `dplyr` is part of the `tidyverse` ecosystem and loads using `library(tidyverse)`. `dplyr` also imports functions from `tidyselect`, which is also part of the `tidyverse` ecosystem.

The functions from the packages in the `tidyverse` can can be used without referencing the packages explicitly but to avoid functions of the same name from other packages being confused, we will reference the package/library and the function (e.g., `package::function()`).

Working with data involves creating new column variables, removing or renaming column variables, removing or deleting row observations, sorting, and summarizing data, often by groups. Consequently, there are five main function verbs for working with data in a data frame: `select`, `filter`, `mutate`, `arange`, and `summarize`. 


- `select(dataframe, variables_to_select)`: subset by columns 
- `mutate(dataframe, variables_to_create)` and `dplyr::rename()`: add or modify existing columns
- `filter(dataframe, rows_to_select)`: subset by rows
- `arrange(dataframe, variable_to_sort_by)`: sort rows
- `summarize(dataframe, procedures_for_summarizing)` in conjunction with `dplyr::group_by()`: aggregate the data in some way


# **Some Common Ways for Selecting Variables Using `dplyr`**

Using `select()`, you can select columns/variables from a data frame. The variables you select are retained and those that you don't select are not included in the returned data frame. 

If not using `%>%`, the first argument passed into `select()` will be the data frame from which to select the variables and the second and subsequent arguments can be variables. 

`select(mydataframe, myvars)`

If piping a data frame with `magrittr`, the "." or ".data" will serve to reference the inherited data frame. 

`dataframe %>%`
  `select(., myvars)`


Variables can be passed separately without quotes or collectively as a character vector.

```{r}
# passing variables by name (does not work with base R manipulation)

# passing variables separately 
USArrests %>% 
  select(., Murder, Assault)

# passing variables separately as characters 
# though combining then with c() is probably more clear
USArrests %>% 
  select(., "Murder", "Assault")


# passing a character vector
USArrests %>% 
  select(., c("Murder", "Assault"))


# passing an object holding a character vector
keep_vars <- c("Murder", "Assault")


USArrests %>% 
  select(., keep_vars)
```


# **Select Variables Starting with or Ending with Certain Characters**

One thing about `dplyr`, when you load the library, there are functions from other libraries that are imported along with `dplyr`s own functions. These important functions are designed to work with each other, so the people who maintain the libraries have packeged them up nicely so you don't have to load separate libraries. 

Many of the functions are imported from the `tidyselect` library and these functions are what give you additional manipulation ability. Some imported functions are: `all_of()`, `any_of()`, `contains()`, `ends_with()`, `everything()`, `last_col()`, `matches()`, `starts_with()`.

With functions like `starts_with()`, `contains()`, and `ends_with()`, you can select variables with patterns in their names.

Rather that passing the names of the variables as the second argument (e.g., `c("Murder", "Assault")`), you would pass the helper function, say `starts_with()`. Whatever `starts_with()` returns is what gets passed to `select()` as the variables. This is what is referred to as functional programming. Rather than coding specifically what to do, you with utilize the task of another function to passed its returned object as an arguemn to another function.  
   
But first, we need to see what's going on with these functions, like `starts_with()`. 

`starts_with(match, ignore.case = TRUE, vars = NULL)`

Notice the arguments we need to pass: 

- `match`: A character vector
- `ignore.case`: If `TRUE`, the default, ignores case when matching names. This is most flexible.
- `vars`: A character vector of variable names. If not supplied, the variables are taken from the current selection context (as established by functions like `select()` or `pivot_longer()`).

Let's just try out `starts_with()` on its own. Let's set a required pattern `match = some character` and because `vars = NULL` by default, let's just set `vars = some character vector`. Note that `vars` is not the second argument, so you will want to name it in the function call. 

```{r}
starts_with(match = "a", vars = c("Hello", "Hi", "Bye"))
```

Returns `integer(0)` which is speak for "there is no match". Hmm, OK. Let's try another character.

```{r}
starts_with(match = "b", vars = c("Hello", "Hi", "Bye"))
```

OK, so now an integer is returned (yes, try `is.integer()` if you don't believe me). 

```{r}
is.integer(starts_with("b", vars = c("Hello", "Hi", "Bye")))
```

Importantly, the value refers to the element index/position in the `vars` vector. Because the third string `"Bye"` starts with `"b"`, that's what is returned. 

Try something else...

```{r}
starts_with("h", vars = c("Hello", "Hi", "Bye"))
```
Now a vector with length = 2 is returned, representing both the first and the second elements start with "h". 

```{r}
length(starts_with("h", vars = c("Hello", "Hi", "Bye")))
```

See, it's really a vector containing the element(s) of the `vars` vector matching the pattern. 

And yes, this the letter casing is ignored because the default `ignore.case = TRUE`. Set to `FALSE` if you want your match to be case sensitive.

```{r}
starts_with("h", 
            vars = c("Hello", "Hi", "Bye"), 
            ignore.case = F)
```

OK, no matches.

You will typically use `starts_with()` along with other functions. When using `starts_with()` in the context of `select()`, the `vars` argument is essentially passing `vars = the names of the columns of the data frame passed to select()`.

Example:

`select(mydataframe,` 
    `starts_with(match = "my pattern",` 
                 `vars = "var names of mydataframe"))`

Without piping...

```{r}
select(USArrests, starts_with("m"))
```

With piping...

```{r}
USArrests %>%
  select(., starts_with("m"))

USArrests %>%
  select(., ends_with("t"))
```

# **Selecting and Selecting Out Variables By/Between Index**

- `select(., 1,2)`: select first and second 
- `select(., c(1,2))`: select first and second
- `select(., -c(1,2))`: select out first and second

- `select(., 1:2)`: select first through second
- `select(., c(1:2))`: select first through second
- `select(., -c(1:2))`: select out first through second

*Recommendation*: use options utilizing `c()` as this habit will be more versatile with base R functionality.


Let's make a data frame to work with first.

```{r}
data <- data.frame(
  Id  = c(100, 101, 102, 103, 104, 100, 105),
  Sex = c('male', 'female', 'Male', NA, 'man', "male", "neither"),
  Age = c(25, 33, 27, 40, 44, 25, 40),
  Renting = c("yes", NA, "yes", NA, "no", "yes", "yes")
)
```

```{r}
data %>%
  select(., 1,2) # select this and that 


data %>%
  select(., c(1,2)) # select this and that


data %>%
  select(., -c(1,2)) # select out this and that


data %>%
  select(., 1:2) # select from here to there


data %>%
  select(., c(1:3)) # select from here to there


data %>%
  select(., -c(1:3))   # select out from here to there
```


# **Selecting and Selecting Out Variables By or Between Character Name**

- `select(., "var1", "var2")`
- `select(., c("var1", "var2"))`
- `select(., -c("var1", "var2"))`

- `select(., var1:var2))`
- `select(., c("var1":"var2))`
- `select(., -c("var1":"var2))`

*Recommendation*: use options utilizing `c()` as this will be more versatile with base R functionality.

These also work but may lead to some confusion regarding usage of quotes:

- `select(., var1, var2)`
- `select(., c(var1, var2))`
- `select(., -c(var1, var2))` 

```{r}
data %>%
  select(., Id:Age) # select from here to there


data %>%
  select(., "Id":"Age") # select from here to there


data %>%
  select(., c("Id":"Age")) # select from here to there


data %>%
  select(., -c("Id":"Age"))   # select out from here to there


# you can also use the ! operator to select NOT these variables (therefore, all others)
data %>%
  select(., !c("Id":"Age"))   # select out from here to there
```

# **Cleaning Data**

Data files are messy and as a result require cleaning. You will have missing rows, incorrect variable names, files with columns named the same, `NA`s, strings for numbers, duplicate rows of data, people who completed a survey twice, and all sorts of unimaginable and unbelieveable data problems. So cleaning is important. 

## *Removing duplicate rows*

- `dplyr::distinct()`: remove duplicate rows
- `dplyr::distinct(., column)`: remove duplicate rows by column
- `na.omit()`: remove any row with NA’s

Let's use the simple `data` data frame.

```{r}
data %>% view(.)     # the full data frame
```

Notice that rows 1 and 6 are the same person (e.g., Id) and have exactly the same data for all variables. 

```{r}
data[1,] == data[6,]
```

Great that they are consistent but you don't want their data twice. So let's just remove any rows that are identical.

```{r}
data %>%
  distinct(.) %>%    # Remove exact duplicates
  view(.)
```

If you know each row is unique based on a variable in the data frame, you can use `distinct()` for that variable. 

```{r}
data %>%             
  distinct(., Id) %>% view(.) # Remove duplicates by variable; passes unique values for data frame
```

But this just returns the unique values in `Id`. To retain the variables, set `.keep_all = T`.

```{r}
data %>%             
  distinct(., Id, .keep_all = T) %>% view(.)
```

Notice, however, this only removed the last instance or `Id == 100`. Which row to include is a judgment call. The first, the last, neither, the average? No right answer. 



# **A Quick Summary**

```{r}
summary(data)
```


# **Selecting and Selecting Out Variables Characters in Their Names**

- `select(., starts_with("character/s"))`
- `select(., ends_with("character/s"))`
- `select(., contains('e'))`

```{r}
data %>% select(., starts_with('i'))


data %>% select(., -starts_with('s'))


data %>% select(., ends_with('e'))


data %>% select(., -ends_with('e'))


data %>% select(., contains('g'))


data %>% select(., -contains('g'))
```


# **Selecting  and Selecting Out Variables by Type**

```{r}
data %>% select(., where(is.numeric))


data %>% select(., -where(is.numeric))


data %>% select(., where(is.character))


data %>% select(., -where(is.character))
```

# **Filtering by Rows/Cases/Observations**

Whereas `select()` is used for columns, `filter()` operates on rows. 

Data frame manipulation may involve keeping only certain rows for data, for example, male or female respondents, male respondents, those who do not contain missing values (e.g., `NA`s) for a specific column variable, who are of a certain age (or born in in certain year), who are above (or below) some acceptable criterion, etc. 

When a column variable has more than one value (e.g., check using `unique()` to determine the unique elements contained), you may wish to filter on some but not others. 

You may even need to filter rows in a data frame that are distinct (e.g., not duplicate responses). This is often a good first step in order to determine the size of the usable data set. `dplyr::distinct()` makes de-duplicating easy as this function will return only distinct rows.

```{r}
data %>%
  dplyr::distinct() %>% # dedup the data frame
  str()                 # take a look as the data frame structure

data <- data %>%
  dplyr::distinct() # dedup and assign the cleaned data frame to an object of the same name
```

## *Filtering Operators*

Filtering cases using the `dplyr::filter()` verbs works by removing rows that do not match a specific criterion and then by returning the data frame that omits the mismatched condition. 

Some useful filtering operators and functions include: `==`, `>`, `>=`, `&`, `|`, `!`, `xor()`, `c()`, `is.na()`, `between()`, `near()`. 

Row/Obervations/Cases can be filtered to "include" only certain matched conditions or can be filtered to "exclude" by negating those matched conditions. If the column variable `Sex` is in the data frame and cases are `'male'`, `'men'`, `'female'`, `'women'`, `'neither'`, `NA`, etc., you can specify the column `Sex` variable and then the row matching condition(s). 

The first argument in `dplyr::filter()` is a data frame, and the function all `dplyr::filter(data, Sex == 'female')` will filter the data frame named `data` to include rows for which the `sex` column equals `'female'`. In other words, `TRUE` rows.

```{r}
dplyr::filter(data, Sex == 'female')
```

Similarly, the function call `dplyr::filter(., Sex == 'male')` can be read "filter the data frame to include rows for which the value of `Sex == 'male'` is `TRUE`". 

More flexibly, however, you could specify a vector containing acceptable strings using `c()`. `dplyr::filter(. Sex %in% c('male'))` filters the rows to include only those for which the value for `sex` is in the string vector which includes a single string,`'male'` whereas `dplyr::filter(. Sex %in% c('male', 'Man'))` filters the rows to include only those for which the value for `Sex` is in the string vector which includes `'male'` and `'Man'`. Cases containing `'Male'`, `'Men'` (R is a case-sensitive language), or `'female'`, for example, will not be included in the returned data frame because they do not match values in the string vector. 

## *Piping Using Multiple Filter Function*

In many cases, data filtering will involve different conditions for different column variables, so specifying them separately as separate lines of code is most appropriate. 

When passing a data frame using `%>%` from `magrittr`, the first argument for the data frame can be specified using a `.` because the function inherits the data frame manipulated. However, `dplyr` also understand this so the `.` can also be omitted for convenience; this is the general practive you will see in forums like (stackoverflow.com)[stackoverflow.com].

# **Filtering Cases by Character Names/String Values **

```{r}
data %>%
  dplyr::filter(., Sex == 'female')

# not equal
data %>%
  dplyr::filter(., Sex != 'female')


# multiple filters 
data %>%
  dplyr::filter(., Sex == 'female' & Age > 27) # this "AND" that


data %>%
  dplyr::filter(., Sex == 'female' | Age > 27) # this "OR" that
```

A cleaner method involves separate lines of code. Although cleaner, this will not allow the "OR" option because the data frame that is returned from the first `filter()` is passed to the second `filter()` and all cases other than `"female"` have already been removed from the data frame.

```{r}
data %>%
  dplyr::filter(., Sex == 'female') %>%   # keep female (and add another pipe)
  dplyr::filter(., Age >= 27)             # keep only those equal to or older than 27
```




# **Filtering Cases by Value**

## *Filter by `<` and `>` or `<=` or `>=`...*

```{r}
data %>% dplyr::filter(., Age < 40)  # keep those less than 


data %>% dplyr::filter(., Age > 40)  # keep older than


data %>% dplyr::filter(., Age >= 40)  # keep equal to or older than
```


## *Filter by conditional X or Y using `|` operator...*

```{r}
data %>%
  dplyr::filter(., Age == 25 | Age == 40)    # filter out numeric values IN a range
```



## *Filter by conditional X and Y using `&` operator...*

```{r}
data %>%
  dplyr::filter(., Id >= 102 & Age <= 43)    # filter by range


data %>%
  dplyr::filter(., Age >= 20 & Age <= 43)    # filter by range

#Note: Age 20:43 won't work. Can you figure out why?
```

## *Filter by range using `%in%`...*

```{r}
data %>%
  dplyr::filter(., Age %in% 20:43)    # filter out numeric values IN a range
```

## *Filter cases with characters using `%in%`...*

- `stringr::str_detect()`: returns matching conditions 

```{r}
data %>% dplyr::filter(., stringr::str_detect(Sex, "ma")) 
```

But the case for which `Sex = Male` is now missing. This is because `stringr::str_detect()` is a case-sensitive pattern match. 

You can fix this is a couple ways:

1) make the cases in `Sex` all lower case to `mutate()` the fix or
2) to wrap `Sex` in `tolower()` to make cases lowercase. 

The first option might be better if you want to fix the problem in the data frame. 

Other casing functions are:

- `tolower()`: returns lower case of string
- `toupper()`: returns upper case of string
- `tools::toTitleCase()`: returns Title Case (capitalize first letter of string) 

```{r}
data %>%
  mutate(., Sex = tolower(Sex)) %>%
  filter(., stringr::str_detect(tolower(Sex), "ma"))


data %>%
  filter(., stringr::str_detect(tolower(Sex), "ma"))


# along with toTitleCase() makes it better
data %>%
  mutate(., Sex = tools::toTitleCase(tolower(Sex))) %>%
  filter(., stringr::str_detect(tolower(Sex), "ma"))
```

But notice the `male` and `man` issue is still a problem. Hard code a fix using `%in%` and `case_when()`...

```{r}
data %>%
  mutate(., 
         Sex = case_when(
           tolower(Sex) %in% c("male", "man") ~ "Male",
           tolower(Sex) %in% c("female", "woman") ~ "Female"
         ))
```

Or for a more flexible fix using `str_detect()`...

BUT beware that the order of operations matters here. Because the string "female" contains "ma", you could accidentally recode all  "female" cases to "male" if you perform the `case_when()` conversion on "male" first. 

```{r}
data %>%
  mutate(., 
         Sex = case_when(
           stringr::str_detect(tolower(Sex), "fe") ~ "Female",
           stringr::str_detect(tolower(Sex), "ma") ~ "Male",
         ))
```


# **Filtering Missing Data (`NA`'s)**

`is.na()` will return a logical vector for which `TRUE` represents there are missing values.

Try on the entire data frame...

```{r}
is.na(data)
```

You can see that some columns contain cases/rows with `TRUE` indicating the cell contains `NA`.

The negation operator, `!`, will be used to illustrate some filtering approaches. Because `filter()` will filter out `FALSE` cases and retain `TRUE` ones, so you may sometimes need to negate a function so that you keep the rows you want to keep.  

- `na.omit()`: removes rows with NAs
- `dplyr::filter(., is.na(column_name))`: keep rows with NA in specific variable
- `dplyr::filter(., !is.na(column_name))`: remove rows with NA in specific variable
- `dplyr::filter(., complete.cases(.))`: remove rows


## *Filter using `na.omit()`...*

```{r}
data %>%
  na.omit(.) %>%     # omit any rows with NAs 
  view(.)
```

## *Filter using `is.na()` and `!is.na()`...*

```{r}
data %>%
  filter(., is.na(Sex)) %>%      # keep NAs by variable
  view(.)


data %>%
  filter(., !is.na(Sex)) %>%      # remove NAs by variable
  view(.)


data %>%
  filter(., !is.na(Sex)) %>%      
  filter(., !is.na(Renting)) %>%
  view(.)


# separate calls on separate lines can also make code inclusion/exclusion easy
data %>%
  #filter(., !is.na(Sex)) %>%      
  filter(., !is.na(Renting)) %>%
  view(.)
```

## *Filter using `complete.cases()`...*

The `complete.cases()` function returns a logical vector for which `TRUE` reflects the row has complete information and no missing cases. Using `complete.cases()` along with `filter()`, you would retain all rows `TRUE` rows.

```{r}
data %>%
  dplyr::filter(., complete.cases(.))
```


# **Summarizing Data Using `dplyr`**

To introduce data summary techniques usng `dplyr`, we will open the `diamonds` data set from the `ggplot2` library. Then, we will use `dplyr::summarise()` or `dplyr::summarize()` to summarize the data. The `summarise()` function works similar to `mutate()` insofar as variables are created but differs insofar as the data frame returned from `summarise()` contains only the variable(s) referenced in `summarize()`. 

In the example below, we summarize by creating a new variable which is set to represent some data summary technique. In essence, summarizing is for descriptive statistics. Using `mean()`, we can summarize the data by taking the mean of the `price` variable.

```{r}
diamonds <- ggplot2::diamonds   # assign data to object

diamonds %>%
  summarise(., 
            mean = mean(price, na.rm = T),
            )
```

Notice what is returned is a single value reflecting the mean of all the data in the data frame. We could have obtained the same without using `dplyr`.

```{r}
mean(diamonds$price, na.rm = T)        # $ notation
```

But we lose flexibility of easily adding new summary procedures. 

```{r}
diamonds %>%
  summarise(., 
            mean = mean(price, na.rm = T),
            sd   = sd(price, na.rm = T)
            )
```

Now there is a mean and standard deviation for price. You can also add the sample size using `dplyr::n()`. 

```{r}
diamonds %>%
  summarise(., 
            mean = mean(price, na.rm = T),
            sd   = sd(price, na.rm = T),
            n    = n()
            )
```


# **Summarizing `across()` Multiple Variables**

Summarizing a single variable is useful but if you want to summarize by many, you likely don't want to code a new line for each variable. In such cases, you can use `across()` as a helper function as was used for creating new variables with `mutate()` (see previous lesson).  

Remember `across()` will want you to pass the columns to summarize by, `.cols`, the function for how to summarize, `.fns`, and the names for how to name the new variables, `.names` (which will be `NULL` by default). The `.x` here stands for passing the vector to the mean function and not the data frame. More on `~` and `.x` later.

## *Summarize my numeric variables...*

```{r}
diamonds %>%
  summarise(., across(.cols = where(is.numeric), 
                      .fns  = ~mean(.x, na.rm = TRUE))
            )
```

Passing `.names`...

```{r}
diamonds %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = ~mean(.x, na.rm = TRUE),
                      .names = "{.col}_mean")
            )
```

## *Summarize by variable name vector...*

```{r}
diamonds %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = ~mean(.x, na.rm = TRUE),
                      .names = "{.col}_mean")
            )
```


## *This needs to be moved below - Summarize by two or more functions...*

This requires a little fancy coding by passing two functions as a `list` object.  A `list` is a special object (e.g., container) for which its elements can be different types of objects. Whereas elements of `vectors` can be only character or only numeric, elements of lists can hold different object. One element can be a numeric vector, another element a data frame, another element a character vector, etc. Many functions used in R will actually return lists for which elements contain different types of objects.

Back to two or more functions. If you pass a `list()` with arguments for the `mean` and the `sd`, you can summarize by both. if you want to prevent errors (yes you do) and want to keep the summaries separate, you can modify `.names` to pass the column  and the function, `"{.col}_{.fn}"`. The underscore is not needed; it only helps with readability of the variables.

```{r}
diamonds %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = list(mean = mean, sd = sd),
                      .names = "{.col}_{.fn}")
            )
```


# **Summarizing Data using `group_by()`**

A summary of the entire data set is fine for understanding grand mean and other metrics but this lacks information at a group level, for example, by sex, ethnicity, personality, city, job title, or in the `diamonds` data by diamont `cut`, `clarity`, or other variation.

When summmarizing data, you will often want to summarize by  levels of other variables, either categorical or numeric. In such cases, you can `group_by()` another variable and then summarize.


Let's summarize in several ways after grouping by diamond `cut`.

```{r}
diamonds %>%
  group_by(., cut) %>%
  summarise(., 
            n = n(),  # or also length()
            mean = mean(price, na.rm = T),
            sd   = sd(price, na.rm = T)
            )
```

You see that price increases with `cut` quality. Using `str()` or `glimpse()` you can see `cut` is an ordered factor.

```{r}
diamonds %>% str()
```

But woah, that was a lot of coding lines. Let's pass the summary procedures as a `list`. Unfortunately, `n()` will throw an error but `length()` will also return the length of the vector, after of course, the grouping variable.

Here are a couple ways to do this. If you pass only the functions into the list, `.names` will take on the order of the functions such that mean would be `"_1"`. This is confusing.

```{r}
diamonds %>%
  group_by(., cut) %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = list(mean, sd, length),
                      .names = "{.col}_{.fn}")
            )
```

A better approach would be to assign the function a name in the `list()` function call so that the name is appended and the variable is named meaningfully.

```{r}
diamonds %>%
  group_by(., cut) %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = list(mean = mean, 
                                   sd = sd,
                                   n = length
                                   ),
                      .names = "{.col}_{.fn}")
            )
```

Importantly, however, if a vector contains even one `NA`, remember the returned statistic for the entire vector will also be `NA`. The previous code will *NOT* return correct statistics if you have an `NA`.

You will want to remove them either by filtering rows for `complete.cases()` or omitting `NA`s from the summary statistic function. To illustrate, let's make some data missing in the data frame. Because there are 53,940 rows in the data frame, we can simply make some data in the last row missing. Let's change the data in `depth` and `table` variables to `NA` just to illustrate the point.

```{r}
diamonds[53940, c("depth", "table")]   # the current data

diamonds[53940, c("depth", "table")] <- NA # set these cells to NA

tail(diamonds)               # see missing values
```

Now filter out missing cases...

```{r}
diamonds %>%
  filter(., complete.cases(.)) %>%
  group_by(., cut) %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = list(mean = mean, 
                                   sd = sd,
                                   n = length),
                      .names = "{.col}_{.fn}"
            ))
```

That's likely the easiest approach but if there is an `NA` in some variables and not others (e.g., only `depth` and `table` here), the variables with complete cases will also lose data. Note how `n` is the same for all variables. 

What you may really want to do would be to compute the statistics by omitting `NA`s at the variable level. Now, `across()` has a way to handle this which involves passing an additional argument `na.rm = TRUE` which will adjust the functions, in this case mean and sd functions to include `na.rm = TRUE`. We can add this after `.names`. Unfortunately, however, `length()` annoyingly has no argument for removing `NA`s. If we drop it out of the list, we get the means and standard deviations. 
 
```{r}
diamonds %>%
  filter(., complete.cases(.)) %>%
  group_by(., cut) %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = list(mean = mean, 
                                   sd = sd
                                   ),
                      .names = "{.col}_{.fn}",
                      na.rm = TRUE
            ))
```

So this doesn't solve the problem for all metrics you want to compute. What now?

Approach #1:

We can write our own function that contains `NA` removal in the same way. We just need to ensure we use `na.rm` and not something like `remove.na`. Let's name the function `length_na`.

```{r}
length_na <- function(x, na.rm = FALSE) {
# as length() substitute that calculates length with and without NAs
  if (na.rm) {
    x = length(na.omit(x))
  } else {
    x = length(x)
  }
  return(x)
}
```

And add `length_na` to the list...

```{r}
diamonds %>%
  filter(., complete.cases(.)) %>%
  group_by(., cut) %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = list(mean = mean, 
                                   sd = sd,
                                   n = length_na
                                   ),
                      .names = "{.col}_{.fn}",
                      na.rm = TRUE
            ))
```

But this removed `NA` row-wise and not for each column variable independently. The `carat` variable should not have the name number of cases as `depth` and `table`, both of which contain missing cases. This approach just did the same thing as filtering by complete cases as done earlier with `filter(., complete.cases(.))`.


Approach #2:

When functions do not contain argument for dealing with `NA`s, there is `na.omit()`, a function that takes an object and removes `NA`s. So you can just pass the variable to `na.omit()` and then wrap it in the metric function of interest. Also, because `na.rm = T` cannot be used for `length()`, `na.omit()` offers consistency across all functions and as a result, I believe, less confusion.

Unfortunately, accomplishing this task can be rather tricky and requires some new syntax. This requires usage of what's called a "lamba" technique. Using this type of syntax, we can pass functions to the `.fns` argument. The `?across()` documentation calls it "a purrr-style lambda" in the arguments section (for clarity, `purrr` is a library). This approach can be a little bit confusing, so I’m going to show you an example, and then walk through it step by step.

We need to precede the function with `~` and reference the vector using `.x`. Let's do this and change the `.fns` argument slightly.

General Example:

`name = ~function(na.omit(.x))`

```{r}
diamonds %>%
  group_by(., cut) %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = list(mean = ~mean(na.omit(.x)),
                                   sd = ~sd(na.omit(.x)),
                                   n = ~length(na.omit(.x))),
                      .names = "{.col}_{.fn}"
                      )
            )
```

Great! Now `carat` contains one more case than the other variables. So what's the point of all of this? Well, you need to be careful not to apply functions and assume they are doing what you believe you are doing. You always need to be smarter than the code you use. Also, there is no single answer for dealing with data. Sometimes one approach will be appropriate and in other instances another approch will be. You as the data scientist need to know that there are different methods so that you an decide where to apply those different methods. 


# **Summarizing Data Grouping by Multiple Variables`**

OK, now this gets exciting. When you want to group by additional variables, pass a new one to `group_by()`. Just to keep the output more simple, let's remove one summary function.

```{r}
diamonds %>%
  group_by(., cut, clarity) %>%
  summarise(., across(.cols = c("carat", "depth", "table"), 
                      .fns  = list(mean = ~mean(na.omit(.x)),
#                                   sd = ~sd(na.omit(.x)),
                                   n = ~length(na.omit(.x))),
                      .names = "{.col}_{.fn}"
                      )
            )
```

# **The Data Manipulation Workflow: Putting It All Together**

Of course, all of this can be paired with `select()`, `mutate()`, `filter()`, etc. Here is the data manipulation workflow 

`dataframe %>%`
    `select(., ...) %>%     # select variables of interest`
    `mutate(., ...) %>%     # then create new variables`
    `filter(., ...) %>%     # then filter by rows`
    `group_by(., ...) %>%   # then group for subsetting`
    `summarize(., ...)      # then summarize`






**Fast Summary of NAs by Column**

```{r}
colMeans(is.na(data))    # proportion of NAs per column



colMeans(!is.na(data))   # proportion of NOT NAs per column



which(colMeans(!is.na(data)) > .75)   # returns column index


these_cols <- which(colMeans(!is.na(data)) > .75) # object holding column index

```


**Select columns with high rates or low rates**

Combine above with `select(., which())`

```{r}
data %>%
  select(., c(1, 2, 3))   # by column index


data %>%
  select(., these_cols)   # by vector holding column index


data %>%
  select(., which(colMeans(!is.na(.)) > 0.75))   # by 


# same thing using select_if 
data %>%
  select_if(~mean(!is.na(.)) > 0.75)  

```






Using the "OR" operator, `|`, cases can be included if "this" or "that".

```{r}
data %>%
  dplyr::filter(sex == 'male' | sex == 'female')

# although dplyr::filter(sex %in% c('male', 'female')) would be easier

data %>%
  dplyr::filter(sex == 'male' | age == 27)  

data %>%
  dplyr::filter(dplyr::between(age, 27, 33))

data %>%
  dplyr::filter(., dplyr::between(age, 27, 33))
```

If a vector object is already defined (e.g., `my_levels = c('male', 'female')`), it can be used for filtering also. Such approaches are useful when data manipulation involves reusing a reference as it simplifies coding and reduces errors because the specification is defined only once.

```{r}
my_levels = c('male', 'female')

data %>%
  dplyr::filter(sex %in% my_levels)
```

When inclusion is inappropriate, exclusion may be useful. The `!` operator means "NOT" in `R` so it is great to accomplish the opposite. For example, `dplyr::filter(!sex %in% c('male', NA))` will "filter the data frame to include rows in the `sex` column for which the value is NOT in the vector".

```{r}
# exclusion
data %>%
  dplyr::filter(!sex %in% c('male', NA))  # keep only if NOT in vector

data %>%
  dplyr::filter(!sex %in% c('male', 'Men'))  # keep only if NOT in vector
```


# Applying Multiple Filters for Different Variables 


If the case for the variable is equal to any element in the list:

- `sex %in% c('male', 'Male', 'MALE', 'm', 'M')`

If the case for the variable is NOT equal to any element in the list:

- `!sex %in% c('male', 'Male', 'MALE', 'm', 'M')` # 

If the case for the variable is not equal to:

- `race != 'white'`                               

If the case for the variable is equal to: 

- `aptitude == 'average'`                         # 

If the value for the variable is greater than:

- `age > 30`                                      

if the vase for the variable is greater than AND less than:

- `age >= 30 & age <= 65`                         # 
 


```{r}
datafame %>%
    dplyr::filter(
        sex %in% c('male', 'Male', 'MALE', 'm', 'M') %>%     # if the case for the variable is equal to any element in the list
        !sex %in% c('male', 'Male', 'MALE', 'm', 'M') %>%    # if the case for the variable is NOT equal to any element in the list
        race != 'white',                                     # if the case for the variable is not equal to 
        aptitude == 'average'                                # if the case for the variable is equal to 
        age > 30,                                            # if the vase for the variable is greater than
        age >= 30 & age <= 65,                               # if the vase for the variable is greater than AND less than
  ) 
```


# If you have a vector of column variable names or numeric values and wish to filter by referencing column names that are stored as strings, use the `.data` pronoun in the `dplyr::filter()` call.

```{r}
vars   <- c('weight', 'height')   # vector of two strings that represent variables
#is.vector(vars)
cutoff <- c(100, 150)             # vector of two values representing cutoffs

datafame %>%
  dplyr::filter(
    .data[[vars[[1]]]] > cutoff[[1]],  # filter if the case value of the first element in the vars vector (e.g., weight) is greater than the first element in the cutoff vector (e.g., 100)
    .data[[vars[[2]]]] > cutoff[[2]],  # filter if the case value of the second element in the vars vector is greater than the second element in the cutoff list
    .data[[vars[[1]]]] %in% cutoff,    # filter if the case value first element in vars is in the cutoff vector
  )
```

```{r}

```

# use lappy to loop over the file list and apply the function; add bind_rows to merge as a single data frame.




```{r}
DAT <- csv.files %>%
  lapply(clean_dat) %>%
  dplyr::bind_rows()

DAT %>% view()
```

# Creating New Column Variables or Modifying Existing Variables 

The `dplyr` library uses the verb "mutate" for changing column variables in a data frame. 

`dplyr::mutate()` and `dplyr::rename()` 

```{r}
data %>%
  dplyr::mutate(
    new_numeric    = 0,                  # compute a numeric 
    new_numeric2   = age * 2,            # perform operation on existing numeric
    new_numeric3   = ifelse(age < 30, "younger", "older"), # perform operation on existing numeric
    new_character  = 'blah',         # 
    new_character2 = as.character(age),  # create a character variable from age
    new_logical    = age >= 30,          # True if older than 29
    new_logical2   = as.numeric(age >= 30), # convert a logical to numeric
  ) 

data %>%
  dplyr::rename(    # rename to a different name
    AGE = age,
  ) %>%             # adding a %>% to pipe the returned data frame to the next function
  dplyr::rename(    # rename 
    Age = AGE,
  ) %>%             # new %>% to pass data frame
  dplyr::mutate(    # mutate to create a new column variable
    age = Age
  )
```

# Selecting Column Variables
When data frames are large and not all column variable are needed, the data frame can be subsetted. The `dplyr` verb for selecting certain variables is `select`. The function is `dplyr::select(data, sex)` will select only the `sex` column from the `data` data frame; all other columns will be omitted.  

One way to subset is to use base `R` to partition the data frames columns. Pass a base `R` subsetted data frame and pipe to mutate a new variable

```{r}
 
data[, c("sex", "age")] %>%
  dplyr::mutate(
    Age = age
  )
```

Another way to subset is to use `dplyr::select()` without using `magrittr`.

```{r}
dplyr::select(data, sex)`
```

Piping with `magrittr` makes subsetting easy using the `select()` verb function(s).

Pass the full data frame, mutate, and subset using `dplyr`. Note, `dplyr::mutate()` will only work on variables included in `dplyr::select()`. Selecting `sex` first will disallow for mutating `Age` from `age`.

```{r}
data %>%
  dplyr::mutate(
    Age = age
  ) %>%
  #dplyr::select(sex)  # Selecting will only include that which is specified in select()
  dplyr::select(sex, Age)  # Selecting will only include that which is specified in select()
  # dplyr::select(age) %>% # select only the age column
```

# Removing Missing Values (e.g., `NA`) 

```{r}
data <- data %>%
  dplyr::mutate(
    junk = NA            # create a junk variable where all rows are NA
    number = NA
  )

data %>%
  tidyr::drop_na() # tidyr::drop_na() will drop rows with NA in any column; 
                   # data from is empty now

data %>%
  dplyr::filter(!is.na(junk))

data %>%
  dplyr::filter(., is.na(sex) | age > 1)

data %>%
  dplyr::filter(., is.na(sex) & age > 1)
```



# if_else(condition, true, false, missing = NULL)

Compared to the base ifelse(), this function is more strict. It checks that true and false are the same type. This strictness makes the output type more predictable, and makes it somewhat faster.



# Recoding 

#### recode() https://dplyr.tidyverse.org/reference/recode.html #####

```{r}
recode(char_vec, a = "Apple", b = "Banana")
recode(char_vec, a = "Apple", b = "Banana", .default = NA_character_) #Use .default as replacement for unmatched values. Note that NA and
# replacement values need to be of the same type. 
# Use a named character vector for unquote splicing with !!!
level_key <- c(a = "apple", b = "banana", c = "carrot")
recode(char_vec, !!!level_key)

num_vec <- c(1:4, NA)
recode(num_vec, `2` = 20L, `4` = 40L) #note: recode(num_vec, `2` = 20, `4` = 40) will replace the 2 and 4 but will make all others NA

factor_vec <- factor(c("a", "b", "c"))
recode(factor_vec, a = "Apple", .default = levels(factor_vec))


se recode_factor() to create factors with levels ordered as they
# appear in the recode call. The levels in .default and .missing
# come last.
recode_factor(num_vec, `1` = "z", `2` = "y", `3` = "x")
#> Warning: Unreplaced values treated as NA as `.x` is not compatible.
#> Please specify replacements exhaustively or supply `.default`.
#> [1] z    y    x    <NA> <NA>
#> Levels: z y x
recode_factor(num_vec, `1` = "z", `2` = "y", `3` = "x",
              .default = "D")
```


Sorting and Arranging Lists, Vectors, and Data Frames

```{r}
# sort vector in descending order using sort()
sort(my_numeric_vector, decreasing = TRUE)
sort(my_numeric_vector, decreasing = TRUE)
sort(my_numeric_vector, decreasing = FALSE)

# sort a data frame using dplyr
# sort the dataframe in R using arrange; by default, arrange is ascending
dplyr::arrange(my_data, a_vector)

# sort dataframe using dplyr::arrange()
my_data %>% dplyr::arrange(dplyr::desc(a_vector))

# sort dataframe using multiple variable with dplyr::arrange()
pipe operator first sorts vector_a in descending order and then sorts vector_b in ascending order 
my_data %>% dplyr::arrange(dplyr::desc(vector_a), vector_b)
```

Sort data frame by variable in Descending or Ascending order

```{r}

dplyr::arrange(dplyr::desc(subid))  # descending
dplyr::arrange(subid)               # not descending
```



**Full Matching**

```{r}
rownames(mtcars)

mtcars %>%
  filter(rownames(.) == "Toyota Corolla")  # the rownames of the passed dataframe "."

mtcars %>%
  filter(rownames(.) %in% c("Toyota Corolla", "Toyota Corona")) 
```

Full matches can be difficult if you have a lot of similar strings that you'll have to specify. Can you search for a partial string match?


**Partial Matching**

What if you wanted to select or exclude cases for which string variable or vectors contain certain characters, digits, or patterns. This is where regular expressions (regex) are amazingly useful. There are many string-related functions can utilize regex (e.g., `grep()`,  `gsub()`, etc. ). 

```{r}
names(mtcars)

# select columns
mtcars %>%
  select(contains("g"))   # select variables that contain the letter g

#?contains

# filter rows
mtcars %>% 
   filter(
     str_detect(string = rownames(.), pattern = "Toy|Hon")
     )
 
```


```{r}
mtcars %>% 
  filter(
    str_detect(string = rownames(.), pattern = "Toy")
    )
```


# **Partial Matching After Splitting**

What are the makes and models of the cars?

```{r}
rownames(mtcars)

# make a data frame
make_model <- data.frame(
  stringr::str_split_fixed(rownames(mtcars), " ", 2) #%>% #split on space
)
names(make_model) <- c("make", "model")

# a new data frame
mtcars2 <- cbind(mtcars, make_model)  # use cbind() to bind columns of data frames of the same length

head(mtcars2)
```

Or combine `tidyr` and `dplyr` to make a new variable named **temp** that hold the `rownames` which can be extract using `rowname()` and then split the string using `separate()` by a space using `sep = " "` but if there are more than one space for each make and model set  `extra = merge` so that all the model information is together and the make is separate.

```{r}
mtcars2 <- mtcars %>%
  dplyr::mutate(temp = rownames(.)) %>%
  tidyr::separate(temp,                      # the variable defined above 
                  into = c('make', 'model'), # the columns names, in this case 2
                  sep = ' ',                 # what to sep by
                  extra = "merge")           # how to deal with extra info
head(mtcars2)
```

Now that the variables are included, filter the data set to include car `make` that contains **Toy**  

```{r}
mtcars2 %>%
  filter(make %in% c("Toyota"))

mtcars2 %>%
  filter(make %in% c("Toy"))

# filter on 2 variables, one OR the other using | operator
mtcars2 %>% 
  filter(
    str_detect(string = make, pattern = "Toy|Hon") | #or
    str_detect(string = model, pattern = "Fire|Chal")  
    )
```


However, `stringr` is an amazing string library for manipulating strings.

Another usecase could be that we want to pick rows where the names contain digits.
In Regex (regular expressions), `\d` means "digit". If you use only `\d` The backslash needs to be escaped (by typing an extra backslash), so you need two  backslashes.



- Escaping characters:

Similarly, if we want all values except those with digits, we could say:



The circonflex means “the string starts with”; in this example “the string starts with "M". To get values ending with, say, “L”, we use $ in Regex:
```{r}

```


```{r}
library(stringr)

filter(!str_detect(rowname, "\\d"))  

```


Dealing with messy vectors
- parsing vectors

```{r}
a = data.frame(
  "function_" = c("parse_logical()", 
                   "parse_integer()", 
                   "parse_double()", 
                   "parse_number()", 
                   "parse_character()", 
                   "parse_factors()", 
                   "parse_datetime(), parse_date() and parse_time()"),
  "operation" = c("parse logical expressions", 
              "parse integers",
              "parse real numbers", 
              "parse any type of number", 
              "parse strings", 
              "parse levels for factors", 
              "parse various date and time formats")
)
a %>% view()
```

**Exploratory Data Analysis: Variation**

The goal of *Exploratory Data Analysis* (EDA) is to determine **where** the data
lies and **what types** of pattern exist in the data.

- variation, how to understand the different types of data. 
- `dplyr::count()` is useful here, both for categorical and for numerical data.
When faced with a new data set, the frst step is usually what statisticians call Exploratory Data Analysis (EDA). This is when we frst try to look at what the data is telling us.
There is no one way to approach EDA, partially because at the beginning, there is noway to know what is going on with your data set. 


Three starting metrics:

- **Center**: where is the data located?
- **Variation**: how does the data vary from its center.
- **Covariation**: how two variables move together or in opposition

Some terminology.

- **Variables** are measurable objects or events; either quantitative (numerical; e.g., age, weight, speed, etc.) or qualitative (e.g., emotion, ethnicity, etc.).

- **Value** is the state of a variable when measured.

- **Observations** are a set of measurements of a particular variable (aka data points).

- **Tabular data** is a representation or organization of data as a table. Some data scientists refer to data set up neatly as a set of columns (variable) and rows (cases/observations) as *tidy*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999) # turn off scientific notation  # 0 = sn is on
options(digits = 4)
```




```{r message=FALSE, warning=FALSE, include=FALSE}
rm(list = ls(all.names = TRUE))
proj_dir <- gsub("R/.*.Rmd","", rstudioapi::getActiveDocumentContext()$path)
source(paste0(proj_dir, "R/functions_", tolower(as.character(Sys.info()[7])), ".txt"))
```

# Load Libraries and Functions

```{r message=FALSE, warning=FALSE, include=FALSE}
library(magrittr)
#library(tidyverse)

# pastebin install libraries if not installed
# source()
# pastebin install functions
# source()
```


Obtaining a list of files in a directory that match a search pattern.

# Use piping to clean up the file list; use full.names = T for the entire file path
list.files(dat_dir2, ".csv", full.names = T) %>%   # get the list
  .[grepl("exp2", .)  == T] %>%                    # keep if contain "exp2"
  .[grepl("PARTIC", .) == F] %>%                   # remove if contain partic
  .[file.info(.)$size > 50] -> csv.files           # keep if greater than a certain file size, and create object

(same as)
pattern   = paste0("exp2")
csv.files = csv.files[grepl(pattern, csv.files)  == T]
csv.files = csv.files[grepl("PARTIC", csv.files) == F]
csv.files = csv.files[file.info(csv.files)$size > 50]
(end same as)

# use the same above and make into dplyr code


read.csv(file) %>%
    dplyr::select(dplyr::starts_with('axcpt_')) %>%
    dplyr::rename_with(., ~gsub("axcpt_", "", .)) %>%
    dplyr::filter(!is.na(subid))


Cleaning and combining multiple files.

# function to clean individual files and extract important variables.
```{r}

clean_dat <- function(file) {
  read.csv(file) %>%
    dplyr::select(dplyr::starts_with('axcpt_')) %>%
    dplyr::rename_with(., ~gsub("axcpt_", "", .)) %>%
    dplyr::filter(!is.na(subid))
}
```


```{r}
df <- tibble::tibble(
  a = c(1, 2, 3, 4, 5),
  b = c(5, 4, 3, 2, 1),
  c = c(1, 2, NA, 1, 2),
  d = c("m", "f", "f", "m", NA),
  e = c(999, rep(NA, 4))
  )

df %>% print()

df %>% 
  #dplyr::filter(!is.na(c)) %>%
  dplyr::filter(
    NA %in% 
    !is.na(c),
    a < 4 & b >= 2,
    
    ) %>%
  tidyr::drop_na()

df %>%
  dplyr::filter(complete.cases(.))   # must include the . (often good practice)

  complete.cases(.)

  dplyr::filter()

  df[complete.cases(df), ]
```

