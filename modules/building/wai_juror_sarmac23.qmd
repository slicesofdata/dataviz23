---
title: "Estimating Recidivism Risk from Data Visualizations:\nAccurate or Illusory"
author: "Gabriel Cook, Daniel Krauss, & Lukas Klapatch"
#description: "ljljasljflsaf"
format: revealjs
---


## Libraries

```{r}
library(dplyr)
library(magrittr)
library(ggplot2)

################################################################################
source("C:/Users/gcook/Sync/Data/wai_juror/r/src/functions.txt")

source("C:/Users/gcook/Sync/Progs/R/R-Portable/mypackages/zaatar Scripts/mode.R")
source("C:/Users/gcook/Sync/Progs/R/R-Portable/mypackages/zaatar Scripts/scale_recode.R")
source("C:/Users/gcook/Sync/Data/wai_juror/r/src/kbl_it_table.R")
source(here::here("r", "src",  "data_summary.R"))


#source(here::here("r", "src",  "libraries.R"))
#source(here::here("r", "src",  "functions.txt"))
#source(here::here("r", "src",  "true_count.R"))
#source(here::here("r", "src",  "mode.R"))
#source(here::here("r", "src",  "count_to_prop.R"))
#source(here::here("r", "src",  "kbl_it_table.R"))
#source(here::here("r", "src",  "glm_modPlot.R"))
#source(here::here("r", "src",  "data_summary.R"))

################################################################################
proj_path <- "C:/Users/gcook/Sync/Data/wai_juror/"
data_path <- paste(proj_path, "data", sep = "/")
data_file <- 'wai_juror_exp1.csv'

data_num <- 'wai_juror_numeric.csv'

# Blais Estimate Data
#source(here::here("r", "src", "blais.R"))

# BLAIS_2y_mean,
BLAIS_2y_mean = 9
# BRENT_Score2_mean,
BRENT_Score2_mean = 9
# end 

DAT <- read.csv(paste(data_path, data_file, sep = "/"))

NC <- read.csv(paste(data_path, data_num, sep = "/"), skip = 0) %>% 
  filter(., Status == 0) %>% 
  filter(., !is.na(id)) %>%
  filter(., id != "") %>%
  select(, c(id, starts_with("NC_"))) 


# recode values
NC <- scale_recode(NC, 
             values_from = c( 1,  2,  3,  4, 5, 6, 7, 8, 9), 
             values_to   = c(-4, -3, -2, -1, 0, 1, 2, 3, 4) 
            )

# then reverse these
NC <- scale_recode(NC, 
             cols = c("NC_3", "NC_4", "NC_5", "NC_7", "NC_8", "NC_9", "NC_12", "NC_16", "NC_17"),
             reverse = T
             )

DAT <- DAT %>%
    select(., id, PlotType, Risk, RiskCheck, RiskEntry, CrimeAcc, Plot,
           Score_Risk, AvgScore_Risk, JuryJudge, 
           Score_Risk_Est_Diff, AvgScore_Risk_Est_Diff,
           Score_Risk_Est_Diff_Exp,
           MinNumEst:MinNumEst_3,
           RiskNumEst_1:RiskNumEst_5
           )

DAT <- DAT %>%
  # all sores
  mutate(., AvgScore_OverEst = case_when(
    AvgScore_Risk > BLAIS_2y_mean ~ 1,
    AvgScore_Risk == BLAIS_2y_mean ~ 0,
    AvgScore_Risk < BLAIS_2y_mean ~ 0,
  )) %>%
  # brent score   
  mutate(., Score_OverEst = case_when(
    Score_Risk > BRENT_Score2_mean ~ 1,
    Score_Risk == BRENT_Score2_mean ~ 0,
    Score_Risk < BRENT_Score2_mean ~ 0,
  ))

#DAT %>% view()  

Score_OverEst <- DAT %>%
  #select(., PlotType, AvgScore_Risk, AvgScore_OverEst, Sc) %>%
  group_by(., PlotType) %>%
  summarize(., 
            Score_Est_mean   = mean(Score_Risk, na.rm = T),
            Score_Est_median = median(Score_Risk, na.rm = T),
            Score_OverEst    = sum(Score_OverEst, na.rm = T)/length(na.omit(Score_OverEst)),
            
            AvgScore_Est_mean   = mean(AvgScore_Risk, na.rm = T),
            AvgScore_Est_median = median(AvgScore_Risk, na.rm = T),
            AvgScore_OverEst    = sum(AvgScore_OverEst, na.rm = T)/length(na.omit(AvgScore_OverEst)),
  )


NC = merge(NC, DAT) %>%
  dplyr::filter(., CrimeAcc == 1) %>%   # correct crime
  dplyr::filter(., RiskEntry == 9) %>%  # correct risk reported
  dplyr::filter(., !is.na(JuryJudge))
  

NC <- NC %>%
  filter(., !is.na(NC_1)) %>% 
  mutate(.,
         NFC = rowMeans(select(., starts_with("NC_")), na.rm = TRUE),
         NFC_n = ntile(NFC, 2)
         )


#Mode(DAT$RiskEntry)

AVGScore_by_group <- DAT %>%
  dplyr::filter(., CrimeAcc == 1) %>%   # correct crime
  dplyr::filter(., RiskEntry == 9) %>%
  dplyr::filter(., !is.na(JuryJudge)) %>% 
  dplyr::mutate(., id = seq(1, length(id))) %>%
  means1(., AvgScore_Risk ~ Plot) %>%
  dplyr::select(., Plot, n, AvgScore_Risk, mdn, min, max, skew)

AVGScore_by_group <- AVGScore_by_group[, c("Plot", "n", "mdn")]
names(AVGScore_by_group)[3] = "AvgScore_Risk"

Score_by_group <- DAT %>%
  dplyr::filter(., CrimeAcc == 1) %>%   # correct crime
  dplyr::filter(., RiskEntry == 9) %>%
  dplyr::filter(., !is.na(JuryJudge)) %>% 
  dplyr::mutate(., id = seq(1, length(id))) %>%
  means1(., Score_Risk ~ Plot) %>%
  dplyr::select(., Plot, n, Score_Risk, mdn, min, max, skew)

Score_by_group <- Score_by_group[, c("Plot", "n", "mdn")]
names(Score_by_group)[3] = "Score_Risk"

```

---

```{r}
  #select(., -mean) %>% 
AVGScore_by_group %>%  t() %>% kbl_it(caption = 
      "Mean Scatterplot Estimate for all Static-99R Scores")

Score_by_group %>%  t() %>% kbl_it(caption = 
      "Mean Scatterplot Estimate for Defendant")
```


---

```{r}

#Score_by_group[, c("Plot", "n", "mdn")]
#AVGScore_by_group

NC %>%
  dplyr::filter(., Plot != "None") %>%   # correct crime
  dplyr::filter(., CrimeAcc == 1) %>%   # correct crime
  dplyr::filter(., RiskEntry == 9) %>%
  dplyr::filter(., !is.na(JuryJudge)) %>% 
  ggplot(.) +
  geom_jitter(aes(x = Plot, 
                  y = AvgScore_Risk,
                  #col = as.factor(NFC_n)
                  ), 
              width = .3, size = 3, #shape = 21, 
              alpha = .4,
              col = "blue"
              ) + 
  geom_point(data = AVGScore_by_group, 
             aes(x = Plot,
                 y = AvgScore_Risk),
             col = "black", size = 4
             ) +
  labs(x = "Plot", y = "Estiamted Recidivism of All Scores") +
  scale_y_continuous(limits = c(0, 95), n.breaks = 20) +
  theme_ben()  
#see::theme_modern()
```

---


```{r}
NC %>%
  dplyr::filter(., Plot != "None") %>%   # correct crime
  dplyr::filter(., CrimeAcc == 1) %>%   # correct crime
  dplyr::filter(., RiskEntry == 9) %>%
  dplyr::filter(., !is.na(JuryJudge)) %>% 
  ggplot(.) +
  geom_jitter(aes(x = Plot, 
                  y = Score_Risk,
                  #col = as.factor(NFC_n)
                  ), 
              width = .3, size = 3, #shape = 21, 
              alpha = .4,
              col = "blue"
              ) + 
  geom_point(data = Score_by_group, 
             aes(x = Plot,
                 y = Score_Risk),
             col = "black", size = 4
             ) +
  labs(x = "Plot", y = "Estiamted Recidivism of All Scores") +
  scale_y_continuous(limits = c(0, 65), n.breaks = 20) +
  theme_ben() 

#score_est <- means1(DAT, AvgScore_Risk ~ Plot)[, c("Plot", "mdn")]

```

---

```{r}
# https://journals.sagepub.com/doi/abs/10.1177/0013164490501026
# 

DAT %>%
  #dplyr::filter(., FailedChecks == 0) %>%  # keep no failed checks
  #dplyr::filter(., OrderedRisk  == 1) %>% # keep ordered risk
  dplyr::filter(., RiskEntry == 9) %>%
  dplyr::filter(., !is.na(JuryJudge)) %>%
  #dplyr::filter(., exclusion == "include") %>%
  dplyr::mutate(., id = seq(1, length(id))) %>%
  ggplot(., aes(x = AvgScore_Risk, fill = Plot)) +
  geom_density(alpha = 0.5) + theme_minimal() 
```


---


```{r}
NC %>%
  filter(., PlotType != "noplot") %>%
  ggplot(.) +
  geom_point(mapping = aes(x = NFC, 
                           y = AvgScore_Risk, 
                           col = PlotType)) +
  geom_smooth(mapping = aes(x = NFC, 
                           y = AvgScore_Risk), method = "lm")
```


---


```{r}
NC %>%
  filter(., PlotType != "noplot") %>%
  select(., NFC, AvgScore_Risk, Score_Risk, JuryJudge) %>% #view()
  cor()


#summary(lm(JuryJudge ~ NFC + PlotType, data = NC))
```


---


```{r}


NC %>%
  mutate(.,
         NFC = rowMeans(select(., starts_with("NC_")), na.rm = TRUE),
         NFC_n = ntile(NFC, 1)
         ) %>%
  group_by(., PlotType, NFC_n) %>% 
  summarise(., 
            NFC = mean(NFC, na.rm = T),
            Commit     = mean(JuryJudge, na.rm = T),
            AvgScore_Risk = mean(AvgScore_Risk, na.rm = T),
            Score_Risk    = mean(Score_Risk, na.rm = T), 
            n = dplyr::n()
            ) 
```


---


```{r}
NC %>%
  ggplot(.) + 
  geom_col(mapping = aes(x = NFC, y = Score_Risk)
             ) +
  facet_wrap(PlotType ~ ., ncol = 1)
```


### x

- you are all data minded. You all work with data.

- You know that there are many ways to represent data

- Bar plots, scatterplots, etc.

---

### xx

A decision to represent data represents a commitment to communicating certain elements of a story.

Bar charts for example are typically used to represent some point estimate of the data for example the mean.

Bar charts are sometimes decorated with information that communicates variability around that point estimate.

For example there may be confidence intervals, error bars, or even the data points that make up that point estimate.

Because data visualizations cannot be too cluttered, some elements must be chosen to visualize whereas others will be selected against. In many cases, all of the data in a data set are not presented. Rather data are distilled down to a point and interval estimate and present in some visual or tabular form. My talk today is not designed to judge in any way, it is just to communicate how we, as experts, often present data. 
 s
What out of whatever that is presented in visual form is a particular constraint, which is the visual system.

The way which the visual system operates influences how we attend to, perceive, and process information.

---


### Experts Communicating Data

- Certainly we are all experts trying to communicate our data with our research.

- In the courtroom, there also experts who try to communicate data in a simplified form to jurors.

- Of course, the way that information is communicated to jurors can influence their decisions.

---


### Juror Decisions with Data

::: {.fragment}

- [Krauss, Cook, & Klapatch (2018)](https://onlinelibrary.wiley.com/doi/10.1002/bsl.2379)

- Others

-  In a simulated sexual violent predator hearing, we examined how mock jurors interpret and use recidivism risk expert testimony communicated either categorically, using verbal labels, or probabilistically, using numeric values. Based upon the STATIC-99R, we compared mock jurors' decision-making and verdicts when we manipulated the style of risk communication across four different risk levels. In terms of verdict decisions, we found that higher risk levels were associated with more commitment decisions, but that this relationship only existed for the categorical risk-communication format. We also replicated previous research demonstrating that participants overestimate recidivism risk in general, especially when higher risk is communicated categorically. Finally, our participants did not differentiate well between the four levels of risk offered, instead apparently employing a more simplistic dichotomy between “low” or “high” risk for both their verdict decisions and their thresholds for commitment. The legal and policy implications of our findings are discussed, as well as suggestions for more effective presentation of expert risk testimony.
:::


---

### Data 

In that study, risk was communicated probabilistically and categorically. The entire data set was not communicated.

- Risk was communicated probabilistically and categorically 

- Essentially as point estimates

- Point estimates don't communicate uncertainty

---

### xxxx

- So building off of this particular project we set out to present recidivism rates in visual form.

- Rather than providing mock jurors with information about the labels, we presented recidivism rates in the form of scatterplot

---



### What is a scatterplot?

- okay this is rhetorical.

- A scatter plot


---


####

Effective visualizations like scatterplots communicate data by leveraging
fast and accurate visual processes. Scatterplots map two data
dimensions to position [8, 77], a precise channel for comparing values
[2, 14, 51]. They also leverage our ability to summarize sets of
point marks through ensemble processing mechanisms [6, 35, 87, 93].
Ensemble processing helps readers easily intuit how data points are
distributed, allowing judgments about summary statistics such as correlations
[39, 72], position means [34, 92], and clusters [1].
While ensemble perception is fundamental to visual data comprehension,
it has limitations that can also interfere with effective communication.
Recent work in vision science suggests that visual channels
corresponding to common design elements, like size or color, may systematically bias our abilities to estimate the mean position of a small
collection of point marks [26, 74, 83]. These limitations could manifest
in common visualization techniques like line charts—which lead to
underestimation of means [96] and overestimation of trends [90])—and
scatterplots.

---

### The Role of Data Visualizations

- Just as we know that the characteristics of experts and what they communicate can systematically bias jurors, data visualizations may do so also.

- The scatterplot mapping the risk assessment score with recidivism rates communicates a few things. 

- First, the most prominent characteristic of the plot is likely that the height position of the points tends to increase from left to right.

- You don't need to look at the labels of the axes to perceive this trend.

- This trend also communicates variability or uncertainty in the recidivism rates. In other words, they are not constant.

- Second, looking more carefully, you see that the recidivism rate as plotted on the y-axis tends to increase as the score on the assessment increases. in other words, the assessment score predicts recidivism rates.

- The plot also communicates that recidivism rates have some range to them, on this plot anyway starting at near zero and extending upward to xx.

- At some point you may even wonder where these rates came from because one will either recidivate in some period of time or they may not. 

- And thus, how long are these time periods? 

- Would plot look the same or different for recidivism occurring in 2 years or 5 years? That of course depends on whether someone who does recidivate always does so within the first two years. Some may do so in year 4. 

that one might extract is the trend (Gestalt?)

---


###

- Feature based attention

- the centroid method defines a weight function called an attention filter, a model of feature-based attention our ability to attend items with specific visual features more or less than other items which may cause the bias toward larger darker points. The attention filter corresponds to the visual quote weight of individual marks

- The position mean is a reliable behavioral marker for studying featurebased
attention in vision science [83] and information visualization [34].
Feature-based attention implies that attention is unevenly distributed
across space, skewing towards marks with certain visual features [12].
The attention filters modeled with the centroid method quantify this
skew [83]. When reading visualizations, we rely on feature-based
attention to, for example, make judgments about different data categories
[34] or search for relevant data [38].

---


### Risk Assessment in SVP Proceedings


The most frequently used and validated risk assessment instruments in SVP proceedings are the STATIC-99 (Hanson & Thorton, 2002) and STATIC-99R ([Hemus, Thorton, Hanson, & Babchishin, 2012](https://onlinelibrary.wiley.com/doi/10.1002/bsl.2379#bsl2379-bib-0038); [Neal & Grisso, 2014](https://onlinelibrary.wiley.com/doi/10.1002/bsl.2379#bsl2379-bib-0021)), which are also the most intensely studied instruments of this type (Fazel, Singh, Doll, & Grann, 2012; Singh, Grann, & Fazel, 2011). The STATIC-99R, which was used in this study, contains 10 separate items related to recidivism that produce a total score from −3 to 12 (Helmus et al., 2012). Over 60 studies, involving more than 20,000 offenders in total, have demonstrated that an earlier version of this instrument moderately predicts sexual recidivism ([Hanson & Morton-Bourgon, 2009](https://onlinelibrary.wiley.com/doi/10.1002/bsl.2379#bsl2379-bib-0009). Yet, almost no empirical research has investigated how different forms of risk communication based on this instrument may affect juror decisions in SVP cases.


This latter result is consistent with other research on SVP decision-making suggesting that jurors may ignore or discount expert testimony running counter to their pre-existing beliefs that sex offenders are dangerous and likely to recidivate ([Scurich & Krauss, 2014](https://onlinelibrary.wiley.com/doi/10.1002/bsl.2379#bsl2379-bib-0029)).

---


## Bubble Charts


- For mapping a third plot dimension

- Make an Inverse Recidivism (recode) and shade

- And color

- Have audience Guess



![Scatterplot](/images/Blais_2y_default_500_500.png){width=40%}

---

### xxx
::: {.fragment .fade-in}
::: {.fragment .highlight-red}
::: {.fragment .semi-fade-out}
Fade in > Turn red > Semi fade out
:::
:::
:::

---

### Two-Year Observed and Estimated General Recidivism Rates for 

::: {#fig-stimuli layout-ncol=2}

::: {.fragment}
![](/images/blais-table2S.png)
:::


::: {.fragment}

- Canadian Sample

- Based on BARR-2002R

- *Recidivism Rates* used for creating averages for materials

:::

[Blais, Babchishin, & Hanson (2021)](https://journals.sagepub.com/doi/10.1177/10790632211047185), Table 2S
:::

---


```{r}
blais_dat <- data.frame(
  #rate1 = c(1.2, NA,  3.4, 5.6, 10.8, 9.6, 19,   25.5, 36, 53.2, 50),
  rate = c(1.2, 2.2, 3.4, 5.7, 9.0,  14,  21.2, 30.6, 42, 54.4, NA),
  score = c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8)
)


ggplot(data = blais_dat, aes(x = score, y = rate)) +
  geom_col() +
  scale_x_continuous() +
  scale_y_continuous(limits = c(0, 70), n.breaks = 20) +
#c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8)) +
  labs(x = "Assessment Score", y = "Estimated Recidivism Rates (2 year)") +
  see::theme_modern()

# likelihood that someone has that score. 
?scale_x_discrete 
```



### Two-Year Observed and Estimated General Recidivism Rates for BARR-2002R

::: {#fig-blais}
::: {.fragment}
![](/images/blais-table2S.png)
:::

[Blais, Babchishin, & Hanson (2021)](https://journals.sagepub.com/doi/10.1177/10790632211047185), Table 2S

```{r}
data.frame(
  Score = c(-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8),
  Counts = c("1/82", "0/17", "6/179", "10/179", "27/251", "15/156",
                          "33/174", "39/153", "54/150", "59/111", "3/6"),
  Observed = c("1.2", "0.0", "3.4", "5.6", "10.8", "9.6",
                                     "19.0", "25.5", "36.0", "53.2", "50.0"),
  Predicted = c("1.3", "2.2", "3.5", "5.7", "9.0", "14.0",
                           "21.2", "30.6", "42.0", "54.4", "")
) %>% as_tibble() %>% 
  kableExtra::kbl(caption = "", align = "r") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Calibri")

```

:::

---


### Recidivism Rates by Score

{.absolute top=200 left=0 width="350" height="300"}


::: {#fig-stimuli layout-ncol=2}

::: {.fragment}
![As a Scatterplot](/images/Blais_2y_default_500_500.png){width=40%}
:::
::: {.fragment}
![As a Bubblechart](/images/Blais_2y_size_500_500.png){width=40%}
:::

Stim 
:::

---

```{r}
ToothGrowth %>%
  mutate(supplement = case_when(supp == "OJ" ~ "Orange Juice", supp == "VC" ~ "Vitamin C", TRUE ~ as.character(supp))) %>%
  group_by(supplement, dose) %>%
  summarise(mean_length = mean(len)) %>%
  mutate(categorical_dose = factor(dose)) %>%
  ggplot(aes(x = categorical_dose,
             y = mean_length,
             fill = supplement)) +
  geom_bar(stat = "identity",
           position = "dodge",
           colour = "#FFFFFF", 
           size = 2) +
    labs(x = "Dose",
       y = "Mean length (mm)",
       title = "In smaller doses, Orange Juice was associated with greater mean tooth growth,
compared to equivalent doses of Vitamin C",
       subtitle = "With the highest dose, the mean recorded length was almost identical.") +
  #facet_wrap(~ supplement) +
  #facet_wrap(supplement ~ ., ncol = 2) +
  facet_wrap(~ supplement ~ ., ncol = 1) +
  #facet_wrap(~ supplement ~ ., nrow = 2) +
  theme_minimal()

?facet_wrap

ToothGrowth$supp


```


### Recidivism Corresponding to Defendant's Score

::: {#fig-stimuli layout-ncol=2}

::: {.fragment}
![As a Scatterplot](/images/Brent_2y_score2_default_500_500.png)
:::
::: {.fragment}
![As a Bubblechart](/images/Brent_2y_score2_size_500_500.png)
:::

zzz 
:::

---



## Hong & Witt (2021) and Weighted-Average Illusion

- Mean position estimates were biased toward locations of larger and (to a
lesser extent)

- Our results show that the perceived
mean of a scatterplot is biased towards larger or darker points (H1).
We have labeled this bias the weighted average illusion because the
bias can be explained by asymmetries in weights we assign to marks
based on irrelevant properties like size and color. We found that these
effects were robust to training and increased as the structure in the data
and range of size or lightness increased (§5). Bias always increased as
correlations between position and the third data dimension increased.
This bias was directed toward areas of larger or darker points and, in the
strongest conditions, caused people to misread the average by 35 pixels,
supporting H2. Widening size ranges also affected bias as correlations
increased, partially supporting H3. While these effects were stronger
for size than lightness, they demonstrate the predictability of this bias
as a function of data patterns and design choices (Figure 6).

- The position mean is a reliable behavioral marker for studying featurebased
attention in vision science [83] and information visualization [34].
Feature-based attention implies that attention is unevenly distributed
across space, skewing towards marks with certain visual features [12].
The attention filters modeled with the centroid method quantify this
skew [83]. When reading visualizations, we rely on feature-based
attention to, for example, make judgments about different data categories
[34] or search for relevant data [38]

- However, if feature-based attention was the only factor at play, we
would see the same attention filters in each correlation condition, varying
only as a function of increasing size or lightness ranges. Instead,
we found that the attention filters varied with increasing correlations
in the data as well, indicating there is more to the observed bias than
simple pop-out effects. People may alternatively be using subsampling
or density-driven strategies (Figure 8). We discuss these strategies
below as both potential explanations for the observed bias as well as
opportunities to inform future designs.


- The weighted average illusion
adds to the growing literature of biases [3, 11, 23, 24, 69, 90, 96] that
may affect interpretations of even the most familiar visualizations.
---


###

- *Separability* is the the ease with which our visual system can process one visual
channel without interference from another  ([32, 62, 91])

- Sometimes easy: color and position

- Sometimes difficult

 channels are separable, since our perception of position
is robust to changes in color, and vice versa. But when visualizing
data using red hue values for one measure and blue hue values for another,
people will struggle to process each measure independently [91].

- 
*Position* has been considered separable from all other channels. 

- Position may be integral with some channels for more complex visualization tasks [19, 51]. For example,
position is integral with motion in outlier detection in multivariate
scatterplots [89]. 

See 
Recent studies provide formal models of separability
across color, shape, and size for comparing data values [22, 80, 85],
See 
[Smart and Szafir (2019)](https://dl.acm.org/doi/10.1145/3290605.3300899). 
Measuring the separability of shape, size, andcolor in scatterplots. In Conference on Human Factors in Computing
Systems - Proceedings, pp. 1–14. Association for Computing Machinery,
New York, New York, USA, may 2019. doi: 10.1145/3290605.3300899
[Szafir]9https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8017604)
[Dakin, Tibber, Greenwood, & Morgan (2011)](https://www.pnas.org/doi/10.1073/pnas.1113195108)


but we lack formal models for the separability of position with other
channels in perceiving means and distributions.


---



## Redicivism Estimates

- Improving our Risk Communication: Standardized Risk Levels for BARR-2002R

- 


---


## References

- Blais, J., Babchishin, K. M., & Hanson, R. K. Improving our Risk Communication: Standardized Risk Levels for BARR-2002R. *Sexual Abuse*, ....




--- 

## Questions

- Are estimates of recidivism extracted from plots accurately? 

- Do those estimates influence decision making even when experts provide point estimates?

- Does point size influence estimates of recidivism?

- Do estimates

- Do estimtates correlate with 

---





# Visualizations


::: {#fig-stimuli layout-ncol=2}

![Subsampling](/images/Subsampling.png){#fig-subsampling}

![Density strategy](/images/density_strategy.png){#fig-density_strategy}

Sampling
:::

---




## output location


```{r}
#| output-location: column-fragment
#| code-line-numbers: "|2"

library(ggplot2)

#DAT  |> 
#  ggplot(aes(x = disp, y = mpg)) +
#  geom_point() +
#  geom_smooth(method = "loess", formula = "y~x")
```


## Design

- Independent Multigroup Design

 - No Vizualization
- Same Size Scatter 
- Bubble 


---






## Plot Range

- Min 

- Max


We investigated whether the average position location of points in a scatterplot is influenced by encoding point size as a third dimension in data visualizations (e.g., bubble charts). When estimating the average position of points along an axis, larger points can bias estimations of average in the direction of those larger points. We investigated whether this weighted-average illusion occurs in a real-world scenario involving mock jurors’ estimates of recidivism risk. Of special interest was the degree to which the illusion influences jurors’ commitment decisions especially in the presence of an expert’s testimony, which included an actuarial mean-point estimate of risk.

## Going to sleep

- Get in bed
- Count sheep



## Conference Program Summary:

We investigated whether the average position location of points in a scatterplot is influenced by encoding point size as a third dimension in data visualizations (e.g., bubble charts). When estimating the average position of points along an axis, larger points can bias estimations of average in the direction of those larger points. We investigated whether this weighted-average illusion occurs in a real-world scenario involving mock jurors’ estimates of recidivism risk. Of special interest was the degree to which the illusion influences jurors’ commitment decisions especially in the presence of an expert’s testimony, which included an actuarial mean-point estimate of risk.

## Conference Abstract:

Expert testimony concerning risk and its communication has important implications for legal decisions. Previous research has shown that recidivism risk-presentation format can influence mock jurors. In a simulated sexual violent predator hearing, Krauss, Cook, and Klapatch (2018) investigated how the format of risk communication can influence mock jurors’ decision‐making and verdicts. Risk communication was category-based using verbal labels (e.g., “low”, “high”) or probability-based using median probabilistic point estimates of risk predicted for each category label (e.g., low = 13%, high, 43%). Higher risk levels were associated with more commitment decisions but that this relationship only existed for the category-based risk‐communication format.

Data summaries involving point estimates, however, lack communication of variability also present in the data. Whereas an individual’s actual recidivism in binary, the likelihood of an individual’s predicted recidivism risk in actuarial terms is estimated based on the data of many individuals. Point-estimates of risk provide information about average recidivism risk, typically without regard to uncertainty or variation in risk. Scatterplots represent one form of data visualization that can represent all data and from which viewers can extract summary information. The presentation format of such visualizations can introduce cognitive challenges for the view, which may also bias perception and interpretation.

Scatterplots map two data dimensions to a single position in Cartesian-coordinate space yet take on a diverse range of design variations (Sarikaya & Gleicher, 2018). For example, points may differ in aesthetic (e.g., color, size, shape) based on group membership or some other variable, either enhancing or compromising perception. Changes in the size of scatterplot points can bias estimates of point position in the direction of larger points, resulting in an illusion referred to as the weighted-average illusion (Hong et al., 2022).  

# [this url](https://rstudio-conf-2022.github.io/get-started-quarto/materials/05-presentations.html#/fragments-nesting-1)

## Step 1

- Split slides up with level 2 headers: `## Heading 2`
- Add some markdown + text and/or some R/Python code



## Some R Code

```{r simple}
2 + 2




# comment 
```

## Slide Title

- one 
- two 

## Make this slide Red  {background-color="red"}


## Making a Slide Incremental

Say you want to reveal the content of slide piecemeal without rewriting separate slides with previous content.

. . .

Then add some content...

. . .

Then some more content


## Omit This Slide {visibility = "hidden"}

## Add links

- [cmc](http://cmc.edu "my tooltip")


::: {.incremental}

- First item
- Second item

:::


## Fragments

::: {.fragment}
Fade in
:::

::: {.fragment .fade-out}
Fade out
:::

::: {.fragment .highlight-red}
Highlight red
:::

::: {.fragment .fade-in-then-out}
Fade in, then out
:::

# New Section

## Fragments, nesting

::: {.fragment .fade-in}
::: {.fragment .highlight-red}
::: {.fragment .semi-fade-out}
Fade in > Turn red > Semi fade out
:::
:::
:::


## Fragments, spans

This is an [important sentence!]{.fragment .highlight-red}


Mind the [gap]{.fragment .fade-in} when riding the rail!

# Columns


## Column layout

:::: {.columns}

::: {.column width="40%"}
contents...s
:::

::: {.column width="60%"}
contents...
:::

::::



## Output Location

```{r}
#| output-location: column-fragment
#| code-line-numbers: "|2"

library(ggplot2)

mtcars |> 
  ggplot(aes(x = disp, y = mpg)) +
  geom_point() +
  geom_smooth(method = "loess", formula = "y~x")
```
