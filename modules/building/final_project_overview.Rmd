---
title: "Team-Based Game Data Exploration Project"
#author: ""
date: "Presentation Due: In Class December 8th" #"`r Sys.Date()`"
output:
  html_document:
    #toc: yes
    #toc_depth: 3
    #number_sections: yes
    #code_folding: show # vs. hide
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **Overview**

Your client has tasked your team with identifying users for whom they could create a board game of some sort. They are interested in developing a game that targets a particular type of user based on their cognitive ability (e.g., things they are good at, games they like, etc.). Of course, your client is only concerned with creating a fun game and making money in the process. As such, the game can take any form and utilize any type of game mechanic and belong to any game category. Similarly, the targeted users can be anyone.


# **Data Informed Decisions**

Your client will want to know how you arrived at your conclusions and will want to be able to replicate your findings (with new data) so they know you aren't just taking their money and making up ideas to sell them. Data science involves exploring data for patterns and/or relationships, testing models, and communicating a story about data. You will need to justify your decisions and communicate how you arrived at your user group or groups. You will do this using both model testing and data visualization.

## *Project Data*  

For your project, you will use any and all or the collected class data.

- *General Game Survey Inventory* (e.g., demographic details, ratings of game mechanics, ratings of game characteristics, etc.).
- *Codenames* game survey 
- *TCGCP* game survey
- *Love Letter* game survey
- *Chronology* game survey
- *Stroop* task data 
- *Mental Rotation* task data
- *Operation Span* task data
- *Word Associate* task data

## *Data Descriptions, Summaries, and Plots*

Your story should be based on models, statistics, and plots. You should convey who your users could be, who they might not be, and how you identified them (think process). Model choice and plot choice is up to you. Think about the data, tell a story. 

Provide any necessary data summary to communicate part of your decision process. This information may include central-tendency measures, dispersion measures, or other descriptive data at either the entire group level or sub-group levels (for comparisons). 

- *Using Values*. Provide any necessary numbers (e.g., means, modes, counts, etc.) that would help you communicate elements about your data.

- *Using Tables and Plots*. Create visuals that would be used to tell a story about the data to identify for the client a candidate target user type. 

- *By Testing Models*. In service of your goals, you should utilize both supervised and unsupervised machine learning models covered in the course (or even try your hand in others if you remember from a stats course). Keep in mind that models can be compared. If adding variables changes the model, you don't need to settle on a model in the absolute if that decision to retain that model was made relative to other models. After all, comparing models would be part of the data science journey you navigated. In addition, when models fail to extract key drivers of performance, reveal clusters of groups, etc. the lack of evidence for a model does not mean that the model was unimportant; the lack of evidence may suggest that the relationships you hoped to identify are not present in the data.  

Related to models, keep in mind how to interpret them (review reading and notes as necessary). How do you compare parameters, changes to parameters, standardize parameters, etc.? Because certain estimates can be biased, consider using cross validation approaches for models. Also, as a general rule, don't be biased by *p*-values (which are wildly misinterpreted anyway) but consider instead statistical information like effect size (e.g., variance accounted for, adj-r2, etc.).


## *Data Joining*

Join all user-level data frames matched by user id. You could also join smaller subsets if joining all makes working with the file too challenging or if you lose cases that prevent some analyses. Sometimes creating smaller data frames containing only variables needed for your model is easier to manage. Warning: If you use `na.omit()` to omit rows with NAs, you might omit a lot of rows so consider leaving NAs in when doing so is not a problem for a model. If you do clustering models, you will need them removed. 


## *Data Cleaning and Wrangling*

Clean data as needed, compute any new variables that could be relevant for exploring and summarizing data. Keep in mind that you are not restricted to variables in the data set but are able to create/mutated new variables from single or multiple variables (e.g., binary groups, quartiles, composite scores, etc.). Consider making creative use of existing data frames by rearranging them using `tidyr::pivot_` functions. For example, your aggregated Stroop data may include only SIE and not the two RTs used to compute SIE. 

You might also consider joining elements a survey data frame with disaggregated data if such a model could reveal something interesting as information is lost when aggregating data. You might also consider creating new variables in the disaggregated data so that you have more variables in the aggregated data. For example, your Stroop data likely only have mean- or median-point estimates of behavior for individuals and not measures of dispersion (e.g., variability). Would one's variability, independent of their average performance, relate to other variables meaningfully?


## **Meetings and Report Logs**

Set up weekly meetings or more frequently if that keeps you on task. Make sure to: a) establish specific personal and team goals for the upcoming week (not something like "Will work on variables."), b) report to the team what you have accomplished/how you have met said goals from the previous week, and c) share with me a summary of those goals and accomplishments weekly. Your ability to fulfill your goals will be weighted toward your grade as will be your ability to send me each week a copy of the goals and accomplishments that you send to your team. 

Please keep correspondence in your private slack channel so that I can see what you are doing and provide help. Upload your report logs there (by 11:59pm Thursdays starting this Thursday. The report log will be the same as used of the other project.  


# **Code**

## *Files*

Because the client will want to be able to check your work and verify it with existing as well as new data, among other things, you will need to compile your code into one (or more) R Markdown files that showcase your clean code as well as code commentary about code sections so that you know what you did and the client understands what you did. Organized teams will include clear summary information that can be extracted easily and placed into a presentation slide deck.

## *Freeze and Submission*

By start of class time on presentation day, there is a code freeze. 

Use your team member's last names to name your slide deck (download as PowerPoint if using Google Slides). 
All of your files can be bundled as a compressed zip file. Include your presentation file, .R and/or .Rmd files, and knit HTML code file submission and upload to [here](https://claremontmckenna.app.box.com/f/80863fd8e0f44ec7a95882d9dda8bb91).


# **Teams**

A: Maria-Jose, Ming, Catherine

B: Jenna, Janey, Natasha

C: Kayleah, Rebecca, Brian 

 
