---
title: "Homework 08: Comparing Multiple Sample Means Anova"
author: "partner names"
date: "add date"
output: html_document
---

##Part A##
#General Questions#

1. **QUESTION:** Describe the purpose of a one-way between-subjects ANOVA.

*ANSWER:* 


2. **QUESTION:** Identifying which t-test uses a pooled estimate of variance. Explain why it does.

*ANSWER:* 


3. **QUESTION:** Identify one test that can be used for testing for homoegeneity of variance. 

*ANSWER:* 


3. **QUESTION:** Identify one test that can be used for testing for normality of a distribution. 

*ANSWER:* 



##Part B##

##Before you begin##

This homework exercise involves having you answer some questions, write some code, and create a nice HTML file with your results. When asked different questions, simply either type your coded or written responses after the ANSWER message. When asked to write code to complete sections, type your code in the empty code blocks that follow the ANSWER message (between the back ticks). After adding that code, you must make sure that it will execute. So remember to read the content and run each line of your code as you write it so that you know it executes correctly. If your code does not execute, then RMarkdown won't know what you are telling it to do and your HTML file will not be produced. Also, don't create your HTML file until you finish and know that all of your code works correctly.

##1.0. Installing and using libraries in RStudio##

1.1. Use the RStudio interface to install packages/libraries. Go to the Tools option and select Install Packages. Type the package name(s) correctly using the proper letter casing. Also, make sure that you *check the box to Install Dependencies*. Do not install with code.

Install the package:  plyr

1.2. Key functions used for this assignment, some old, some new: 

- aov() for calculating an ANOVA; built-in stats library
- by() for applying a function to a data frame split out by levels of a factor; built-in base library 
- bartlett.test() for viewing homogeneity of variance; built-in stats library
- count() for viewing the frequency of each factor; plyr library
- densityplot() for creating density plot graphs; lattice library
- describeBy() for descriptive stats for groups; psych library
- histogram() for histograms; lattice library
- leveneTest() for viewing homogeneity of variance; car library
- pairwise.t.test() for examining pairwise comparisons with Bonferroni correction; built-in stats library
- shapiro.test() for testing normality; built-in stats library
- summary.lm() for extracting r-squared; built-in stats library
- TukeyHSD() for analyzing the differences between groups; built-in stats library


## 2.0. Loading libraries ##
If you know what libraries you will use for your code, you can load them now. Use the library() function to load the following libraries: lattice, plyr, psych, and car. A summary of the functions and the libraries is listed above.

*ANSWER:* 
```{r, message = FALSE, warning = FALSE}
library(plyr)
library(car)
library(lattice)
library(psych)

#options(scipen = 999) #remove scientific notation if you want
```

##Part C##
##1.0. Overview of a between-groups ANOVA##

1.1. The statistical procedure for testing variation among the means of more than two groups 
is called the *analysis of variance*, abbreviated as *ANOVA*. The null hypothesis in an analysis of variance is that the several populations being compared all have the same mean. Hypothesis testing in analysis of variance is about whether the means of the samples differ more than you would expect if the null hypothesis were true. This question about means is answered, surprisingly, by analyzing variances (hence the name analysis of variance). Among other reasons, you focus on variances because when you want to know how several means differ, you are asking about the variation among those means

ANOVA is a commonly used statistical technique for investigating data by comparing more than two sample means. When there are multiple levels of one IV and the levels are based on independent groups (e.g., different demographics, random assignment, etc.), *one-way between-subjects ANOVA* is used. This is an extension of *independent-samples t-test* for instances where comparisons are made between more than two groups. There is also a *one-way within-subjects ANOVA* which corresponds to multiple repeated measures conditions for which there is one IV and the levels represent measurements of individuals more than once (e.g., measuring alterness in the morning, afternoon, and evening). This exercise is on the one-way between-subjects ANOVA only. 

1.2. Data for the *one-way between-subjects ANOVA* are grouped on some classification factor, or variable (e.g., class rank) so that group means can be created based on that classification. 

For example, a data frame may look like this:

- ID   ClassRank   Happiness
- 1    Freshman       6
- 2    Freshman       5
- 3    Sophomore      6
- 4    Sophomore      7
- 5    Junior         8
- 6    Junior         8
- 7    Senior         9
- 8    Senior         10


Using some real data, we can read in the class survey data frame. Based on some questions in the survey, we will analyze different DVs by comparing levels of different IVs. 

Read in the Survey data set and assign the contents to a data frame called SURVEY:
```{r}
#setwd("c:/users/gcook/desktop/Psyc109") #set working directory if necessary
SURVEY <- read.csv("SurveyNames.csv")

# There is a misspelling of a variable named Excercise. Let's rename it correctly. 
names(SURVEY)[names(SURVEY) == 'Excercise'] <- 'Exercise'
```


##2.0. Examining Data## 

2.1. As always, examine the str() of the data frame to see the classification of variables in the SURVEY data frame. 

```{r}
str(SURVEY)   #or View(SURVEY)
```

You will notice that many variables are listed as int, or integers but they should not really reflect numerical values. The integers are just placeholders for different groups (e.g., men, women). For example, check out Gender, PolyParty, MusGenre, FavTime, etc. R will read in a data file in a way that it thinks is appropriate. However, sometimes you will need to change the scaling of the variable so that you can perform certain test. Because these variables refer to categories/nominal variables, they are also known as factors. We need to modify them for the ANOVA test. Using the factor() function we will convert them to factors because they are certainly not integers. 

Knowing the sample size of each of the groups is important for many reasons. For instance, you wouldn't want to run an ANOVA when you have really small sample sizes. You can count these by hand of course, but it' much easier to create a frequency table of the variable using the count() function from the plyr library so that you know the sample size for each level of a variable. 

Gender...
```{r}
# get a frequency count to see how many people are in each 
count(SURVEY$Gender)
```

Values are either 0 (men) or 1 (women).



2.2. Now that we the levels and how many people in the different groups, we can create some variables that do not include very small samples. Let's create the factors using the factor() function. If we add two arguments to the function (e.g., levels and labels) we can replace the numbers with names that correspond to the levels of the IV. We will add ".fact" to the new variable so that we know these are our new factors. Let's practice with a simple two-level example. Remember that in order to add the variable to your existing data frame, you have to specify the data frame too. 

Ex. : dataframename$newvariable <- factor(oldvariable, levels, labels)

```{r}
SURVEY$Gender.fact <- factor(SURVEY$Gender, 
                        levels = c(0, 1), 
                        labels = c("Male", "Female"))
```


Political party preference...
```{r}
# get a frequency count to see how many people are in each category
count(SURVEY$PolParty) # too few for an ANOVA with 3 groups

SURVEY$PolParty.fact <- factor(SURVEY$PolParty, 
                               levels = c(0, 1, 2, 3, 4, 5), 
                               labels = c("No Affiliation", "Democrat", "Independent", 
                                          "Libertarian", "Republican", "Green"))
```


Music Genre...
```{r}
# get a count
count(SURVEY$MusGenre)

# create a new factor with 3 groups with samples sized of over 10 each (we don't want really small samples, so we drop them out; they will become NA)
SURVEY$MusGenre.fact <- factor(SURVEY$MusGenre, 
                            levels = c(3, 4, 5), 
                            labels = c("Alternative", "Hip-Hop Rap", "Electronic"))

count(SURVEY$MusGenre.fact)
```

Favorite time of the day...
````{r}
count(SURVEY$FavTime)

SURVEY$FavTime.fact <- factor(SURVEY$FavTime, 
                         levels = c(1, 2, 3, 4), 
                         labels = c("Morning", "Afternoon", "Night", "Late Night"))

count(SURVEY$FavTime.fact)
```

OK, now that you have some IVs with samples that aren't too small and you know what the levels of those IVs are, sized samples, proceed to comparing groups with an ANOVA. 


#3.0. Examing Assumptions of the between-subjects ANOVA###

3.1. Assumptions of a one-way between-subjects ANOVA are the same as for a independent-samples *t*-test except that they apply to two or more groups, not just two groups.

  1. DV is interval/ratio in measurement scale.
  2. The populations have the same variance; homogeneity of variance.
  3. The populations are distributed normally.
  4. Each value is sampled independently from each other value. This assumption requires that           
  each subject provide only one value. If an experimental unit provides two scores, then the values are 
  not independent. 


3.2. Testing the Assumptions

3.2.1. Looking at your data is always good before doing statistical testing. Examine the descriptive statisics for the groups in order to determine what the sample means and variances are. One really useful way to do this is to use the describeBy() function from the psych library. This function takes two main arguments: the DV and the factor IV. Examine amount of exercise for people who have different music genre preferences. We will describe the DV by the IV in order to obtain a bunch of statistics for the levels of MusGenre.fact.

- describeBY(DV, IV)

```{r}
describeBy(SURVEY$Exercise, SURVEY$MusGenre.fact)
```

You can see that there are 3 music groups and because we added labels, the labels are also included. If we didn't add the labels above, the output would be more difficult to interpret, so always create labels first. The sample sizes are no greater than 17, the means are slightly different but around 8 and 9, and the standard deviations also differ slightly but not by much. All distributions also have a slight positive skew which is evidenced by the skew measure as well as the fact that the means are higher than the medians. In order to compare means appropriately for the ANOVA, you need to check assumptions.

3.2.2. Normality can be examined visually of course with a histogram or density plot. Remember that the lattice library makes creating graphs for levels of a factor very easy to do. Use those from the lattice library. The density plot provides more detail about shape. The | tells R to plot the DV separately for each level of IV. 

- densityplot(~ DV | IV) 

```{r}
densityplot(~ SURVEY$Exercise | SURVEY$MusGenre.fact)
```

Adding a "layout" argument helps plots the graphs on top of each other which is usefulf for comparing the means of the distrubutions.

```{r}
densityplot(~ SURVEY$Exercise | SURVEY$MusGenre.fact, layout=c(1,3))
```

Besides looking at the data visually, the shapiro.test() will test for normality. However, the function does not have a built-in way to test normality for the subgroups or levels of a factor. However, the by() function will serve as a helper function to allow you to conduct the test at each level of your factor.

- by(DV, IV, shapiro.test)

```{r}
by(SURVEY$Exercise, SURVEY$MusGenre.fact, shapiro.test)

# to show you more of how the by() function works to repeat tasks, do the same for mean
by(SURVEY$Exercise, SURVEY$MusGenre.fact, mean)
```

Having non-normal distributions is almost preordained with small sample sizes. When you have sample sizes of about 30 or more and you still have normality issues, you may have to transform your data before conducting an ANOVA test. Or you might night be able to even do an ANOVA. Given the shapes of the distributions just examined (some being non-normal), you will consider whether the ANOVA is appropriate as a test.  

Although it appears that we have violated the assumption of normality for the Exercise data for MusGenre.fact, we will continue with our analysis for illustration purposes only. 


3.2.3. Homogeneity of Variance

For an *ANOVA*, one assumption is the *homogeneity of variance* (HOV) assumption. That is, in an *ANOVA* we assume that variances of the groups are equal. Much like with the *t*-test, moderate deviations from equal variances do not seriously affect the results of the *ANOVA*. In other words, the *ANOVA* is robust to small deviations from the *HOV* assumption. We only need to be concerned about large deviations from this assumption. There are several ways to test this assumption; two of those are the Levene's test and the Bartlett test. The Bartlett test is a common test for the homogeneity of variances when the data are distributed normally. 

If your distributions are normal, you can use the Bartlett's test for violations in the homogeneity of variance using the bartlett.test() function. This test uses two main arguments and follows in formula format, the DV as a function of the IV: 

-  bartlett.test(DV ~ IV)
  
```{r}
# Bartlett test
bartlett.test(SURVEY$Exercise ~ SURVEY$MusGenre.fact)
```

If you examine the *p*-value, you will see that it is larger than an alpha = .05, so there appears to homogeneity of variance. However, because some of our levels of the IV has a very small sample size and because there was some positive skew to the distributions (see earlier description of the descriptive statistics), the Levene's Test would be more appropriate than the Bartlett test because it is not as sensitive to departures from normality as is the Bartlett's test. The Levene's test takes two arguments, the DV and the factor IV, but is not in the form of a formula:

-  leveneTest(DV, IV)

```{r}
leveneTest(SURVEY$Tip, SURVEY$MusGenre.fact)
```

If you notice from the title of the output, the default version of the Levene test is based on "medians" which is supposedly more robust and accurate than that based on "means". If you wanted to use means for the variance measure, you can simply use the *center* argument and set it equal to "mean". If the mean version makes more sense to you, use that one, but remember to use "center = mean" because by default "center = median".

```{r}
leveneTest(SURVEY$Tip, SURVEY$MusGenre.fact, center = mean)
```

Because the Levene's test is comparing the 3 groups, the test provides an *F*-value which ironically is an ANOVA value. One way to think about the Levene's test when there are more than 2 groups is that it's an ANOVA test on the variances rather than the means. The *p*-value can be used for interpretation. Both versions of the test reveal that the variances are not different (e.g., *p* > alpha), suggesting that we likely have not violated the homogeneity of variance assumption. 

We can write the Levene's test result as:

- *F*(2, 38) = .7532, *p* > .05.



##4.0. Conducting the ANOVA test##

4.1. The ANOVA stands for *Analysis of Variance*, which is actually a test of the ratio of variance between groups (e.g., between-groups variability = sample means deviated from a grand mean) to variance within groups (e.g., within-groups variability = how people within samples deviate from their respective sample means). In order words, when an IV does not explain the data, the differences between the sample means will be about the sames as the variability within the sample means. When the difference between groups is larger than the difference between people in groups, the *F* value will be larger and has a greater likelihood of suggesting that the sample means differ from one another. 

The ANOVA test provides an *F* ratio: 

-  *F* = between-groups variance  /  within-groups variance 
  
  And because you know that the unbiased variance = SS/df...
  
-  *F* = between groups SS/df  /  within groups SS/df 
  


4.2. In order to obtain the *F* ratio value, SS, degrees of freedom, and the *p*-value, the aov() can be used for fitting ANOVA models for categorical IVs.

The aov() function follows the same format as the lm() function for regression. 

-  aov(DV ~ IV)


Specify the linear model by setting the DV and the IV and assign the result to an object named EXERCISE.aov. The aov is a useful reminder of the aov() function so you know which test you ran. However, you could name the object anything you wanted.

```{r}
EXERCISE.aov <- aov(Exercise ~ MusGenre.fact, data = SURVEY) 

# or if you prefer using the $ approach you can specify SURVEY twice 
EXERCISE.aov <- aov(SURVEY$Exercise ~ SURVEY$MusGenre.fact) 
```

Then use the anova() function on the model you created in order to examine the ouput.

```{r}
anova(EXERCISE.aov)
```

**BONUS:** If there is heterogeneity of variance and you want to use a Welch correction for multiple groups, you can use the oneway.test() function for ANOVA. Like the aov() function, you specify the DV as a function of the IV. However, the output does not provide SS, so it's limited in this context. You can read up more on it if interested. 

-  oneway.test(DV ~ IV)


4.3. The output of the anova() function displays 2 rows (e.g., between-groups and within-groups/residuals information) and 5 columns of values (e.g., degrees of freedom, Sums of Squares, Mean Squares, F-value, and p-value. For illustration purposes only, the description below also describes how the values in the output are used to calculate the F-value. 

**Degrees of Freedom** 

-  *Between-groups df* (#groups - 1): 3 - 1 = 2

-  *Within-groups df* (n - 1): 
    1. Alternative: 14 - 1
    2. Hip Hop and Rap: 17 - 1
    3. Electronic: 10 - 1
    -  Total: 13 + 16 + 9 = 38

**Mean Squares**

- Mean squares are simply SS/df (variances). Taken from the output,

```{r}
MSbetween <- 14.4/2
MSwithin <- 1962.8/38
```

**F-value and p-value**

- And the *F* ratio is simply a ratio of the two MS (variances). 

```{r}
Fval <- MSbetween/MSwithin

# examine the values 
MSbetween; MSwithin; Fval
```


4.4. When reporting the between-subjects ANOVA, you need so specify the F value along with degrees of freedom because there is a family of F values just like there is a family of t values and the calculated test is a test of the data fitting an F distribution of a certain combination of degrees of freedom for the groups and the error:

-  *F*(between-groups df, within-groups df) = F, *p*-value. 
  
-  *F*(2, 38) = .1394, *p* > .05.
  

##5. More on Understanding the Variance

5.1 The Sum of Squares

ANOVA is a method for testing differences among means by analyzing variance. ANOVA partitions the variability among all the values into one component that is due to variability among group means (due to the treatment) and another component that is due to variability within the groups (also called residual variation). Variability within groups (within the levels of the IV) is quantified as the sum of squares of the differences between each value in a sample and that sample mean. 

For Example, in our ANOVA:
The between-groups SS, which examine the differences among the group means from a grand mean (mean of all means) is: 

- *64.4* with a DF of *4*

and...

The within-groups SS, which examine error variation, or variation of individual scores around each group mean. This error is variation in the scores that is not due to the treatment (or IV) is:

-  *437.2* with a DF of *49*. 


5.2. The Mean Square

Each SS is associated with a certain number of degrees of freedom (df, computed from number of subjects and number of groups), and the mean square (MS) is computed by dividing the SS by the appropriate number of df. These can be thought of as variances, SS/df. I'm sorry that someone created a new name for them. Just think about the MS as between-groups and within-groups variance estimates.

The MS values obtained can be found in the ANOVA table that we previously ran earlier under the Mean Sq column. 

5.3 The *F*-value

The F ratio is the ratio of two variances, or well, MS values. If the null hypothesis is true, you expect F to have a value close to 1.0; the variances are the same and therefore the IV does not explain the data. The larger the F ratio, the greater the variation among group means relative to the error within groups. In order words the groups differ from one another than are the people within the groups differ from each other. 

You'll see a large F ratio both when H0 of equal groups means does not really account for the data (the data are not sampled from populations with the same means) or when random sampling accidentally produced samples with means that are not equal even thoguh they should be (if the H0 did account for the data). 


5.4. The P value is determined from the F ratio and the two values for degrees of freedom shown in the ANOVA table. Luckily you do not need to look up any values in a table when running the analysis in R.


## 6. Post-hoc tests

6.1. If you achieve significance in with your ANOVA you must run a post-hoc test to determine which levles of the factor are significantly different from other another. Post-hoc test correct for familywise error rate.  Two methods for post-hoc testing include using the TukeyHSD() and the pairwise.t.test() functions. 

6.2. TukeyHSD (Tukey Honest Significant Differences) is a commonly used test to show which levels are significantly different from othe another. You simply put the ANOVA model in the function.

```{r}
TukeyHSD(EXERCISE.aov)
```

As you can see this compares each of the groups to each other and shows you the differences as well as the *p*value for each of the pairwise tests. In this case, there are no significant differences between Exercise habits for individuals who prefer different Genres of music. 


6.3. Unlike, TukeyHSD, the pairwise.t.test() function requires you to specify the DV and the IV and specify the adjustment of the p value. This pairwise comparison adjusts the *p*-value due to the familywise error rate. A common correction is *Bonferroni*.

```{r}
pairwise.t.test(SURVEY$Exercise, SURVEY$MusGenre.fact, p.adj = "bonf")
```

Notice that the *p*-values are all 1, or > .05. 



## 7. Effect Size

calculate an effect size after conducting an appropriate statistical test for significance. This post will look at effect size with ANOVA, which is not the same as other tests (like a *t*-test). When using effect size with ANOVA, we use a measure of *r*-squared, which reflects the ratio of variability that the model explains out of all the variability that exists. This meausure is sometimes also referred to as *Eta squared*. 

- *r*-squared is SS model / SS total. For our example we simply divide:

```{r}
r2 <- 14.4 / (14.4 + 1962.8)
round(r2, 4) # if you don't like all the decimals
```

Or, because *r*-squared is based on the linear model, use summary.lm() and extract the r.squared value.
```{r}
r2 <- summary.lm(EXERCISE.aov)$r.squared
round(r2, 4)
```


In this example, there was no difference between Genre groups and how much they exercise, so having a small effect size makes a lot of sense. 


##8.0. Graphing##

If you want to create a graph of the conditions, one way to do so is to create a simple box-and-whisker plot for the levels of the factor by using the lattice package. Plot the DV as a function of the IV. Box-and-whisker plots use the bwplot() function. They are nice because they convey a lot of information. A good summary and illustration is at http://flowingdata.com/2008/02/15/how-to-read-and-use-a-box-and-whisker-plot/

- The point on the box represents the median, not the mean. However, when distributions are noy skewed the means and medians are the same. When they are skewed, the median is more informative anyway. Remember the median is the 50th percentile score which splits the distribution into two equal parts.  

- The box boundaries indicate the 25th and 75th percentiles; thus only 25% of the scores fall below or above the box boundaries.

- The whiskers provide information about the most extreme scores in the distribution; thus the whiskers represent the 25% between the box and the whisker. 

- If there are dots that fall beyond the whiskers, they are treated as outliers, which makes identifying values easy. There are no outliers here, however. 

```{r}
# basic (not really pretty)
boxplot(SURVEY$Exercise ~ SURVEY$MusGenre.fact)

# lattice version
bwplot(SURVEY$Exercise ~ SURVEY$MusGenre.fact)

# lattice more fancy
bwplot(SURVEY$Exercise ~ SURVEY$MusGenre.fact, 
       ylab = "Hours of Exercise", 
       xlab = "Music Genre",
       col = "red",
       fill = "yellow")
```

##Part D##
##Do it yourself!##

One question asked on the survey was electronic device used most and hours spent on social media. Consider the case for which you want to determine whether people who listen different types of music exercise different amounts. The variable names in the SURVEY data frame are *FavTime.fact* (we already made this a factor) and *Exercise*.

1. **QUESTION:** Produce a density plot of the DV for each level of the IV.  

*CODED ANSWER:*
```{r}
```


2. **QUESTION:** Based on how the plots look, you might expect there to be differences in normality for each group as well as with variance across the groups. Test for that. 

*CODED ANSWER:*
```{r}
by(SURVEY$Exercise, SURVEY$FavTime.fact, shapiro.test)
```


3. **QUESTION:** You might also wonder if the groups had similar variances. Test for the assumption of homogeneity of variance with center = mean.

*CODED ANSWER*:
```{r}
```


4. **QUESTION:** Create the ANOVA model using the aov() function and name the model something:

*CODED ANSWER:*
```{r}
```


5. **QUESTION:** Examing the model ouput to determine whether your ANOVA test reveals differences between groups.

*CODED ANSWER:*
```{r}
```


6. **QUESTION:** What is the Sum of Squares for Between-groups?

*ANSWER:*



7. **QUESTION:** What is the Sum of Squares for Within-groups?

*ANSWER:*



8. **QUESTION:** Were the groups significantly different? Explain how you made that decision. 

*ANSWER:*



9. **QUESTION:** The result of the ANOVA determines whether to run a post-hoc test. For practic, run a post-hoc test to determine which factors levels would be significantly different and the direction of that difference. For example, use the Tukey HSD test to compare all groups or a pairwise test with the Bonferroni correction.  

*CODED ANSWER:*
```{r}
```


10. **QUESTION:** Now that you have your data, you might want to share a graph. Create a boxplot.

*CODED ANSWER:*
```{r}
```


