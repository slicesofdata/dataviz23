---
title: "HW 6: z-tests, t-tests, and effect sizes"
author: "partner names"
date: "type date"
output: 
 html_document:
   toc: true # this will create a table of contents of hyperlinks (change to false to omit)
   toc_depth: 2
---

# Before you begin

This homework exercise involves you answering some questions, writing some code, and creating a nice HTML file with your results. When asked different questions, simply type your coded or written responses after the ANSWER message. When asked to write code to complete sections, type your code in the empty code blocks that follow the ANSWER message. After adding that code, you must make sure that it will execute. So, remember to read the content and run each line of your code as you write it so that you know it executes correctly. If your code does not execute, then `R Markdown` won't know what you are telling it to do and your HTML file will not be produced. Also, don't create your HTML file until you finish and know that all your code works correctly.

## 1. Checking your working directory
Always make sure that your working directory points to Psyc109 on your desktop. 
```{r}
getwd()
```


1.2. Key functions used for this assignment: 

- `as.data.frame()` for combining vectors into a data frame
- `lattice::histogram()` for histograms
- `length()` obtain the length of an object or variable
- `nortest::lillie.test()` or `shapiro.test` for testing normality
- `mean()` obtain the mean of an object or variable
- `options()` for changing the scientific notation display (e.g., scipen = 999)
- `qqnorm()` and `qqline()` for examining normality
- `read.csv()` read in a csv file
- `str()` to obtain the structure of a data.frame
- `subset()` for grabbing select variables from a data.frame
- `summary()`  for viewing descriptive statistics of a variable 
- `t2r()` for calculting the effect size for a t.test; on my dropbox
- `t.test()` for calculating t-tests; built-in stats library
- `z.test()` for calculating z-test; on my dropbox

## 2. Loading libraries

2.1. Run the code below to download some libraries needed for this assignment. By using `include=FALSE, cache=FALSE` in the `R` code header, we will make sure that any error messages do not appear in the HTML file you create.

```{r include=FALSE, cache=FALSE}
source("https://dl.dropboxusercontent.com/u/6036547/109_2016_f.txt?raw=1")
```

If you know what libraries you will use for your code, you can load them now. Use `library()` to load the following libraries: `lattice`, `nortest`, `PerformanceAnalytics`, `moments`, `lattice`, `psych`. 


*ANSWER:* 
```{r, message = FALSE, warning = FALSE}


```

Change from scientific notation if you want. 

```{r}
options(scipen = 999) # to turn on, set: options(scipen=0)
```

#Part A
##1. Overview of the z-test

1.1. The *z*-test is used to compare a sample mean to a population mean to determine if the population from which the sample was drawn is different from another population. The *z*-test is also only used for variables that are distributed normally. The NHST perspective assumes equivalence between the two populations (e.g., H0: mu1 = mu2), so a difference between the two groups should be 0 on average *IF* the populations have equivalent means. If, however, the sample produces a mean that differs from the population mean, you need to determine how likely such a result would occur under H0. If the likelihood is below your level of acceptable risk of making a Type I error, you could claim that the populations likely differ in their means and that the null hypothesis may not be a reasonable model.

1.2. In order to make such a comparison for the *z*-test, you will need to know the

- **(a)** population mean, mu, 
- **(b)** the population standard deviation, sigma, 
- **(c)** the sample mean, xbar, and 
- **(d)** the sample size, *n*. 

Because the standard deviation of sampling distributions is called the standard error of the mean, the *z*-test tells you how many standard errors the sample mean deviates from the population mean. As with extreme *z*-scores, large *z*-test values are less likely to occur due to chance if there is no difference between the population and your sample on your dependent variable. 


1.4. Read the `cdc.csv` file the you have used before. Assign it to an object named `HEALTH`.  

**ANSWER:**
```{r}


# examine
head(HEALTH)

# add a constant variable to the data frame (for grouping everyone)
HEALTH$All <- 0
```

1.5. If we wanted to test the average height of people in our sample to that of an average height of a population, we need to specify those values. Obtain the descriptive statistics for `Height` (inches) from your sample data from the `cdc.csv` file. You can use `psych::describeBy` and identify the grouping variable.


```{r}

```

1.6. You would normally examine whether the heights are distributed normally. We won't do that here, however, doing so is important. Now that you know the sample's mean height, you will need to compare that to the population mean. Let's assume that the average adult height of the population is 67 inches tall (5'7") with a standard deviation of 3 inches. The population data are also normally distributed. Create an object called `Popmean` and assign it a value of 67; create an object called `Popsd` and assign it a value of 3.


**ANSWER:**

```{r}

```

1.7. The `cdc` data set contains data from very many people (20K). Let's still just assume that's a sample for this exercise. However, your samples will be much smaller of course. In order to calculate the standard error of the mean for the *z*-test, you will need to know the size of your sample. Use `length()` to obtain the number of people in your height variable and assign that to an object named `Samplesize`.

- Ex:  `with(dataframe, length(myvariable))`

**ANSWER:**

```{r}



#take a look at it
Samplesize
```

1.8. Now use all of those pieces of information to plug into `z.test()` from the class source library. Select your dataframe with `with()` and specify the other information needed to conduct the test. You can copy your modified code and then put it in the `R` code block to execute. Remember all `R` code needs to be in those code blocks. 

Formula: `z test = (Sample mean - population mean) / (sigma / sqrt(n))`

Ex: `with(dataframe, z.test(data = ??, null.mu = ??, sigma = ??))`

**ANSWER:**
```{r}


```


1.9. **QUESTION** Notice the *z*-test value and the *p*-value for the test. Compare your *p*-value to your alpha .05 and decided whether you would retain or reject H0. State your answer in words.

**ANSWER:** 


1.10. One thing you will have noticed about this test is that when you have very, very, large sample sizes, the standard error of the mean (sigma/sqrt(n)) will be very, very small. Consequently, you may reject H0 even when the sample mean is very close to the population mean. I used this example to illustrate that point and make you become vigilant about data using very large samples. 


#Part B
##1. Overview of the one-sample *t*-test

1.1. The procedures for testing hypotheses described up to this point compared a group of scores to a known population (e.g., z-test). For many research questions, however, you do not have any direct information about the populations you wish to study. In such cases, you can estimate population parameters using sample statistics. These kinds of research situations are very common in behavioral and social science research, where usually the only information available is from the samples. You want to compare the mean of the scores in a sample to a population for which the mean is known but the variance is unknown. Hypothesis testing in this situation is called a *one-sample t-test*.

The *one-sample t-test*, like the *z-test*, compares the mean of a single sample to a hypothesized population value (e.g., mu).  Unlike the other *t*-tests (e.g. independent and dependent), this test analyzes data from only one dependent variable. 

For example: To test this we are going to create a data set of 20 first year resident female doctors resting systolic blood pressure drawn at random from one area

If you don't already have data in a data frame, you can combine values into vector variables and then combine them into a data frame object using the built-in `data.frame()` . We will create two vectors by combining values using `c()` to combine them. 

```{r}
Id <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)
Bp <- c(128, 127, 124, 126, 144, 142, 133, 140, 132, 131, 130, 132, 149, 122, 139, 119,136, 129, 126, 128)

BLOOD <- data.frame(Id, Bp) # pass the two vectors into the function to create a date frame object. 

# look at the data frame; look for NAs
str(BLOOD)
BLOOD
```
1.2. Examining the descriptive statsitics for the mean, standard deviation, and skew.

```{r}
with(BLOOD, psych::describe(Bp))
```


1.3.  Examining Data and Assumptions of *t*-tests. 

After determining that your data are either interval or ratio in scale, you should examine whether normality of our data is a reasonable assumption. In the process, you can look for outliers in the data, which you should normally remove, but you don't have to here. 

```{r}
with(BLOOD, lattice::histogram(~Bp, breaks = 20)) # use the breaks argument to manipulate how many breaks to put in your histogram so that you can see the distribution better than the default option
```

You can also examine normal fit using quantile-quantile plots. These plots show theoretical values that are expected for a normal distribution on the x-axis and the sample data on the y-axis. By adding a line to the plot, you can think of the line a what would be predicted for normal data; if the points fall on the line indicates perfect normality, whereas the less they fall along the line, the less likely the data are distributed normally.  Severe problems are revealed when most points fall above (or below) the line, which indicates skew.  (See also Field pp. 172 or [Q-Q Plots](http://data.library.virginia.edu/understanding-q-q-plots/) ).

```{r}
with(BLOOD, qqnorm(Bp)) 
with(BLOOD, qqline(Bp))
```

1.4. You can also use different statistical tests to examine whether the shape of distribution fits the shape or characteristics of a normal distribution. H0 for these tests is that the distribution is normal in shape, so if the distribution of your data deviates too far from normality, the *p*-value will be small. Some tests are included in the`nortest library`. We will use the Shapiro-Wilk test using `shapiro.test()` and the Lilliefors (Kolmogorov-Smirnov) test for normality using `lillie.test()`.  


```{r}
# pass the variable of interest into the function
with(BLOOD , shapiro.test(Bp)) # The p value is > .05

# pass the variable into the function
with(BLOOD, nortest::lillie.test(Bp)) # The p value is > .05
```

To report the outcome of the Shapiro-Wilk test, the general form is:

  *S-W*(df) = test value, *p* < or > alpha 


By substitution and making sure to italicize S-W and p, we can say:

  The distribution of resting systolic blood pressure for the sample of first year resident female doctors did not differ statistically from that of a normal distribution, *S-W*(19) = .96, *p* > .05. Normality is a reasonable assumption for the sampling distribution.


1.5. If your data adhere to a fairly normal distribution, you can compare your sample mean to a population mean using the one-sample *t*-test. In order to calculate a one-sample *t*-test you must obtain the mean and standard deviation of the sample. You could do this manually as you have before, but functions will also accomplish this. Again, `psych::describe` will be helpful.

```{r}
with(BLOOD, psych::describe(Bp))
```

Knowing your sample mean and standard deviation you also must know the mean of the population you are testing. From previous large studies of women drawn at random from the healthy general public, a resting systolic blood pressure of 120 mm Hg was predicted as the population mean for the relevant age group.  

A data summary:

- Sample mean = 131.85
- Population mean = 120
- Sample size n = 20
- Sample sd = 7.741039

Below is the formula to conduct a one-sample *t*-test:

- `t = (Sample mean - population mean) / (unbiased sample sd / sqrt(n))`

By substitution,

- `t = (131.85 - 120)/ (7.741039)/ sqrt(20))`


1.6. Use `t.test` to calculate the *t*-value and obtain the corresponding *p*-value. Of course, you will need to specify variable and the population mean arguments in `t.test()`.   

The general formula is:  

-  `t.test(dependent variable, mu = population mean)`


```{r}
# to see the print out only
with(BLOOD, t.test(Bp, mu = 120))

# or assign the information from the test to an object named something useful like Blood.t
Blood.t <- with(BLOOD, t.test(Bp, mu = 120))
```


##2. Reporting the test statistic values

Based on the `R` output, you will see the variable for which you calculated the sample mean and estimated standard deviation (S), the *t*-value based on the calculation, the degrees of freedom for the mean (n - 1), and the *p*-value correspond to finding a difference between the sample and population means if they were supposed to be equal to each other under H0. 

When you calculate a *t*-test and report the results of the statistic, you will need to specify the *t*-value and the degrees of freedom (See also Field's chapter on t-tests). The df for the one-sample *t*-test is n - 1. 

To report the outcome of the test, the general form is:

- *t*(df) = t-value, *p* < or > alpha 

By substitution and making sure to italicize t and p, we can say:

  First year resident female doctors had resting systolic blood pressures that was statistically higher than that of the population, *t*(19) = 6.85, *p* < .05.


If you used the *p*-value to make decisions about H0, you could interpret the data as evidence for the sample (its mean) being different from the population mean. In other words, you have evidence that your sample does not come from a population with a mean of 120; your sample likely comes from a population with a mean that is statistically greater than 120 (perhaps closer to 131.85). 

You don't always need to compare a sample mean to a population mean. Perhaps you want to compare your sample mean to some hypothetical value. Some other uses of a one-sample *t*-test include:

- **(a)** testing a sample against a pre-defined value, 
- **(b)** testing a sample against an expected value (e.g, mu), 
- **(c)** testing a sample against common sense or expectations, 
- **(d)** testing the results of a replicated experiment against the results of an original study


##4. Degrees of Freedom

The concept of degrees of freedom is central to the principle of estimating statistics of populations from samples of them. "Degrees of freedom" is commonly abbreviated to df. In short, think of df as a mathematical restriction that we need to put in place when we calculate an estimate one statistic from an estimate of another. The idea is that, when estimating the variance, you first have to know the mean. If you know the mean and all but one of the scores in the sample, you can figure out the one you do not know with a little arithmetic. Thus, once you know the mean, one of the scores in the sample is not free to have any possible value. So in this kind of situation the df is the number of scores minus 1. 

In terms of a formula, *df* = *n* - 1

In our example, we have 19 degrees of freedom:

```{r}
df = 20 - 1 #Because our n is 20
df

# or use the length() function
df = with(BLOOD, length(Bp) - 1)
df                                 
```                                                     


##5. Assumptions for *t*-tests

5.1. As we have seen, when you are using an estimated population variance, the comparison distribution is a *t* distribution rather than a *z* distribution (normal).

However, in order to perform a *t*-test, there are a few assumptions that should be met. 

5.2. Assumptions for the one-sample *t*-test

- **(a)** The data must be interval/ratio
- **(b)** The sampling distribution should follow the normal probability distribution (check the data distribution to get an idea of this assumption)
- **(c)** The sample represents a random sample from its population


##6. Effect size: Calculating the strength of an effect

The conventions for effect size may already be familiar to you in the form of correlation values. Correlation providing a measure of the strength of relationship between variables. Typically, a larger effect size provides better evidence for the difference between comparison groups. 

6.1. Correlation-based effect sizes

One measure of effect size is the Pearson's *r* correlation coefficient, *r*, which can range from -1.0 to +1.0. Related, *r*-squared represented an estimate of the amount of the variance within an experiment that is "accounted for" by the statistical model (e.g., linear regression). This can range from 0 to 1.0. Effect sizes vary from discipline to discipline, so rather than determine was the small or large, just know that larger is generally better.  

We can obtain Pearson's *r* correlation coefficient, *r*, and *r*-squared by using `t2r` a function that you downloaded from the source code. This will obtain the *t*-value, df, *p*-value, *r* and *r*-squared for a t-score.

```{r}
## Obtain the effect size
t2r(Blood.t)
```

6.2. Cohen's *d* effect size

Another measure of effect size is Cohen's *d*. In its general form, this is a measure of the difference between comparison groups as a function of standard deviations. The greater the number of standard deviations that separate the two means, the larger the effect size. Because the measurement is in terms of standard deviations, large difference scores that are accompanied by large standard deviations are not impressive in terms of effect size, whereas large difference scores that are accompanied by small standard deviations can be impressive. Notice that Cohen's *d* does not account for sampling distributions based on sample size as does the *t*-test, so Cohen's *d* is influenced less by fluctuations in sample size. In sum, Cohen's *d* provides a measure of the difference in terms of standard deviations. For example, a *d* = 1.0 simply refers to a difference between the group means is separated by 1 standard deviation, whereas a *d* = .50 refers to a difference between the group means which is separated by half of a standard deviation. Because it is measured in terms of the number of standard deviations that separate the comparison means, it is not limited to 1.0 like *r*-squared is. 

A great dynamic illustration of Cohen's *d* that I recommend checking out can be found at [rpsychologist.com](http://rpsychologist.com/d3/cohend/)  (just use the visual, don't worry about Cohen's U value)


Although classifying values that are continuous places limits on the size of effect size, Cohen (1988) suggested that effect sizes could be classified as Small, *d* = .2, Medium, *d* = .5, and Large, *d* = .8.


6.3. Calculating different measures of effect size

6.3.1. *z*-test: When the population standard deviation is known we can use Cohen's *d* as an estimate of effect size:

- *d* = | xbar - mu / sigma |


6.3.2. One-sample *t*-test: When the population variance is not known, Cohen's *d* is estimated using the unbiased sample standard deviation:

- *d* = | xbar - mu / sigma |

Using the blook-pressure data, we can calculate Cohen's *d* based on the difference between the means as a function of standard deviations.

```{r}
BLOOD.d <- abs((mean(BLOOD$BP) - 120) / sd(BLOOD$BP))
BLOOD.d
```
library(effsize)

*BONUS:* If you wanted to be savvy and didn't want to remember the formula, you could also write your own personal R function for calculating Cohen's *d*. 

```{r, echo=F}
cohens.d.one.sample <- function(x, mu, sigma = NULL){
  if (is.null(sigma))  {  # if sigma is not provided
          sigma = sd(x) } # calculate estimate
  d = abs( (mean(x) - mu) / sigma ) # cohen's d
  return(d) # return the value of d
}
```

When you want to use your newly-created function, you can enter the arguments as needed:

```{r}
# enter the arguments and assign the value returned from the calculation to an object named BLOOD.d
BLOOD.d <- with(BLOOD, cohens.d.one.sample(Bp, 120))
BLOOD.d # Notice this is the same value as before. 
```


#Part C: Do it yourself!

1.1. An outbreak of Salmonella-related illness was attributed to ice cream produced at a certain factory. Scientists measured the level of Salmonella in 9 randomly sampled batches of ice cream. The levels (in MPN/g) were:

- 0.593 0.142 0.329 0.691 0.231 0.793 0.519 0.392 0.418

```{r}
Salmonella <- c(0.593, 0.142, 0.329, 0.691, 0.231, 0.793, 0.519, 0.392, 0.418)
```

1.2. **QUESTION:** Test whether a normal distribution is a reasonable assumption for those data. Test with alpha = .05. You can look at a histogram and qqplots too if you want. 

*ANSWER:*
```{r}


```


1.3. **QUESTION:** Is there evidence that the factory has a mean level of Salmonella in the ice cream that differs from 0.3 MPN/g? Note: The variable is not in a data frame, so you cannot use the `with` function unless you make the data into a data frame. Use alpha .05

*ANSWER:*
```{r}

```


1.4. **QUESTION:** What do you conclude based on your test output? Be clear in your answer by making sure to explain the nature of the outcome.  

*ANSWER:* 




###DONE!
Upload your knit HTML file to Sakai's dropbox. Make sure to include your name(s). 
