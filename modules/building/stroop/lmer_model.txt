library(performance)
library(dplyr)
library(lem4)
library(ggplot2)

# standard Stroop

conruent is baseline (0), so incongruent is the comparison group (1)

mutate(., incongruent = case_when(
  congruent == "congruent" ~ 0,
  congruent == "incongruent" ~ 1
))

STROOP %>% 
  ggplot() +
  #geom_point(mapping = aes(x = rt, y = incongruent)) +
  geom_point(mapping = aes(x = rt, y = incongruent)) +
  facet_wrap(~ id)

STROOP %>%
  ggplot(.,                                       # Grouped barplot using ggplot2
       aes(x = incongruent,
           y = rt,
           fill = incongruent)) +
  geom_bar(stat = "identity",
           position = "dodge")

# with stat = "identity"
STROOP %>%
ggplot(., aes(incogruent, rt)) +           # ggplot2 barplot with sum
  geom_bar(stat = "identity")
  
  
STROOP %>%
ggplot(., aes(incongruent, rt)) +           # ggplot2 barplot with mean
  geom_bar(position = "dodge",
           stat = "summary",
           fun = "mean")
           
            Order of the bars of the bar graph

#The default order of the bars depend on the levels of the factor variable. In our example you can check the order of the bars with levels(as.factor(df$group)). However, you reorder the bars in several ways: changing the limits with scale_x_discrete, modifying the levels order with factor or even using the reorder function.

https://r-charts.com/ranking/bar-plot-ggplot2/
STROOP %>%
ggplot(., aes(x = valence, y = rt)) +
  geom_bar(stat = "identity") +
  scale_x_discrete(limits = c("Negative", "Neutral", "Positive"))

# Or changing the levels of the factor variable
STROOP %>%
ggplot(., aes(x = factor(valence, levels = c("Negative", "Neutral", "Positive")), y = rt)) +
  geom_bar(stat = "identity")
  
https://r-charts.com/ranking/ggradar/
https://r-charts.com/ranking/lollipop-chart-ggplot2/

ggplot(df, aes(x = x, y = y, color = group)) +
  geom_point() +
  stat_ellipse()

ggplot(df, aes(x = x, y = y, color = group,
               linetype = group)) +
  geom_point() +
  stat_ellipse()
  
# add ellipse to scatter by CI level
ggplot(df, aes(x = x, y = y)) +
  geom_point() +
  stat_ellipse(level = 0.9) +
  stat_ellipse(level = 0.95, color = 2) +
  stat_ellipse(level = 0.99, color = 3)
  
# https://www.learn-mlms.com/09-module-9.html




# Random-Intercept-Only/Null Model
null_model <- lmer(rt ~ 1 + (1|id), data = STROOP, REML = FALSE) # note that REML = FALSE
performance::icc(null_model)

# Adding Level-1 Fixed Effects

lev1_model <- lmer(rt ~ 1 + incongruent + (1|id), data = STROOP, REML = FALSE)
performance::lev1_model

anova(null_model, lev1_model)

# Compare models, see if there is less "deviance" in the real model. If so, it's a better model. 


#Add random slope effects (but no covariances):
l1_random <- lmer(rt ~ 1 + incongruent + (1|id) + (0 + incongruent|id), data = STROOP, REML = FALSE)
summary(l1_random)


# if there are multiple predictors. Is there an estimation error? Singularity occurs when a variance term is close to zero or a correlation between variance terms is near 1 (high multicollinearity). The variance terms for predictor var1 and var2 both look quite small. Try to address the estimation issue by removing the smaller of the two

l1_random_without_cmean <- lmer(rt ~ 1 + val_mn + arous_mn + (1|id) + (0 + val_mn|id), data = STROOP, REML = FALSE)
summary(l1_random_without_cmean)




# emotional

mutate(., 
valence = case_when(
  val == "neutral" ~ 0,
  val == "negative" ~ -1,
  val == "positive" ~ 1
))

estroop_lev1_model <- lmer(rt ~ 1 + valence + (1|id), data = STROOP, REML = FALSE)
summary(l1_model)


estroop_lev1_model <- lmer(rt ~ 1 + val_mn + arous_mn + (1|id), data = STROOP, REML = FALSE)
l1_model <- lmer(lg_rt ~ 1 + c_mean + c_sal + (1|id), data = data, REML = FALSE)
